"""
Async TerminusDB ì„œë¹„ìŠ¤ ëª¨ë“ˆ
httpxë¥¼ ì‚¬ìš©í•œ ë¹„ë™ê¸° TerminusDB í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
"""

import httpx
import json
import asyncio
from typing import Dict, List, Optional, Any, Union
from datetime import datetime
import logging
from contextlib import asynccontextmanager
from functools import wraps

import sys
import os
# ğŸ”¥ THINK ULTRA! Add ontology-management-service root directory to path for utils/validators imports
# CRITICAL: This must come FIRST to avoid conflicts with shared/utils
oms_root = os.path.join(os.path.dirname(__file__), '..')
sys.path.insert(0, oms_root)  # Insert at beginning to take precedence

# Add shared directory to path AFTER local directories
sys.path.insert(1, os.path.join(os.path.dirname(__file__), '..', '..', 'shared'))

# print(f"ğŸ”¥ DEBUG: Added {oms_root} to sys.path")
# print(f"ğŸ”¥ DEBUG: sys.path = {sys.path[:5]}")  # Show first 5 entries

from models.ontology import (
    OntologyCreateRequest,
    OntologyUpdateRequest,
    MultiLingualText,
    QueryOperator,
    OntologyBase,
    Relationship
)
from models.config import ConnectionConfig, AsyncConnectionInfo
from exceptions import (
    OntologyNotFoundError,
    DuplicateOntologyError,
    OntologyValidationError,
    ConnectionError,
    DatabaseNotFoundError
)
from models.common import DataType  # ğŸ”¥ THINK ULTRA! Import at top level

# ğŸ”¥ THINK ULTRA! Import new relationship management components - USING DIRECT IMPORTLIB
from .relationship_manager import RelationshipManager
from validators.relationship_validator import RelationshipValidator, ValidationResult, ValidationSeverity

# ğŸ”¥ THINK ULTRA! Use direct import with importlib to force correct path and avoid shared/utils conflict
import importlib.util

# Load local utils modules directly to bypass import conflicts
utils_circular_path = os.path.join(oms_root, 'utils', 'circular_reference_detector.py')
utils_path_tracker_path = os.path.join(oms_root, 'utils', 'relationship_path_tracker.py')

# Load circular_reference_detector
spec = importlib.util.spec_from_file_location("circular_reference_detector", utils_circular_path)
circular_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(circular_module)

CircularReferenceDetector = circular_module.CircularReferenceDetector
CycleInfo = circular_module.CycleInfo

# Load relationship_path_tracker
spec2 = importlib.util.spec_from_file_location("relationship_path_tracker", utils_path_tracker_path)
path_module = importlib.util.module_from_spec(spec2)
spec2.loader.exec_module(path_module)

RelationshipPathTracker = path_module.RelationshipPathTracker
PathQuery = path_module.PathQuery
RelationshipPath = path_module.RelationshipPath
PathType = path_module.PathType

logger = logging.getLogger(__name__)

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
AsyncOntologyNotFoundError = OntologyNotFoundError
AsyncDuplicateOntologyError = DuplicateOntologyError
AsyncValidationError = OntologyValidationError
AsyncDatabaseError = ConnectionError


def async_terminus_retry(max_retries: int = 3, delay: float = 1.0):
    """ë¹„ë™ê¸° ì¬ì‹œë„ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_retries):
                try:
                    return await func(*args, **kwargs)
                except (httpx.RequestError, httpx.HTTPStatusError) as e:
                    last_exception = e
                    if attempt < max_retries - 1:
                        await asyncio.sleep(delay * (2 ** attempt))
                        continue
                    raise
            raise last_exception
        return wrapper
    return decorator


class AsyncTerminusService:
    """
    ë¹„ë™ê¸° TerminusDB ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    httpxë¥¼ ì‚¬ìš©í•˜ì—¬ TerminusDB APIì™€ ì§ì ‘ í†µì‹ 
    """
    
    def __init__(self, connection_info: Optional[ConnectionConfig] = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            connection_info: ì—°ê²° ì •ë³´ ê°ì²´
        """
        # Use environment variables if no connection info provided
        self.connection_info = connection_info or ConnectionConfig.from_env()
        
        self._client = None
        self._auth_token = None
        self._db_cache = set()
        
        # ğŸ”¥ THINK ULTRA! Initialize relationship management components - TESTING ROOT CAUSE
        self.relationship_manager = RelationshipManager()
        self.relationship_validator = RelationshipValidator()
        self.circular_detector = CircularReferenceDetector()
        self.path_tracker = RelationshipPathTracker()
        
        # Relationship cache for performance
        self._ontology_cache: Dict[str, List[OntologyBase]] = {}
    
    async def _get_client(self) -> httpx.AsyncClient:
        """HTTP í´ë¼ì´ì–¸íŠ¸ ìƒì„±/ë°˜í™˜"""
        if self._client is None:
            self._client = httpx.AsyncClient(
                base_url=self.connection_info.server_url,
                timeout=self.connection_info.timeout,
                headers={
                    "Content-Type": "application/json",
                    "Accept": "application/json"
                }
            )
        return self._client
    
    async def _authenticate(self) -> str:
        """TerminusDB ì¸ì¦ ì²˜ë¦¬ - Basic Auth ì‚¬ìš©"""
        import base64
        
        if self._auth_token:
            return self._auth_token
        
        # Validate credentials exist
        if not self.connection_info.user or not self.connection_info.key:
            raise ConnectionError("TerminusDB credentials not configured. Set TERMINUS_USER and TERMINUS_KEY environment variables.")
        
        # Warn if not using HTTPS in production
        if not self.connection_info.server_url.startswith("https://") and "localhost" not in self.connection_info.server_url:
            logger.warning("Using HTTP instead of HTTPS for TerminusDB connection. This is insecure for production use.")
        
        # Basic Auth í—¤ë” ìƒì„± (TerminusDB requirement)
        credentials = f"{self.connection_info.user}:{self.connection_info.key}"
        encoded_credentials = base64.b64encode(credentials.encode('utf-8')).decode('ascii')
        self._auth_token = f"Basic {encoded_credentials}"
        
        return self._auth_token
    
    async def _make_request(self, method: str, endpoint: str, 
                          data: Optional[Dict] = None, 
                          params: Optional[Dict] = None) -> Dict[str, Any]:
        """HTTP ìš”ì²­ ì‹¤í–‰"""
        client = await self._get_client()
        token = await self._authenticate()
        
        headers = {
            "Authorization": token,
            "X-Request-ID": str(id(self)),  # For request tracking
            "User-Agent": "SPICE-HARVESTER-OMS/1.0"  # Identify our service
        }
        
        try:
            response = await client.request(
                method=method,
                url=endpoint,
                json=data,
                params=params,
                headers=headers
            )
            response.raise_for_status()
            
            # TerminusDB ì‘ë‹µì´ ë¹ˆ ê²½ìš° ì²˜ë¦¬
            if response.text.strip():
                return response.json()
            else:
                # ë¹ˆ ì‘ë‹µì€ ì„±ê³µì ì¸ ì‘ì—…ì„ ì˜ë¯¸í•  ìˆ˜ ìˆìŒ (ì˜ˆ: DELETE)
                # ê°€ì§œ ì„±ê³µ ì‘ë‹µ ëŒ€ì‹  ë¹ˆ dict ë°˜í™˜
                return {}
            
        except httpx.HTTPStatusError as e:
            error_detail = ""
            try:
                error_detail = e.response.text
            except AttributeError:
                # response.textê°€ ì—†ì„ ìˆ˜ ìˆìŒ
                pass
            except Exception as detail_error:
                logger.debug(f"Error extracting error detail: {detail_error}")
            
            if e.response.status_code == 404:
                raise AsyncOntologyNotFoundError(f"ë¦¬ì†ŒìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {endpoint}")
            elif e.response.status_code == 409:
                raise AsyncDuplicateOntologyError(f"ì¤‘ë³µëœ ë¦¬ì†ŒìŠ¤: {endpoint}")
            else:
                raise AsyncDatabaseError(f"HTTP ì˜¤ë¥˜ {e.response.status_code}: {e}. ì‘ë‹µ: {error_detail}")
        except httpx.RequestError as e:
            raise AsyncDatabaseError(f"ìš”ì²­ ì‹¤íŒ¨: {e}")
    
    async def connect(self, db_name: Optional[str] = None) -> None:
        """TerminusDB ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            # TerminusDB ì—°ê²° í…ŒìŠ¤íŠ¸ - ì‹¤ì œ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
            result = await self._make_request("GET", "/api/")
            
            if db_name:
                self._db_cache.add(db_name)
            
            logger.info(f"Connected to TerminusDB successfully")
            
        except (httpx.HTTPError, httpx.RequestError, ConnectionError) as e:
            logger.error(f"Failed to connect to TerminusDB: {e}")
            raise AsyncDatabaseError(f"TerminusDB ì—°ê²° ì‹¤íŒ¨: {e}")
    
    async def disconnect(self) -> None:
        """ì—°ê²° í•´ì œ"""
        if self._client:
            await self._client.aclose()
            self._client = None
        
        self._auth_token = None
        self._db_cache.clear()
        logger.info("Disconnected from TerminusDB")
    
    async def check_connection(self) -> bool:
        """ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            await self._make_request("GET", "/api/")
            return True
        except Exception:
            return False
    
    @async_terminus_retry(max_retries=3)
    async def database_exists(self, db_name: str) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        try:
            # TerminusDB ì˜¬ë°”ë¥¸ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
            endpoint = f"/api/db/{self.connection_info.account}/{db_name}"
            await self._make_request("GET", endpoint)
            return True
        except AsyncOntologyNotFoundError:
            return False
    
    async def ensure_db_exists(self, db_name: str, description: Optional[str] = None) -> None:
        """ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ìƒì„±"""
        if db_name in self._db_cache:
            return
        
        try:
            if await self.database_exists(db_name):
                self._db_cache.add(db_name)
                return
            
            # ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
            await self.create_database(db_name, description)
            self._db_cache.add(db_name)
            
        except Exception as e:
            logger.error(f"Error ensuring database exists: {e}")
            raise AsyncDatabaseError(f"ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±/í™•ì¸ ì‹¤íŒ¨: {e}")
    
    async def create_database(self, db_name: str, description: Optional[str] = None) -> Dict[str, Any]:
        """ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±"""
        # ì¤‘ë³µ ê²€ì‚¬ - ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ì˜ˆì™¸ ë°œìƒ
        if await self.database_exists(db_name):
            raise AsyncDuplicateOntologyError(f"ë°ì´í„°ë² ì´ìŠ¤ '{db_name}'ì´(ê°€) ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤")
        
        endpoint = f"/api/db/{self.connection_info.account}/{db_name}"
        
        # TerminusDB ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ìš”ì²­ í˜•ì‹
        data = {
            "label": db_name,
            "comment": description or f"{db_name} database",
            "prefixes": {"@base": f"terminusdb:///{self.connection_info.account}/{db_name}/data/", "@schema": f"terminusdb:///{self.connection_info.account}/{db_name}/schema#"}
        }
        
        try:
            result = await self._make_request("POST", endpoint, data)
            self._db_cache.add(db_name)
            
            return {
                "name": db_name,
                "created_at": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Failed to create database: {e}")
            raise AsyncDatabaseError(f"ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
    
    async def list_databases(self) -> List[Dict[str, Any]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ"""
        try:
            endpoint = f"/api/db/{self.connection_info.account}"
            result = await self._make_request("GET", endpoint)
            
            # Debug logging to understand TerminusDB response format
            logger.debug(f"TerminusDB list response type: {type(result)}")
            if isinstance(result, dict):
                logger.debug(f"TerminusDB list response keys: {list(result.keys())}")
            
            databases = []
            # TerminusDB ì‘ë‹µ í˜•ì‹ ì²˜ë¦¬ - ì—¬ëŸ¬ í˜•ì‹ ì§€ì›
            if isinstance(result, list):
                db_list = result
            elif isinstance(result, dict):
                # Check for common keys that might contain the database list
                if "@graph" in result:
                    db_list = result["@graph"]
                elif "databases" in result:
                    db_list = result["databases"]
                elif "dbs" in result:
                    db_list = result["dbs"]
                else:
                    # If no known keys, assume the dict contains database info directly
                    db_list = []
                    logger.warning(f"Unknown TerminusDB response format for database list: {result}")
            else:
                db_list = []
            
            for db_info in db_list:
                # ë‹¤ì–‘í•œ ì‘ë‹µ í˜•ì‹ ì²˜ë¦¬
                db_name = None
                
                if isinstance(db_info, str):
                    # ë‹¨ìˆœ ë¬¸ìì—´ì¸ ê²½ìš°
                    db_name = db_info
                elif isinstance(db_info, dict):
                    # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ì—¬ëŸ¬ í‚¤ ì‹œë„
                    db_name = (db_info.get("name") or 
                              db_info.get("id") or
                              db_info.get("@id"))
                    
                    # path í˜•ì‹ ì²˜ë¦¬
                    if not db_name and "path" in db_info:
                        path = db_info.get("path", "")
                        if "/" in path:
                            _, db_name = path.split("/", 1)
                
                if db_name:
                    databases.append({
                        "name": db_name,
                        "label": db_info.get("label", db_name) if isinstance(db_info, dict) else db_name,
                        "comment": db_info.get("comment", f"Database {db_name}") if isinstance(db_info, dict) else f"Database {db_name}",
                        "created": db_info.get("created") if isinstance(db_info, dict) else None,
                        "path": db_info.get("path") if isinstance(db_info, dict) else f"{self.connection_info.account}/{db_name}"
                    })
                    self._db_cache.add(db_name)
            
            return databases
            
        except Exception as e:
            logger.error(f"Failed to list databases: {e}")
            raise AsyncDatabaseError(f"ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    @async_terminus_retry(max_retries=3)
    async def delete_database(self, db_name: str) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ"""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            if not await self.database_exists(db_name):
                raise AsyncOntologyNotFoundError(f"ë°ì´í„°ë² ì´ìŠ¤ '{db_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # TerminusDB ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
            endpoint = f"/api/db/{self.connection_info.account}/{db_name}"
            await self._make_request("DELETE", endpoint)
            
            # ìºì‹œì—ì„œ ì œê±°
            self._db_cache.discard(db_name)
            
            logger.info(f"Database '{db_name}' deleted successfully")
            return True
            
        except AsyncOntologyNotFoundError:
            raise
        except Exception as e:
            logger.error(f"Failed to delete database '{db_name}': {e}")
            raise AsyncDatabaseError(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ ì‹¤íŒ¨: {e}")
    
    async def create_ontology(self, db_name: str, jsonld_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ìƒì„±"""
        await self.ensure_db_exists(db_name)
        
        # TerminusDB ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ ì—”ë“œí¬ì¸íŠ¸
        endpoint = f"/api/schema/{self.connection_info.account}/{db_name}"
        
        # JSON-LD í˜•ì‹ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆ ë°ì´í„° í¬ë§·íŒ…
        schema_data = [{
            "@type": "Class",
            "@id": jsonld_data.get("@id"),
            "@documentation": jsonld_data.get("rdfs:comment", {}),
            "rdfs:label": jsonld_data.get("rdfs:label", {}),
            "@key": {
                "@type": "Lexical",
                "@fields": ["@id"]
            }
        }]
        
        try:
            result = await self._make_request("POST", endpoint, schema_data)
            
            return {
                "id": jsonld_data.get("@id"),
                "created_at": datetime.utcnow().isoformat(),
                "database": db_name
            }
            
        except Exception as e:
            logger.error(f"Failed to create ontology: {e}")
            if "already exists" in str(e):
                raise AsyncDuplicateOntologyError(str(e))
            elif "validation" in str(e).lower():
                raise AsyncValidationError(str(e))
            else:
                raise AsyncDatabaseError(f"ì˜¨í†¨ë¡œì§€ ìƒì„± ì‹¤íŒ¨: {e}")
    
    async def get_ontology(self, db_name: str, class_id: str, 
                          raise_if_missing: bool = True) -> Optional[Dict[str, Any]]:
        """ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ì¡°íšŒ - Document API ì‚¬ìš©"""
        await self.ensure_db_exists(db_name)
        
        # Document APIë¥¼ í†µí•œ ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
        endpoint = f"/api/document/{self.connection_info.account}/{db_name}"
        params = {
            "graph_type": "schema"
        }
        
        try:
            # JSON Lines í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ ë°›ê¸°
            client = await self._get_client()
            token = await self._authenticate()
            
            headers = {
                "Authorization": token
            }
            
            response = await client.request(
                method="GET",
                url=endpoint,
                params=params,
                headers=headers
            )
            response.raise_for_status()
            
            # JSON Lines í˜•ì‹ íŒŒì‹±
            response_text = response.text.strip()
            
            if response_text:
                for line in response_text.split('\n'):
                    try:
                        doc = json.loads(line)
                        if doc.get("@id") == class_id and doc.get("@type") == "Class":
                            return doc
                    except json.JSONDecodeError:
                        # ì»¨í…ìŠ¤íŠ¸ ì¤„ ë“±ì€ ë¬´ì‹œ
                        continue
            
            if raise_if_missing:
                raise AsyncOntologyNotFoundError(f"ì˜¨í†¨ë¡œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {class_id}")
            return None
            
        except AsyncOntologyNotFoundError:
            if raise_if_missing:
                raise
            return None
        except Exception as e:
            logger.error(f"ì˜¨í†¨ë¡œì§€ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            if raise_if_missing:
                raise AsyncDatabaseError(f"ì˜¨í†¨ë¡œì§€ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    async def update_ontology(self, db_name: str, class_id: str, 
                            jsonld_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ì—…ë°ì´íŠ¸ - Document API ì‚¬ìš©"""
        await self.ensure_db_exists(db_name)
        
        # ë¨¼ì € ê¸°ì¡´ ë¬¸ì„œ ì¡°íšŒ
        existing_doc = await self.get_ontology(db_name, class_id, raise_if_missing=True)
        if not existing_doc:
            raise AsyncOntologyNotFoundError(f"ì˜¨í†¨ë¡œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {class_id}")
        
        # ê¸°ì¡´ ë¬¸ì„œì™€ ìƒˆ ë°ì´í„° ë³‘í•©
        updated_doc = {**existing_doc, **jsonld_data}
        updated_doc["@id"] = class_id  # IDëŠ” ë³€ê²½í•˜ì§€ ì•ŠìŒ
        updated_doc["@type"] = "Class"  # íƒ€ì… ìœ ì§€
        
        # Document APIë¥¼ í†µí•œ ì—…ë°ì´íŠ¸ (replace)
        endpoint = f"/api/document/{self.connection_info.account}/{db_name}"
        
        # ë¨¼ì € ì‚­ì œ
        delete_params = {
            "graph_type": "schema",
            "author": self.connection_info.user,
            "message": f"Deleting {class_id} for update"
        }
        
        try:
            # IDë¡œ ì‚­ì œ
            await self._make_request("DELETE", f"{endpoint}/{class_id}", None, delete_params)
        except Exception as e:
            logger.warning(f"ì‚­ì œ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
        
        # ìƒˆë¡œ ìƒì„±
        create_params = {
            "graph_type": "schema",
            "author": self.connection_info.user,
            "message": f"Updating {class_id} schema"
        }
        
        try:
            result = await self._make_request("POST", endpoint, [updated_doc], create_params)
            
            return {
                "id": class_id,
                "updated_at": datetime.utcnow().isoformat(),
                "database": db_name,
                "result": result
            }
            
        except Exception as e:
            if "validation" in str(e).lower():
                raise AsyncValidationError(str(e))
            else:
                raise AsyncDatabaseError(f"ì˜¨í†¨ë¡œì§€ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    async def delete_ontology(self, db_name: str, class_id: str) -> bool:
        """ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ì‚­ì œ - Document API ì‚¬ìš©"""
        await self.ensure_db_exists(db_name)
        
        # ë¨¼ì € ë¬¸ì„œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        existing_doc = await self.get_ontology(db_name, class_id, raise_if_missing=False)
        if not existing_doc:
            raise AsyncOntologyNotFoundError(f"ì˜¨í†¨ë¡œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {class_id}")
        
        # Document APIë¥¼ í†µí•œ ì‚­ì œ
        endpoint = f"/api/document/{self.connection_info.account}/{db_name}/{class_id}"
        params = {
            "graph_type": "schema",
            "author": self.connection_info.user,
            "message": f"Deleting {class_id} schema"
        }
        
        try:
            await self._make_request("DELETE", endpoint, None, params)
            return True
            
        except Exception as e:
            raise AsyncDatabaseError(f"ì˜¨í†¨ë¡œì§€ ì‚­ì œ ì‹¤íŒ¨: {e}")
    
    async def list_ontologies(self, db_name: str, class_type: str = "sys:Class",
                            limit: Optional[int] = None, offset: int = 0) -> List[Dict[str, Any]]:
        """ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ëª©ë¡ ì¡°íšŒ - Document API ì‚¬ìš©"""
        # list_ontology_classes ë©”ì„œë“œë¥¼ ì¬ì‚¬ìš©
        classes_raw = await self.list_ontology_classes(db_name)
        
        # ì‘ë‹µ í˜•ì‹ ë³€í™˜
        classes = []
        for cls in classes_raw:
            if cls.get("type") == "Class" or class_type == "sys:Class":
                class_info = {
                    "id": cls.get("id"),
                    "type": cls.get("type", "Class"),
                    "label": cls.get("properties", {}).get("rdfs:label", {}),
                    "description": cls.get("properties", {}).get("rdfs:comment", {}),
                    "properties": cls.get("properties", {})
                }
                classes.append(class_info)
        
        # í˜ì´ì§• ì²˜ë¦¬
        if offset > 0:
            classes = classes[offset:]
        if limit:
            classes = classes[:limit]
        
        return classes
    
    async def execute_query(self, db_name: str, query_dict: Dict[str, Any]) -> List[Dict[str, Any]]:
        """WOQL ì¿¼ë¦¬ ì‹¤í–‰"""
        await self.ensure_db_exists(db_name)
        
        # TerminusDB WOQL ì¿¼ë¦¬ ì—”ë“œí¬ì¸íŠ¸
        endpoint = f"/api/woql/{self.connection_info.account}/{db_name}"
        
        # ì¿¼ë¦¬ ë”•ì…”ë„ˆë¦¬ë¥¼ WOQL í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        woql_query = self._convert_to_woql(query_dict)
        
        try:
            result = await self._make_request("POST", endpoint, woql_query)
            
            # ê²°ê³¼ íŒŒì‹±
            bindings = result.get("bindings", [])
            parsed_results = []
            
            for binding in bindings:
                parsed_result = {}
                for key, value in binding.items():
                    if isinstance(value, dict) and "@value" in value:
                        parsed_result[key] = value["@value"]
                    elif isinstance(value, dict) and "@id" in value:
                        parsed_result[key] = value["@id"]
                    else:
                        parsed_result[key] = value
                parsed_results.append(parsed_result)
            
            return {"results": parsed_results, "total": len(parsed_results)}
            
        except Exception as e:
            logger.error(f"Failed to execute query: {e}")
            raise AsyncDatabaseError(f"ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
    
    async def delete_ontology(self, db_name: str, class_id: str) -> bool:
        """ì‹¤ì œ TerminusDB ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ì‚­ì œ"""
        try:
            await self.ensure_db_exists(db_name)
            
            # TerminusDB Document APIë¥¼ í†µí•œ ì‚­ì œ: DELETE /api/document/<account>/<db>/<id>
            endpoint = f"/api/document/{self.connection_info.account}/{db_name}/{class_id}"
            params = {
                "graph_type": "schema"
            }
            
            # ì‹¤ì œ ì‚­ì œ ìš”ì²­
            await self._make_request("DELETE", endpoint, params=params)
            
            logger.info(f"TerminusDB ontology '{class_id}' deleted successfully from database '{db_name}'")
            return True
            
        except Exception as e:
            logger.error(f"TerminusDB delete ontology API failed: {e}")
            if "not found" in str(e).lower():
                raise AsyncOntologyNotFoundError(f"ì˜¨í†¨ë¡œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {class_id}")
            else:
                raise AsyncDatabaseError(f"ì˜¨í†¨ë¡œì§€ ì‚­ì œ ì‹¤íŒ¨: {e}")
    
    async def list_ontology_classes(self, db_name: str) -> List[Dict[str, Any]]:
        """ì‹¤ì œ TerminusDB ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ëª©ë¡ ì¡°íšŒ"""
        try:
            await self.ensure_db_exists(db_name)
            
            # TerminusDB Document APIë¡œ ëª¨ë“  ìŠ¤í‚¤ë§ˆ ë¬¸ì„œ ì¡°íšŒ: GET /api/document/<account>/<db>
            endpoint = f"/api/document/{self.connection_info.account}/{db_name}"
            params = {
                "graph_type": "schema",
                "type": "Class"
            }
            
            # ì‹¤ì œ API ìš”ì²­
            client = await self._get_client()
            token = await self._authenticate()
            
            headers = {
                "Authorization": token
            }
            
            response = await client.request(
                method="GET",
                url=endpoint,
                params=params,
                headers=headers
            )
            response.raise_for_status()
            
            # JSON Lines í˜•ì‹ íŒŒì‹±
            response_text = response.text.strip()
            ontologies = []
            
            if response_text:
                for line in response_text.split('\n'):
                    if line.strip():
                        try:
                            doc = json.loads(line.strip())
                            if isinstance(doc, dict) and doc.get("@type") == "Class":
                                ontologies.append(doc)
                        except json.JSONDecodeError:
                            logger.warning(f"Failed to parse JSON line: {line}")
            
            logger.info(f"TerminusDB retrieved {len(ontologies)} ontology classes from database '{db_name}'")
            return ontologies
            
        except Exception as e:
            logger.error(f"TerminusDB list ontology classes API failed: {e}")
            raise AsyncDatabaseError(f"ì˜¨í†¨ë¡œì§€ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    # === BRANCH MANAGEMENT METHODS ===
    
    async def list_branches(self, db_name: str) -> List[str]:
        """ì‹¤ì œ TerminusDB ë¸Œëœì¹˜ ëª©ë¡ ì¡°íšŒ"""
        try:
            # TerminusDBì˜ ì‹¤ì œ ë¸Œëœì¹˜ API: GET /api/db/<account>/<db>/branch
            endpoint = f"/api/db/{self.connection_info.account}/{db_name}/branch"
            
            # TerminusDBì— ì‹¤ì œ ìš”ì²­
            result = await self._make_request("GET", endpoint)
            
            branches = []
            if isinstance(result, dict):
                # TerminusDB ë¸Œëœì¹˜ ì‘ë‹µ êµ¬ì¡°: {"@type": "BranchList", "branch_name": [...]}
                if "branch_name" in result:
                    branches = result["branch_name"]
                elif "branches" in result:
                    branches = [branch.get("name", branch) for branch in result["branches"]]
            elif isinstance(result, list):
                # ì§ì ‘ ë¸Œëœì¹˜ ëª©ë¡ì¸ ê²½ìš°
                branches = [branch if isinstance(branch, str) else branch.get("name", str(branch)) for branch in result]
            
            # ìœ íš¨í•œ ë¸Œëœì¹˜ë§Œ ë°˜í™˜
            valid_branches = [b for b in branches if b and isinstance(b, str)]
            
            if not valid_branches:
                # TerminusDB ê¸°ë³¸ ë¸Œëœì¹˜ëŠ” 'main'
                valid_branches = ['main']
            
            logger.info(f"Retrieved {len(valid_branches)} branches: {valid_branches}")
            return valid_branches
            
        except Exception as e:
            logger.error(f"TerminusDB branch API failed: {e}")
            raise AsyncDatabaseError(f"ë¸Œëœì¹˜ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    async def get_current_branch(self, db_name: str) -> str:
        """ì‹¤ì œ TerminusDB í˜„ì¬ ë¸Œëœì¹˜ ì¡°íšŒ"""
        try:
            # TerminusDBì˜ ì‹¤ì œ HEAD ì •ë³´ API
            endpoint = f"/api/db/{self.connection_info.account}/{db_name}/_meta"
            result = await self._make_request("GET", endpoint)
            
            # HEAD ì •ë³´ì—ì„œ í˜„ì¬ ë¸Œëœì¹˜ ì¶”ì¶œ
            if isinstance(result, dict):
                current_branch = result.get("head", {}).get("branch", "main")
                if isinstance(current_branch, str):
                    return current_branch
            
            # ê¸°ë³¸ê°’ìœ¼ë¡œ main ë°˜í™˜
            return "main"
            
        except Exception as e:
            logger.error(f"TerminusDB get current branch API failed: {e}")
            raise AsyncDatabaseError(f"í˜„ì¬ ë¸Œëœì¹˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    async def create_branch(self, db_name: str, branch_name: str, from_branch: Optional[str] = None) -> bool:
        """ì‹¤ì œ TerminusDB ë¸Œëœì¹˜ ìƒì„±"""
        try:
            if not branch_name or not branch_name.strip():
                raise ValueError("ë¸Œëœì¹˜ ì´ë¦„ì€ í•„ìˆ˜ì…ë‹ˆë‹¤")
            
            # ì˜ˆì•½ëœ ì´ë¦„ í™•ì¸
            reserved_names = {'HEAD', 'main', 'master', 'origin'}
            if branch_name.lower() in reserved_names:
                raise ValueError(f"'{branch_name}'ì€(ëŠ”) ì˜ˆì•½ëœ ë¸Œëœì¹˜ ì´ë¦„ì…ë‹ˆë‹¤")
            
            # TerminusDB ì‹¤ì œ ë¸Œëœì¹˜ ìƒì„± API: POST /api/db/<account>/<db>/branch/<branch_name>
            endpoint = f"/api/db/{self.connection_info.account}/{db_name}/branch/{branch_name}"
            
            # ë¸Œëœì¹˜ ìƒì„± ìš”ì²­ ë°ì´í„°
            data = {
                "origin": from_branch or "main"
            }
            
            # TerminusDBì— ì‹¤ì œ ë¸Œëœì¹˜ ìƒì„± ìš”ì²­
            await self._make_request("POST", endpoint, data)
            
            logger.info(f"TerminusDB branch '{branch_name}' created successfully from '{from_branch or 'main'}'")
            return True
            
        except Exception as e:
            logger.error(f"TerminusDB create branch API failed: {e}")
            raise ValueError(f"ë¸Œëœì¹˜ ìƒì„± ì‹¤íŒ¨: {e}")
    
    async def delete_branch(self, db_name: str, branch_name: str) -> bool:
        """ì‹¤ì œ TerminusDB ë¸Œëœì¹˜ ì‚­ì œ"""
        try:
            # ë³´í˜¸ëœ ë¸Œëœì¹˜ í™•ì¸
            protected_branches = {'main', 'master', 'HEAD'}
            if branch_name.lower() in protected_branches:
                raise ValueError(f"ë³´í˜¸ëœ ë¸Œëœì¹˜ '{branch_name}'ì€(ëŠ”) ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # TerminusDB ì‹¤ì œ ë¸Œëœì¹˜ ì‚­ì œ API: DELETE /api/db/<account>/<db>/branch/<branch_name>
            endpoint = f"/api/db/{self.connection_info.account}/{db_name}/branch/{branch_name}"
            
            # TerminusDBì— ì‹¤ì œ ë¸Œëœì¹˜ ì‚­ì œ ìš”ì²­
            await self._make_request("DELETE", endpoint)
            
            logger.info(f"TerminusDB branch '{branch_name}' deleted successfully")
            return True
            
        except Exception as e:
            logger.error(f"TerminusDB delete branch API failed: {e}")
            raise ValueError(f"ë¸Œëœì¹˜ ì‚­ì œ ì‹¤íŒ¨: {e}")
    
    async def checkout(self, db_name: str, target: str, target_type: str = "branch") -> bool:
        """ì‹¤ì œ TerminusDB ì²´í¬ì•„ì›ƒ"""
        try:
            if not target or not target.strip():
                raise ValueError(f"{target_type} ì´ë¦„ì€ í•„ìˆ˜ì…ë‹ˆë‹¤")
            
            if target_type == "branch":
                # TerminusDB ë¸Œëœì¹˜ ì²´í¬ì•„ì›ƒ API: POST /api/db/<account>/<db>/_meta
                endpoint = f"/api/db/{self.connection_info.account}/{db_name}/_meta"
                data = {
                    "head": {
                        "branch": target
                    }
                }
            elif target_type == "commit":
                # TerminusDB ì»¤ë°‹ ì²´í¬ì•„ì›ƒ API
                endpoint = f"/api/db/{self.connection_info.account}/{db_name}/_meta"
                data = {
                    "head": {
                        "commit": target
                    }
                }
            else:
                raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” target_type: {target_type}")
            
            # TerminusDBì— ì‹¤ì œ checkout ìš”ì²­
            await self._make_request("PUT", endpoint, data)
            
            logger.info(f"TerminusDB checkout to {target_type} '{target}' completed successfully")
            return True
            
        except Exception as e:
            logger.error(f"TerminusDB checkout API failed: {e}")
            raise ValueError(f"ì²´í¬ì•„ì›ƒ ì‹¤íŒ¨: {e}")
    
    # === VERSION CONTROL METHODS ===
    
    async def commit(self, db_name: str, message: str, author: str = "admin") -> str:
        """ì‹¤ì œ TerminusDB ì»¤ë°‹ ìƒì„±"""
        try:
            if not message or not message.strip():
                raise ValueError("ì»¤ë°‹ ë©”ì‹œì§€ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤")
            
            # TerminusDB ì‹¤ì œ ì»¤ë°‹ API: POST /api/db/<account>/<db>/_commit
            endpoint = f"/api/db/{self.connection_info.account}/{db_name}/_commit"
            
            # ì»¤ë°‹ ìš”ì²­ ë°ì´í„°
            data = {
                "message": message,
                "author": author
            }
            
            # TerminusDBì— ì‹¤ì œ ì»¤ë°‹ ìš”ì²­
            result = await self._make_request("POST", endpoint, data)
            
            # ì»¤ë°‹ ID ì¶”ì¶œ
            commit_id = result.get("commit_id", result.get("id", f"commit_{int(__import__('time').time())}"))
            
            logger.info(f"TerminusDB commit '{commit_id}' created successfully with message: '{message}' by {author}")
            return str(commit_id)
            
        except Exception as e:
            logger.error(f"TerminusDB commit API failed: {e}")
            raise ValueError(f"ì»¤ë°‹ ìƒì„± ì‹¤íŒ¨: {e}")
    
    async def get_commit_history(self, db_name: str, branch: Optional[str] = None, 
                          limit: int = 10, offset: int = 0) -> List[Dict[str, Any]]:
        """ì‹¤ì œ TerminusDB ì»¤ë°‹ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        try:
            # TerminusDB ì‹¤ì œ ë¡œê·¸ API: GET /api/db/<account>/<db>/_log
            endpoint = f"/api/db/{self.connection_info.account}/{db_name}/_log"
            
            # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°
            params = {
                "limit": limit,
                "offset": offset
            }
            if branch:
                params["branch"] = branch
            
            # TerminusDBì— ì‹¤ì œ ë¡œê·¸ ìš”ì²­
            result = await self._make_request("GET", endpoint, params=params)
            
            # ì»¤ë°‹ íˆìŠ¤í† ë¦¬ ì¶”ì¶œ
            history = []
            if isinstance(result, dict) and "commits" in result:
                history = result["commits"]
            elif isinstance(result, list):
                history = result
            
            # í˜•ì‹ ì •ê·œí™”
            normalized_history = []
            for commit in history:
                if isinstance(commit, dict):
                    normalized_commit = {
                        "id": commit.get("id", commit.get("commit_id", "unknown")),
                        "message": commit.get("message", ""),
                        "author": commit.get("author", "unknown"),
                        "timestamp": commit.get("timestamp", commit.get("time", 0)),
                        "branch": commit.get("branch", branch or "main")
                    }
                    normalized_history.append(normalized_commit)
            
            logger.info(f"TerminusDB retrieved {len(normalized_history)} commits for database '{db_name}'")
            return normalized_history
            
        except Exception as e:
            logger.error(f"TerminusDB get commit history API failed: {e}")
            raise AsyncDatabaseError(f"ì»¤ë°‹ íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    async def diff(self, db_name: str, from_ref: str, to_ref: str) -> List[Dict[str, Any]]:
        """ì‹¤ì œ TerminusDB diff ì¡°íšŒ"""
        try:
            # TerminusDB ì‹¤ì œ diff API: GET /api/db/<account>/<db>/_diff
            endpoint = f"/api/db/{self.connection_info.account}/{db_name}/_diff"
            
            # diff ìš”ì²­ íŒŒë¼ë¯¸í„°
            params = {
                "from": from_ref,
                "to": to_ref
            }
            
            # TerminusDBì— ì‹¤ì œ diff ìš”ì²­
            result = await self._make_request("GET", endpoint, params=params)
            
            # diff ê²°ê³¼ ì¶”ì¶œ
            changes = []
            if isinstance(result, dict) and "changes" in result:
                changes = result["changes"]
            elif isinstance(result, list):
                changes = result
            
            # í˜•ì‹ ì •ê·œí™”
            normalized_changes = []
            for change in changes:
                if isinstance(change, dict):
                    normalized_change = {
                        "type": change.get("type", "unknown"),
                        "path": change.get("path", change.get("id", "unknown")),
                        "old_value": change.get("old_value"),
                        "new_value": change.get("new_value")
                    }
                    normalized_changes.append(normalized_change)
            
            logger.info(f"TerminusDB found {len(normalized_changes)} changes between '{from_ref}' and '{to_ref}'")
            return normalized_changes
            
        except Exception as e:
            logger.error(f"TerminusDB diff API failed: {e}")
            raise AsyncDatabaseError(f"diff ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    async def merge(self, db_name: str, source_branch: str, target_branch: str, 
             strategy: str = "auto") -> Dict[str, Any]:
        """ì‹¤ì œ TerminusDB ë¸Œëœì¹˜ ë¨¸ì§€"""
        try:
            if source_branch == target_branch:
                raise ValueError("ì†ŒìŠ¤ì™€ ëŒ€ìƒ ë¸Œëœì¹˜ê°€ ë™ì¼í•©ë‹ˆë‹¤")
            
            # TerminusDB ì‹¤ì œ ë¨¸ì§€ API: POST /api/db/<account>/<db>/_merge
            endpoint = f"/api/db/{self.connection_info.account}/{db_name}/_merge"
            
            # ë¨¸ì§€ ìš”ì²­ ë°ì´í„°
            data = {
                "source_branch": source_branch,
                "target_branch": target_branch,
                "strategy": strategy
            }
            
            # TerminusDBì— ì‹¤ì œ ë¨¸ì§€ ìš”ì²­
            result = await self._make_request("POST", endpoint, data)
            
            # ë¨¸ì§€ ê²°ê³¼ ì¶”ì¶œ ë° ì •ê·œí™”
            merge_result = {
                "merged": result.get("success", result.get("merged", True)),
                "conflicts": result.get("conflicts", []),
                "source_branch": source_branch,
                "target_branch": target_branch,
                "strategy": strategy,
                "commit_id": result.get("commit_id", result.get("id"))
            }
            
            logger.info(f"TerminusDB merge completed: {source_branch} -> {target_branch}")
            return merge_result
            
        except Exception as e:
            logger.error(f"TerminusDB merge API failed: {e}")
            raise ValueError(f"ë¸Œëœì¹˜ ë¨¸ì§€ ì‹¤íŒ¨: {e}")
    
    async def rollback(self, db_name: str, target: str) -> bool:
        """ì‹¤ì œ TerminusDB ë¡¤ë°±"""
        try:
            if not target or not target.strip():
                raise ValueError("ë¡¤ë°± ëŒ€ìƒì€ í•„ìˆ˜ì…ë‹ˆë‹¤")
            
            # TerminusDB ì‹¤ì œ ë¡¤ë°± API: POST /api/db/<account>/<db>/_reset
            endpoint = f"/api/db/{self.connection_info.account}/{db_name}/_reset"
            
            # ë¡¤ë°± ìš”ì²­ ë°ì´í„°
            data = {
                "target": target
            }
            
            # TerminusDBì— ì‹¤ì œ ë¡¤ë°± ìš”ì²­
            await self._make_request("POST", endpoint, data)
            
            logger.info(f"TerminusDB rollback to '{target}' completed successfully")
            return True
            
        except Exception as e:
            logger.error(f"TerminusDB rollback API failed: {e}")
            raise ValueError(f"ë¡¤ë°± ì‹¤íŒ¨: {e}")
    
    async def rebase(self, db_name: str, onto: str, branch: Optional[str] = None) -> Dict[str, Any]:
        """ì‹¤ì œ TerminusDB ë¦¬ë² ì´ìŠ¤"""
        try:
            if not onto or not onto.strip():
                raise ValueError("ë¦¬ë² ì´ìŠ¤ ëŒ€ìƒì€ í•„ìˆ˜ì…ë‹ˆë‹¤")
            
            if branch and branch == onto:
                raise ValueError("ë¦¬ë² ì´ìŠ¤ ëŒ€ìƒê³¼ ë¸Œëœì¹˜ê°€ ë™ì¼í•©ë‹ˆë‹¤")
            
            # TerminusDB ì‹¤ì œ ë¦¬ë² ì´ìŠ¤ API: POST /api/db/<account>/<db>/_rebase
            endpoint = f"/api/db/{self.connection_info.account}/{db_name}/_rebase"
            
            # ë¦¬ë² ì´ìŠ¤ ìš”ì²­ ë°ì´í„°
            data = {
                "onto": onto
            }
            if branch:
                data["branch"] = branch
            
            # TerminusDBì— ì‹¤ì œ ë¦¬ë² ì´ìŠ¤ ìš”ì²­
            result = await self._make_request("POST", endpoint, data)
            
            # ë¦¬ë² ì´ìŠ¤ ê²°ê³¼ ì •ê·œí™”
            rebase_result = {
                "success": result.get("success", True),
                "branch": branch or result.get("branch", "current"),
                "onto": onto,
                "commit_id": result.get("commit_id", result.get("id"))
            }
            
            logger.info(f"TerminusDB rebase completed: {branch or 'current'} onto {onto}")
            return rebase_result
            
        except Exception as e:
            logger.error(f"TerminusDB rebase API failed: {e}")
            raise ValueError(f"ë¦¬ë² ì´ìŠ¤ ì‹¤íŒ¨: {e}")
    
    def _convert_to_woql(self, query_dict: Dict[str, Any]) -> Dict[str, Any]:
        """ì¿¼ë¦¬ ë”•ì…”ë„ˆë¦¬ë¥¼ WOQL í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        class_id = query_dict.get("class_id")
        filters = query_dict.get("filters", [])
        select_fields = query_dict.get("select", [])
        limit = query_dict.get("limit")
        offset = query_dict.get("offset", 0)
        
        # WOQL ì¿¼ë¦¬ ê¸°ë³¸ êµ¬ì¡°
        and_clauses = []
        
        # í´ë˜ìŠ¤ íƒ€ì… ì¡°ê±´
        if class_id:
            and_clauses.append({
                "@type": "Triple",
                "subject": {"@type": "NodeValue", "variable": "ID"},
                "predicate": {"@type": "NodeValue", "node": "http://www.w3.org/1999/02/22-rdf-syntax-ns#type"},
                "object": {"@type": "Value", "node": f"http://www.w3.org/2002/07/owl#{class_id}"}
            })
        
        # í•„í„° ì¡°ê±´ë“¤ ì¶”ê°€
        for filter_item in filters:
            field = filter_item.get("field")
            operator = filter_item.get("operator")
            value = filter_item.get("value")
            
            if operator == "=":
                and_clauses.append({
                    "@type": "Triple",
                    "subject": {"@type": "NodeValue", "variable": "ID"},
                    "predicate": {"@type": "NodeValue", "node": field},
                    "object": {"@type": "Value", "data": {"@type": "xsd:string", "@value": value}}
                })
            elif operator == ">":
                and_clauses.append({
                    "@type": "Greater",
                    "left": {
                        "@type": "Triple",
                        "subject": {"@type": "NodeValue", "variable": "ID"},
                        "predicate": {"@type": "NodeValue", "node": field},
                        "object": {"@type": "Value", "variable": f"{field}_val"}
                    },
                    "right": {"@type": "Value", "data": {"@type": "xsd:string", "@value": value}}
                })
        
        # SELECT í•„ë“œ ì¶”ê°€
        if select_fields:
            for field in select_fields:
                and_clauses.append({
                    "@type": "Triple",
                    "subject": {"@type": "NodeValue", "variable": "ID"},
                    "predicate": {"@type": "NodeValue", "node": field},
                    "object": {"@type": "Value", "variable": field}
                })
        
        # ê¸°ë³¸ ì¿¼ë¦¬ êµ¬ì¡°
        woql_query = {
            "@type": "And",
            "and": and_clauses
        }
        
        # LIMIT ë° OFFSET ì¶”ê°€
        if limit:
            woql_query = {
                "@type": "Limit",
                "limit": limit,
                "query": woql_query
            }
        
        if offset > 0:
            woql_query = {
                "@type": "Start",
                "start": offset,
                "query": woql_query
            }
        
        return woql_query
    
    async def query_database(self, db_name: str, query: Dict[str, Any]) -> Dict[str, Any]:
        """WOQL ì¿¼ë¦¬ ì‹¤í–‰"""
        await self.ensure_db_exists(db_name)
        
        # TerminusDB WOQL ì—”ë“œí¬ì¸íŠ¸
        endpoint = f"/api/woql/{self.connection_info.account}/{db_name}"
        
        # ì¿¼ë¦¬ë¥¼ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ë˜í•‘
        woql_request = {
            "query": query,
            "author": self.connection_info.user,
            "message": "Creating ontology class"
        }
        
        try:
            result = await self._make_request("POST", endpoint, woql_request)
            return result
            
        except Exception as e:
            logger.error(f"WOQL ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise AsyncDatabaseError(f"WOQL ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
    
    async def create_ontology_class(self, db_name: str, class_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ìƒì„± (Document API ì‚¬ìš©)"""
        class_id = class_data.get("id")
        if not class_id:
            raise AsyncValidationError("í´ë˜ìŠ¤ IDê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ìŠ¤í‚¤ë§ˆ ë¬¸ì„œ ìƒì„±
        schema_doc = {
            "@type": "Class",
            "@id": class_id
        }
        
        # ì†ì„± ì¶”ê°€
        if "properties" in class_data:
            for prop in class_data["properties"]:
                prop_name = prop.get("name")
                prop_type = prop.get("type", "xsd:string")
                if prop_name:
                    # ğŸ”¥ THINK ULTRA! ë³µí•© íƒ€ì…ì„ ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ TerminusDBê°€ ì´í•´í•  ìˆ˜ ìˆê²Œ í•¨
                    if DataType.is_complex_type(prop_type):
                        base_type = DataType.get_base_type(prop_type)
                        schema_doc[prop_name] = base_type
                        logger.info(f"ğŸ”¥ CONVERTED: {prop_type} -> {base_type} for {prop_name}")
                        print(f"ğŸ”¥ DEBUG: Converted complex type {prop_type} to base type {base_type} for property {prop_name}")
                    else:
                        schema_doc[prop_name] = prop_type
        
        # ê¸°ë³¸ ì†ì„± ì¶”ê°€ (optionalë¡œ ì„¤ì •)
        if "label" in class_data:
            schema_doc["rdfs:label"] = {"@type": "Optional", "@class": "xsd:string"}
        if "description" in class_data:
            schema_doc["rdfs:comment"] = {"@type": "Optional", "@class": "xsd:string"}
        
        # Document APIë¥¼ í†µí•œ ìŠ¤í‚¤ë§ˆ ìƒì„±
        endpoint = f"/api/document/{self.connection_info.account}/{db_name}"
        params = {
            "graph_type": "schema",
            "author": self.connection_info.user,
            "message": f"Creating {class_id} schema"
        }
        
        try:
            # ğŸ”¥ THINK ULTRA! ë””ë²„ê¹…: TerminusDBì— ë³´ë‚´ëŠ” ìŠ¤í‚¤ë§ˆ ë¬¸ì„œ ë¡œê¹…
            logger.info(f"Sending schema document to TerminusDB: {schema_doc}")
            print(f"ğŸ”¥ FINAL DOCUMENT TO TERMINUSDB: {json.dumps(schema_doc, indent=2)}")
            result = await self._make_request("POST", endpoint, [schema_doc], params)
            # ì‹¤ì œ TerminusDB ì‘ë‹µì„ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return result
            
        except Exception as e:
            logger.error(f"ìŠ¤í‚¤ë§ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            raise AsyncDatabaseError(f"ìŠ¤í‚¤ë§ˆ ìƒì„± ì‹¤íŒ¨: {e}")
    
    async def list_ontology_classes(self, db_name: str) -> List[Dict[str, Any]]:
        """ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ëª©ë¡ ì¡°íšŒ (Document API ì‚¬ìš©)"""
        endpoint = f"/api/document/{self.connection_info.account}/{db_name}"
        params = {
            "graph_type": "schema"
        }
        
        try:
            # íŠ¹ë³„í•œ ì²˜ë¦¬: TerminusDBëŠ” JSON Lines í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ
            client = await self._get_client()
            token = await self._authenticate()
            
            headers = {
                "Authorization": token
            }
            
            response = await client.request(
                method="GET",
                url=endpoint,
                params=params,
                headers=headers
            )
            response.raise_for_status()
            
            # JSON Lines í˜•ì‹ íŒŒì‹±
            classes = []
            response_text = response.text.strip()
            
            if response_text:
                for line in response_text.split('\n'):
                    try:
                        doc = json.loads(line)
                        if doc.get("@type") == "Class":
                            classes.append({
                                "id": doc.get("@id"),
                                "type": "Class",
                                "properties": {k: v for k, v in doc.items() if k not in ["@type", "@id"]}
                            })
                    except json.JSONDecodeError:
                        # ì»¨í…ìŠ¤íŠ¸ ì¤„ ë“±ì€ ë¬´ì‹œ
                        continue
            
            return classes
            
        except Exception as e:
            logger.error(f"í´ë˜ìŠ¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise AsyncDatabaseError(f"í´ë˜ìŠ¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    async def create_document(self, db_name: str, document_data: Dict[str, Any]) -> Dict[str, Any]:
        """ë¬¸ì„œ ìƒì„±"""
        doc_type = document_data.get("@type")
        if not doc_type:
            raise AsyncValidationError("ë¬¸ì„œ íƒ€ì…ì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ID í”„ë¦¬í”½ìŠ¤ í™•ì¸ ë° ìˆ˜ì •
        doc_id = document_data.get("@id")
        if doc_id and not doc_id.startswith(f"{doc_type}/"):
            document_data["@id"] = f"{doc_type}/{doc_id}"
        
        # Document APIë¥¼ í†µí•œ ë¬¸ì„œ ìƒì„±
        endpoint = f"/api/document/{self.connection_info.account}/{db_name}"
        params = {
            "author": self.connection_info.user,
            "message": f"Creating {doc_type} document"
        }
        
        try:
            result = await self._make_request("POST", endpoint, [document_data], params)
            # ì‹¤ì œ TerminusDB ì‘ë‹µì„ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return result
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            raise AsyncDatabaseError(f"ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
    
    async def list_documents(self, db_name: str, doc_type: Optional[str] = None) -> List[Dict[str, Any]]:
        """ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ"""
        endpoint = f"/api/document/{self.connection_info.account}/{db_name}"
        params = {}
        
        if doc_type:
            params["type"] = doc_type
        
        try:
            result = await self._make_request("GET", endpoint, None, params)
            
            documents = []
            if isinstance(result, list):
                for doc in result:
                    documents.append(doc)
            
            return documents
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise AsyncDatabaseError(f"ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    # ğŸ”¥ THINK ULTRA! Enhanced Relationship Management Methods
    
    async def create_ontology_with_advanced_relationships(
        self, 
        db_name: str, 
        ontology_data: Dict[str, Any],
        auto_generate_inverse: bool = True,
        validate_relationships: bool = True,
        check_circular_references: bool = True
    ) -> Dict[str, Any]:
        """
        ê³ ê¸‰ ê´€ê³„ ê´€ë¦¬ ê¸°ëŠ¥ì„ í¬í•¨í•œ ì˜¨í†¨ë¡œì§€ ìƒì„±
        
        Args:
            db_name: ë°ì´í„°ë² ì´ìŠ¤ ëª…
            ontology_data: ì˜¨í†¨ë¡œì§€ ë°ì´í„°
            auto_generate_inverse: ìë™ ì—­ê´€ê³„ ìƒì„± ì—¬ë¶€
            validate_relationships: ê´€ê³„ ê²€ì¦ ì—¬ë¶€
            check_circular_references: ìˆœí™˜ ì°¸ì¡° ì²´í¬ ì—¬ë¶€
        """
        logger.info(f"ğŸ”¥ Creating ontology with advanced relationship management: {ontology_data.get('id', 'unknown')}")
        
        # 1. ê¸°ë³¸ ì˜¨í†¨ë¡œì§€ ê²€ì¦
        ontology = OntologyBase(**ontology_data)
        
        # 2. ê´€ê³„ ê²€ì¦
        validation_results = []
        if validate_relationships:
            validation_results = self.relationship_validator.validate_ontology_relationships(ontology)
            
            # ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ìƒì„± ì¤‘ë‹¨
            critical_errors = [r for r in validation_results if r.severity == ValidationSeverity.ERROR]
            if critical_errors:
                error_messages = [r.message for r in critical_errors]
                raise AsyncValidationError(f"ê´€ê³„ ê²€ì¦ ì‹¤íŒ¨: {', '.join(error_messages)}")
        
        # 3. ìˆœí™˜ ì°¸ì¡° ì²´í¬
        cycle_info = []
        if check_circular_references:
            # ê¸°ì¡´ ì˜¨í†¨ë¡œì§€ë“¤ê³¼ í•¨ê»˜ ìˆœí™˜ ì°¸ì¡° ê²€ì‚¬
            existing_ontologies = await self._get_cached_ontologies(db_name)
            test_ontologies = existing_ontologies + [ontology]
            
            self.circular_detector.build_relationship_graph(test_ontologies)
            cycle_info = self.circular_detector.detect_all_cycles()
            
            # ì¹˜ëª…ì ì¸ ìˆœí™˜ ì°¸ì¡°ê°€ ìˆìœ¼ë©´ ìƒì„± ì¤‘ë‹¨
            critical_cycles = [c for c in cycle_info if c.severity == "critical"]
            if critical_cycles:
                cycle_messages = [c.message for c in critical_cycles]
                raise AsyncValidationError(f"ì¹˜ëª…ì ì¸ ìˆœí™˜ ì°¸ì¡° ê°ì§€: {', '.join(cycle_messages)}")
        
        # 4. ìë™ ì—­ê´€ê³„ ìƒì„±
        enhanced_relationships = []
        if auto_generate_inverse:
            for rel in ontology.relationships:
                forward_rel, inverse_rel = self.relationship_manager.create_bidirectional_relationship(
                    source_class=ontology.id,
                    relationship=rel,
                    auto_generate_inverse=True
                )
                
                enhanced_relationships.append(forward_rel)
                if inverse_rel:
                    # ì—­ê´€ê³„ëŠ” ë³„ë„ ì˜¨í†¨ë¡œì§€ë¡œ ì €ì¥í•˜ê±°ë‚˜ ê´€ë ¨ ì˜¨í†¨ë¡œì§€ì— ì¶”ê°€
                    # ì—¬ê¸°ì„œëŠ” ë©”íƒ€ë°ì´í„°ì— ì €ì¥
                    if "inverse_relationships" not in ontology_data:
                        ontology_data["inverse_relationships"] = []
                    ontology_data["inverse_relationships"].append({
                        "target_class": inverse_rel.target,
                        "relationship": inverse_rel.dict()
                    })
        else:
            enhanced_relationships = ontology.relationships
        
        # 5. ê°œì„ ëœ ì˜¨í†¨ë¡œì§€ ë°ì´í„° ì¤€ë¹„
        enhanced_data = ontology_data.copy()
        enhanced_data["relationships"] = [rel.dict() for rel in enhanced_relationships]
        
        # ê²€ì¦ ë° ìˆœí™˜ ì°¸ì¡° ì •ë³´ë¥¼ ë©”íƒ€ë°ì´í„°ì— ì¶”ê°€
        if "metadata" not in enhanced_data:
            enhanced_data["metadata"] = {}
        
        # ë©”íƒ€ë°ì´í„°ê°€ Noneì¸ ê²½ìš° ì²˜ë¦¬
        if enhanced_data["metadata"] is None:
            enhanced_data["metadata"] = {}
            
        enhanced_data["metadata"].update({
            "relationship_validation": {
                "validated": validate_relationships,
                "validation_results": len(validation_results),
                "warnings": len([r for r in validation_results if r.severity == ValidationSeverity.WARNING]),
                "info": len([r for r in validation_results if r.severity == ValidationSeverity.INFO])
            },
            "circular_reference_check": {
                "checked": check_circular_references,
                "cycles_detected": len(cycle_info),
                "critical_cycles": len([c for c in cycle_info if c.severity == "critical"])
            },
            "auto_inverse_generated": auto_generate_inverse,
            "enhanced_at": datetime.utcnow().isoformat()
        })
        
        # 6. ì‹¤ì œ ì˜¨í†¨ë¡œì§€ ìƒì„±
        try:
            result = await self.create_ontology_class(db_name, enhanced_data)
            
            # ìºì‹œ ë¬´íš¨í™”
            if db_name in self._ontology_cache:
                del self._ontology_cache[db_name]
            
            # ê´€ê³„ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸
            await self._update_relationship_graphs(db_name)
            
            logger.info(f"âœ… Successfully created ontology with enhanced relationships: {ontology.id}")
            
            # resultê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬
            if isinstance(result, list):
                # TerminusDBê°€ ì‘ë‹µì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ëŠ” ê²½ìš°ê°€ ìˆìŒ
                result_data = {
                    "id": enhanced_data.get("id"),
                    "created": True,
                    "response": result
                }
            elif isinstance(result, dict):
                result_data = result
            else:
                result_data = {
                    "id": enhanced_data.get("id"),
                    "created": True
                }
            
            return {
                **result_data,
                "relationship_enhancements": {
                    "validation_results": validation_results,
                    "cycle_info": cycle_info,
                    "inverse_relationships_generated": auto_generate_inverse
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ Failed to create enhanced ontology: {e}")
            raise
    
    async def validate_relationships(self, db_name: str, ontology_data: Dict[str, Any]) -> Dict[str, Any]:
        """ê´€ê³„ ê²€ì¦ ì „ìš© ë©”ì„œë“œ"""
        
        ontology = OntologyBase(**ontology_data)
        
        # ê¸°ì¡´ ì˜¨í†¨ë¡œì§€ë“¤ ì¡°íšŒ
        existing_ontologies = await self._get_cached_ontologies(db_name)
        self.relationship_validator.existing_ontologies = existing_ontologies
        
        # ê²€ì¦ ì‹¤í–‰
        validation_results = self.relationship_validator.validate_ontology_relationships(ontology)
        
        # ê²€ì¦ ìš”ì•½
        summary = self.relationship_validator.get_validation_summary(validation_results)
        
        return {
            "validation_summary": summary,
            "validation_results": [
                {
                    "severity": r.severity.value,
                    "code": r.code,
                    "message": r.message,
                    "field": r.field,
                    "related_objects": r.related_objects
                }
                for r in validation_results
            ]
        }
    
    async def detect_circular_references(self, db_name: str, include_new_ontology: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ìˆœí™˜ ì°¸ì¡° íƒì§€ ì „ìš© ë©”ì„œë“œ"""
        
        # ê¸°ì¡´ ì˜¨í†¨ë¡œì§€ë“¤ ì¡°íšŒ
        existing_ontologies = await self._get_cached_ontologies(db_name)
        
        # ìƒˆ ì˜¨í†¨ë¡œì§€ê°€ ìˆìœ¼ë©´ í¬í•¨
        test_ontologies = existing_ontologies[:]
        if include_new_ontology:
            new_ontology = OntologyBase(**include_new_ontology)
            test_ontologies.append(new_ontology)
        
        # ìˆœí™˜ ì°¸ì¡° íƒì§€
        self.circular_detector.build_relationship_graph(test_ontologies)
        cycles = self.circular_detector.detect_all_cycles()
        
        # ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
        report = self.circular_detector.get_cycle_analysis_report(cycles)
        
        return {
            "cycle_analysis_report": report,
            "detected_cycles": [
                {
                    "type": c.cycle_type.value,
                    "path": c.path,
                    "predicates": c.predicates,
                    "length": c.length,
                    "severity": c.severity,
                    "message": c.message,
                    "can_break": c.can_break,
                    "resolution_suggestions": self.circular_detector.suggest_cycle_resolution(c)
                }
                for c in cycles
            ]
        }
    
    async def find_relationship_paths(self, db_name: str, start_entity: str, end_entity: Optional[str] = None, **query_params) -> Dict[str, Any]:
        """ê´€ê³„ ê²½ë¡œ íƒìƒ‰"""
        
        # ê´€ê³„ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸
        await self._update_relationship_graphs(db_name)
        
        # path_typeì„ PathType enumìœ¼ë¡œ ë³€í™˜
        if 'path_type' in query_params:
            path_type_str = query_params.pop('path_type')
            try:
                query_params['path_type'] = PathType(path_type_str)
            except ValueError:
                # ì˜ëª»ëœ path_typeì¸ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
                query_params['path_type'] = PathType.SHORTEST
        
        # ê²½ë¡œ ì¿¼ë¦¬ ìƒì„±
        query = PathQuery(
            start_entity=start_entity,
            end_entity=end_entity,
            **query_params
        )
        
        # ê²½ë¡œ íƒìƒ‰
        paths = self.path_tracker.find_paths(query)
        
        # í†µê³„ ì •ë³´
        statistics = self.path_tracker.get_path_statistics(paths)
        
        return {
            "query": {
                "start_entity": start_entity,
                "end_entity": end_entity,
                "parameters": query_params
            },
            "paths": [
                {
                    "start_entity": p.start_entity,
                    "end_entity": p.end_entity,
                    "entities": p.entities,
                    "predicates": p.predicates,
                    "length": p.length,
                    "total_weight": p.total_weight,
                    "path_type": p.path_type.value if hasattr(p.path_type, 'value') else p.path_type,
                    "semantic_score": p.semantic_score,
                    "confidence": p.confidence,
                    "readable_path": p.to_readable_string()
                }
                for p in paths
            ],
            "statistics": statistics
        }
    
    async def get_reachable_entities(self, db_name: str, start_entity: str, max_depth: int = 3) -> Dict[str, Any]:
        """ì‹œì‘ ì—”í‹°í‹°ì—ì„œ ë„ë‹¬ ê°€ëŠ¥í•œ ëª¨ë“  ì—”í‹°í‹° ì¡°íšŒ"""
        
        await self._update_relationship_graphs(db_name)
        
        reachable = self.path_tracker.find_all_reachable_entities(start_entity, max_depth)
        
        return {
            "start_entity": start_entity,
            "max_depth": max_depth,
            "reachable_entities": {
                entity: {
                    "path": path.entities,
                    "predicates": path.predicates,
                    "distance": path.length,
                    "weight": path.total_weight
                }
                for entity, path in reachable.items()
            },
            "total_reachable": len(reachable)
        }
    
    async def analyze_relationship_network(self, db_name: str) -> Dict[str, Any]:
        """ê´€ê³„ ë„¤íŠ¸ì›Œí¬ ì¢…í•© ë¶„ì„"""
        
        logger.info(f"ğŸ”¥ Analyzing relationship network for database: {db_name}")
        
        # ì˜¨í†¨ë¡œì§€ë“¤ ì¡°íšŒ
        ontologies = await self._get_cached_ontologies(db_name)
        
        if not ontologies:
            return {"message": "No ontologies found in database"}
        
        # 1. ê´€ê³„ ê²€ì¦
        all_validation_results = []
        for ontology in ontologies:
            results = self.relationship_validator.validate_ontology_relationships(ontology)
            all_validation_results.extend(results)
        
        validation_summary = self.relationship_validator.get_validation_summary(all_validation_results)
        
        # 2. ìˆœí™˜ ì°¸ì¡° ë¶„ì„
        self.circular_detector.build_relationship_graph(ontologies)
        cycles = self.circular_detector.detect_all_cycles()
        cycle_report = self.circular_detector.get_cycle_analysis_report(cycles)
        
        # 3. ê²½ë¡œ ì¶”ì  ê·¸ë˜í”„ êµ¬ì¶•
        self.path_tracker.build_graph(ontologies)
        graph_summary = self.path_tracker.export_graph_summary()
        
        # 4. ê´€ê³„ í†µê³„
        all_relationships = []
        for ontology in ontologies:
            all_relationships.extend(ontology.relationships)
        
        relationship_summary = self.relationship_manager.generate_relationship_summary(all_relationships)
        
        return {
            "database": db_name,
            "analysis_timestamp": datetime.utcnow().isoformat(),
            "ontology_count": len(ontologies),
            "relationship_summary": relationship_summary,
            "validation_summary": validation_summary,
            "cycle_analysis": cycle_report,
            "graph_summary": graph_summary,
            "recommendations": self._generate_network_recommendations(
                validation_summary, cycle_report, relationship_summary
            )
        }
    
    async def _get_cached_ontologies(self, db_name: str) -> List[OntologyBase]:
        """ìºì‹œëœ ì˜¨í†¨ë¡œì§€ ì¡°íšŒ (ì„±ëŠ¥ ìµœì í™”)"""
        
        if db_name not in self._ontology_cache:
            # ì˜¨í†¨ë¡œì§€ë“¤ì„ ì‹¤ì œë¡œ ì¡°íšŒí•˜ì—¬ ìºì‹œ
            ontology_dicts = await self.list_ontologies(db_name)
            ontologies = []
            
            for onto_dict in ontology_dicts:
                try:
                    # í•„ìš”í•œ í•„ë“œë“¤ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ê¸°ë³¸ê°’ ì„¤ì •
                    if "id" not in onto_dict:
                        continue
                    
                    onto_dict.setdefault("label", onto_dict["id"])
                    onto_dict.setdefault("properties", [])
                    onto_dict.setdefault("relationships", [])
                    
                    ontology = OntologyBase(**onto_dict)
                    ontologies.append(ontology)
                except Exception as e:
                    logger.warning(f"Failed to parse ontology {onto_dict.get('id', 'unknown')}: {e}")
                    continue
            
            self._ontology_cache[db_name] = ontologies
        
        return self._ontology_cache[db_name]
    
    async def _update_relationship_graphs(self, db_name: str) -> None:
        """ê´€ê³„ ê·¸ë˜í”„ë“¤ ì—…ë°ì´íŠ¸"""
        
        ontologies = await self._get_cached_ontologies(db_name)
        
        # ëª¨ë“  ê´€ê³„ ê´€ë¦¬ ì»´í¬ë„ŒíŠ¸ì˜ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸
        self.circular_detector.build_relationship_graph(ontologies)
        self.path_tracker.build_graph(ontologies)
        
        # ê²€ì¦ê¸°ì— ê¸°ì¡´ ì˜¨í†¨ë¡œì§€ ì •ë³´ ì œê³µ
        self.relationship_validator.existing_ontologies = ontologies
    
    def _generate_network_recommendations(
        self, 
        validation_summary: Dict[str, Any], 
        cycle_report: Dict[str, Any], 
        relationship_summary: Dict[str, Any]
    ) -> List[str]:
        """ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        
        recommendations = []
        
        # ê²€ì¦ ê´€ë ¨ ê¶Œì¥ì‚¬í•­
        if validation_summary.get("errors", 0) > 0:
            recommendations.append(f"âŒ {validation_summary['errors']}ê°œì˜ ê´€ê³„ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”")
        
        if validation_summary.get("warnings", 0) > 5:
            recommendations.append(f"âš ï¸ {validation_summary['warnings']}ê°œì˜ ê´€ê³„ ê²½ê³ ë¥¼ ê²€í† í•˜ì„¸ìš”")
        
        # ìˆœí™˜ ì°¸ì¡° ê´€ë ¨ ê¶Œì¥ì‚¬í•­
        if cycle_report.get("critical_cycles", 0) > 0:
            recommendations.append(f"ğŸ”„ {cycle_report['critical_cycles']}ê°œì˜ ì¹˜ëª…ì ì¸ ìˆœí™˜ ì°¸ì¡°ë¥¼ í•´ê²°í•˜ì„¸ìš”")
        
        if cycle_report.get("total_cycles", 0) > 10:
            recommendations.append("ğŸ—ï¸ ë³µì¡í•œ ìˆœí™˜ êµ¬ì¡°ë¥¼ ë‹¨ìˆœí™”í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”")
        
        # ê´€ê³„ ê´€ë ¨ ê¶Œì¥ì‚¬í•­
        total_relationships = relationship_summary.get("total_relationships", 0)
        if total_relationships == 0:
            recommendations.append("ğŸ“ ì˜¨í†¨ë¡œì§€ ê°„ ê´€ê³„ë¥¼ ì •ì˜í•˜ì—¬ ì˜ë¯¸ì  ì—°ê²°ì„ ê°•í™”í•˜ì„¸ìš”")
        elif total_relationships > 50:
            recommendations.append("ğŸ“Š ê´€ê³„ê°€ ë§ìŠµë‹ˆë‹¤. ëª¨ë“ˆí™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”")
        
        # ì—­ê´€ê³„ ì»¤ë²„ë¦¬ì§€
        inverse_coverage = relationship_summary.get("inverse_coverage", "0/0 (0%)")
        coverage_percent = float(inverse_coverage.split("(")[1].split("%")[0]) if "(" in inverse_coverage else 0
        if coverage_percent < 50:
            recommendations.append("â†”ï¸ ì—­ê´€ê³„ ì •ì˜ë¥¼ ëŠ˜ë ¤ ì–‘ë°©í–¥ íƒìƒ‰ì„ ê°œì„ í•˜ì„¸ìš”")
        
        if not recommendations:
            recommendations.append("âœ… ê´€ê³„ ë„¤íŠ¸ì›Œí¬ê°€ ê±´ê°•í•œ ìƒíƒœì…ë‹ˆë‹¤")
        
        return recommendations

    async def __aenter__(self):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        await self.disconnect()