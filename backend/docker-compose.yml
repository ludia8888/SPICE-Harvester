version: '3.8'

services:
  # PostgreSQL - 표준화된 인증 정보
  postgres:
    image: postgres:16-alpine
    container_name: spice_postgres
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-spiceadmin}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-spicepass123}
      - POSTGRES_DB=${POSTGRES_DB:-spicedb}
    ports:
      - "${POSTGRES_PORT_HOST:-5433}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init:/docker-entrypoint-initdb.d
    networks:
      - spice_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-spiceadmin} -d ${POSTGRES_DB:-spicedb}"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Redis - 표준화된 인증 정보
  redis:
    image: redis:7-alpine
    container_name: spice_redis
    command: redis-server --requirepass ${REDIS_PASSWORD:-spicepass123}
    ports:
      - "${REDIS_PORT_HOST:-6379}:6379"
    volumes:
      - redis_data:/data
    networks:
      - spice_network
    healthcheck:
      test: ["CMD-SHELL", "redis-cli -a ${REDIS_PASSWORD:-spicepass123} ping || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Elasticsearch - 표준화된 인증 정보
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.0
    container_name: spice_elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - xpack.security.http.ssl.enabled=false
      - xpack.security.transport.ssl.enabled=false
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - http.host=0.0.0.0
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "${ELASTICSEARCH_PORT_HOST:-9200}:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - spice_network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Kafka
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: spice_kafka
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    ports:
      - "${KAFKA_PORT_HOST:-9092}:9092"
    depends_on:
      - zookeeper
    networks:
      - spice_network
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: spice_zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "${ZOOKEEPER_PORT_HOST:-2181}:2181"
    networks:
      - spice_network
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 30s
      timeout: 10s
      retries: 5

  # MinIO - 표준화된 인증 정보
  minio:
    image: minio/minio:latest
    container_name: spice_minio
    environment:
      - MINIO_ROOT_USER=${MINIO_ACCESS_KEY:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_SECRET_KEY:-minioadmin123}
    ports:
      - "${MINIO_PORT_HOST:-9000}:9000"
      - "${MINIO_CONSOLE_PORT_HOST:-9001}:9001"
    volumes:
      - minio_data:/data
    networks:
      - spice_network
    command: server /data --console-address ":9001"
    healthcheck:
      # MinIO image doesn't ship with curl; use bash TCP check.
      test: ["CMD-SHELL", "bash -c 'echo > /dev/tcp/127.0.0.1/9000'"]
      interval: 30s
      timeout: 10s
      retries: 5

  # TerminusDB - 표준화된 인증 정보
  terminusdb:
    image: terminusdb/terminusdb-server:latest
    container_name: spice_terminusdb
    environment:
      - TERMINUSDB_ADMIN_PASS=${TERMINUS_KEY:-admin}
      - TERMINUSDB_SERVER_NAME=SpiceTerminusDB
      - TERMINUSDB_AUTOLOGIN=false
    ports:
      - "6363:6363"
    volumes:
      - terminusdb_data:/app/terminusdb/storage
    networks:
      - spice_network
    healthcheck:
      # terminusdb-server image doesn't ship with curl; use bash TCP check.
      test: ["CMD-SHELL", "bash -c 'echo > /dev/tcp/127.0.0.1/6363'"]
      interval: 30s
      timeout: 10s
      retries: 5

  # OMS (Ontology Management Service) - 표준화된 인증 정보
  oms:
    build:
      context: .
      dockerfile: ./oms/Dockerfile
    container_name: spice_oms
    environment:
      # TerminusDB
      - TERMINUS_SERVER_URL=http://terminusdb:6363
      - TERMINUS_USER=admin
      - TERMINUS_ACCOUNT=admin
      - TERMINUS_KEY=${TERMINUS_KEY:-admin}
      # PostgreSQL
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-spiceadmin}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-spicepass123}
      - POSTGRES_DB=${POSTGRES_DB:-spicedb}
      # Kafka
      - KAFKA_HOST=kafka
      - KAFKA_PORT=29092
      # Redis
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD:-spicepass123}
      # Elasticsearch
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
      - ELASTICSEARCH_USERNAME=${ELASTICSEARCH_USERNAME:-}
      - ELASTICSEARCH_PASSWORD=${ELASTICSEARCH_PASSWORD:-}
      # Event Store (S3/MinIO)
      - MINIO_ENDPOINT_URL=http://minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY:-minioadmin123}
      - EVENT_STORE_BUCKET=${EVENT_STORE_BUCKET:-spice-event-store}
      # Service
      - LOG_LEVEL=INFO
      - DOCKER_CONTAINER=true
      - OMS_REQUIRE_AUTH=${OMS_REQUIRE_AUTH:-true}
      - ADMIN_TOKEN=${ADMIN_TOKEN:?ADMIN_TOKEN is required}
    ports:
      - "8000:8000"
    depends_on:
      - terminusdb
      - postgres
      - redis
      - elasticsearch
    networks:
      - spice_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # BFF
  bff:
    build:
      context: .
      dockerfile: ./bff/Dockerfile
    container_name: spice_bff
    environment:
      - OMS_BASE_URL=http://oms:8000
      - FUNNEL_BASE_URL=http://funnel:8003
      # Infra (needed for WebSocket notifications / search / rate limiting)
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-spiceadmin}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-spicepass123}
      - POSTGRES_DB=${POSTGRES_DB:-spicedb}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD:-spicepass123}
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
      - ELASTICSEARCH_USERNAME=${ELASTICSEARCH_USERNAME:-}
      - ELASTICSEARCH_PASSWORD=${ELASTICSEARCH_PASSWORD:-}
      - KAFKA_HOST=kafka
      - KAFKA_PORT=29092
      - LOG_LEVEL=INFO
      - DOCKER_CONTAINER=true
      - BFF_REQUIRE_AUTH=${BFF_REQUIRE_AUTH:-true}
      - ADMIN_TOKEN=${ADMIN_TOKEN:?ADMIN_TOKEN is required}
    ports:
      - "8002:8002"
    depends_on:
      - oms
      - funnel
    networks:
      - spice_network
    volumes:
      - bff_data:/app/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Connector Trigger Service (Foundry-style; polls + emits connector-updates)
  connector-trigger-service:
    build:
      context: .
      dockerfile: ./connector_trigger_service/Dockerfile
    container_name: spice_connector_trigger_service
    environment:
      - KAFKA_HOST=kafka
      - KAFKA_PORT=29092
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-spiceadmin}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-spicepass123}
      - POSTGRES_DB=${POSTGRES_DB:-spicedb}
      - LOG_LEVEL=INFO
      - DOCKER_CONTAINER=true
      - CONNECTOR_UPDATES_TOPIC=connector-updates
      - CONNECTOR_TRIGGER_SOURCE_TYPE=google_sheets
      - CONNECTOR_TRIGGER_TICK_SECONDS=5
      - CONNECTOR_TRIGGER_POLL_CONCURRENCY=5
      # Optional (public sheets work without it)
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-}
    depends_on:
      - kafka
      - postgres
    networks:
      - spice_network
    restart: unless-stopped

  # Connector Sync Worker (Foundry-style; consumes connector-updates and submits writes)
  connector-sync-worker:
    build:
      context: .
      dockerfile: ./connector_sync_worker/Dockerfile
    container_name: spice_connector_sync_worker
    environment:
      - KAFKA_HOST=kafka
      - KAFKA_PORT=29092
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-spiceadmin}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-spicepass123}
      - POSTGRES_DB=${POSTGRES_DB:-spicedb}
      # IMPORTANT: override ServiceConfig default (127.0.0.1) in Docker
      - BFF_BASE_URL=http://bff:8002
      - ADMIN_TOKEN=${ADMIN_TOKEN:?ADMIN_TOKEN is required}
      - LOG_LEVEL=INFO
      - DOCKER_CONTAINER=true
      - CONNECTOR_UPDATES_TOPIC=connector-updates
      - CONNECTOR_UPDATES_DLQ_TOPIC=connector-updates-dlq
      # Optional (public sheets work without it)
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-}
    depends_on:
      - bff
      - kafka
      - postgres
    networks:
      - spice_network
    restart: unless-stopped

  # Funnel
  funnel:
    build:
      context: .
      dockerfile: ./funnel/Dockerfile
    container_name: spice_funnel
    environment:
      # Infra (rate limiting)
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD:-spicepass123}
      - LOG_LEVEL=INFO
      - DOCKER_CONTAINER=true
    ports:
      - "8003:8003"
    networks:
      - spice_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Message Relay - 표준화된 인증 정보
  message-relay:
    build:
      context: .
      dockerfile: ./message_relay/Dockerfile
    container_name: spice_message_relay
    environment:
      - KAFKA_HOST=kafka
      - KAFKA_PORT=29092
      - MINIO_ENDPOINT_URL=http://minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY:-minioadmin123}
      - EVENT_STORE_BUCKET=${EVENT_STORE_BUCKET:-spice-event-store}
      - EVENT_PUBLISHER_BATCH_SIZE=${EVENT_PUBLISHER_BATCH_SIZE:-200}
      - EVENT_PUBLISHER_POLL_INTERVAL=${EVENT_PUBLISHER_POLL_INTERVAL:-3}
      - LOG_LEVEL=INFO
      - DOCKER_CONTAINER=true
    depends_on:
      - kafka
    networks:
      - spice_network
    restart: unless-stopped

  # Ontology Worker - 표준화된 인증 정보
  ontology-worker:
    build:
      context: .
      dockerfile: ./ontology_worker/Dockerfile
    container_name: spice_ontology_worker
    environment:
      - KAFKA_HOST=kafka
      - KAFKA_PORT=29092
      - TERMINUS_SERVER_URL=http://terminusdb:6363
      - TERMINUS_USER=admin
      - TERMINUS_ACCOUNT=admin
      - TERMINUS_KEY=${TERMINUS_KEY:-admin}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-spiceadmin}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-spicepass123}
      - POSTGRES_DB=${POSTGRES_DB:-spicedb}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD:-spicepass123}
      - LOG_LEVEL=INFO
      - DOCKER_CONTAINER=true
    depends_on:
      - terminusdb
      - kafka
      - redis
    networks:
      - spice_network
    restart: unless-stopped

  # Instance Worker - 표준화된 인증 정보
  instance-worker:
    build:
      context: .
      dockerfile: ./instance_worker/Dockerfile
    container_name: spice_instance_worker
    environment:
      - KAFKA_HOST=kafka
      - KAFKA_PORT=29092
      - TERMINUS_SERVER_URL=http://terminusdb:6363
      - TERMINUS_USER=admin
      - TERMINUS_ACCOUNT=admin
      - TERMINUS_KEY=${TERMINUS_KEY:-admin}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-spiceadmin}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-spicepass123}
      - POSTGRES_DB=${POSTGRES_DB:-spicedb}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD:-spicepass123}
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
      - ELASTICSEARCH_USERNAME=${ELASTICSEARCH_USERNAME:-}
      - ELASTICSEARCH_PASSWORD=${ELASTICSEARCH_PASSWORD:-}
      - MINIO_ENDPOINT_URL=http://minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY:-minioadmin123}
      - INSTANCE_BUCKET=instance-events
      - EVENT_STORE_BUCKET=${EVENT_STORE_BUCKET:-spice-event-store}
      # Correctness/chaos tuning (defaults are production-safe)
      - PROCESSED_EVENT_LEASE_TIMEOUT_SECONDS=${PROCESSED_EVENT_LEASE_TIMEOUT_SECONDS:-900}
      - PROCESSED_EVENT_HEARTBEAT_INTERVAL_SECONDS=${PROCESSED_EVENT_HEARTBEAT_INTERVAL_SECONDS:-30}
      - INSTANCE_WORKER_MAX_RETRY_ATTEMPTS=${INSTANCE_WORKER_MAX_RETRY_ATTEMPTS:-5}
      - ENABLE_CHAOS_INJECTION=${ENABLE_CHAOS_INJECTION:-false}
      - CHAOS_CRASH_POINT=${CHAOS_CRASH_POINT:-}
      - CHAOS_CRASH_ONCE=${CHAOS_CRASH_ONCE:-true}
      - CHAOS_CRASH_EXIT_CODE=${CHAOS_CRASH_EXIT_CODE:-42}
      - LOG_LEVEL=INFO
      - DOCKER_CONTAINER=true
    depends_on:
      - terminusdb
      - kafka
      - elasticsearch
      - minio
    networks:
      - spice_network
    restart: unless-stopped

  # Projection Worker - 표준화된 인증 정보
  projection-worker:
    build:
      context: .
      dockerfile: ./projection_worker/Dockerfile
    container_name: spice_projection_worker
    environment:
      - KAFKA_HOST=kafka
      - KAFKA_PORT=29092
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
      - ELASTICSEARCH_USERNAME=${ELASTICSEARCH_USERNAME:-}
      - ELASTICSEARCH_PASSWORD=${ELASTICSEARCH_PASSWORD:-}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-spiceadmin}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-spicepass123}
      - POSTGRES_DB=${POSTGRES_DB:-spicedb}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD:-spicepass123}
      # Correctness/chaos tuning (defaults are production-safe)
      - PROCESSED_EVENT_LEASE_TIMEOUT_SECONDS=${PROCESSED_EVENT_LEASE_TIMEOUT_SECONDS:-900}
      - PROCESSED_EVENT_HEARTBEAT_INTERVAL_SECONDS=${PROCESSED_EVENT_HEARTBEAT_INTERVAL_SECONDS:-30}
      - PROJECTION_WORKER_MAX_RETRIES=${PROJECTION_WORKER_MAX_RETRIES:-5}
      - ENABLE_CHAOS_INJECTION=${ENABLE_CHAOS_INJECTION:-false}
      - CHAOS_CRASH_POINT=${CHAOS_CRASH_POINT:-}
      - CHAOS_CRASH_ONCE=${CHAOS_CRASH_ONCE:-true}
      - CHAOS_CRASH_EXIT_CODE=${CHAOS_CRASH_EXIT_CODE:-42}
      - LOG_LEVEL=INFO
      - DOCKER_CONTAINER=true
    depends_on:
      - kafka
      - elasticsearch
      - redis
    networks:
      - spice_network
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  elasticsearch_data:
  minio_data:
  terminusdb_data:
  bff_data:

networks:
  spice_network:
    name: spice_network
    driver: bridge
