"""
ğŸ”¥ THINK ULTRA! Funnel Service - ë…ë¦½ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤
íƒ€ì… ì¶”ë¡  ë° ìŠ¤í‚¤ë§ˆ ì œì•ˆ ì „ìš© ì„œë¹„ìŠ¤

Port: 8003
"""

from dotenv import load_dotenv

load_dotenv()  # Load .env file

from contextlib import asynccontextmanager
from typing import Any, Dict

from fastapi import FastAPI

# Shared service factory import
from shared.services.service_factory import FUNNEL_SERVICE_INFO, create_fastapi_service, run_service

from funnel.routers.type_inference_router import router as type_inference_router
from shared.utils.app_logger import get_logger

# Rate limiting middleware
from shared.middleware.rate_limiter import rate_limit, RateLimitPresets, RateLimiter

# Observability imports
from shared.observability.tracing import get_tracing_service, trace_endpoint
from shared.observability.metrics import get_metrics_collector, RequestMetricsMiddleware
from shared.observability.context_propagation import TraceContextMiddleware

logger = get_logger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸"""
    logger.info("ğŸš€ Funnel Service ì‹œì‘")
    
    # Initialize Rate Limiter
    try:
        rate_limiter = RateLimiter()
        await rate_limiter.initialize()
        app.state.rate_limiter = rate_limiter
        logger.info("Rate limiter initialized")
    except Exception as e:
        logger.error(f"Failed to initialize rate limiter: {e}")
    
    # Initialize OpenTelemetry
    try:
        tracing_service = get_tracing_service("funnel-service")
        metrics_collector = get_metrics_collector("funnel-service")
        
        # Instrument FastAPI
        tracing_service.instrument_fastapi(app)
        
        # Add middleware
        app.add_middleware(RequestMetricsMiddleware, metrics_collector=metrics_collector)
        app.add_middleware(TraceContextMiddleware)
        
        app.state.tracing_service = tracing_service
        app.state.metrics_collector = metrics_collector
        
        logger.info("OpenTelemetry initialized")
    except Exception as e:
        logger.error(f"Failed to initialize OpenTelemetry: {e}")
    
    yield
    
    # Cleanup
    if hasattr(app.state, 'rate_limiter'):
        await app.state.rate_limiter.close()
    
    if hasattr(app.state, 'tracing_service'):
        app.state.tracing_service.shutdown()
        
    logger.info("ğŸ”„ Funnel Service ì¢…ë£Œ")


# FastAPI ì•± ìƒì„± - Service Factory ì‚¬ìš©
app = create_fastapi_service(
    service_info=FUNNEL_SERVICE_INFO,
    custom_lifespan=lifespan,
    include_health_check=False,  # ê¸°ì¡´ health check ìœ ì§€
    include_logging_middleware=True
)

# ë¼ìš°í„° ë“±ë¡
app.include_router(type_inference_router, prefix="/api/v1")


# ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.get("/")
async def root() -> Dict[str, Any]:
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "service": "funnel",
        "version": "0.1.0",
        "status": "running",
        "description": "íƒ€ì… ì¶”ë¡  ë° ìŠ¤í‚¤ë§ˆ ì œì•ˆ ì „ìš© ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤",
        "endpoints": {
            "health": "/health",
            "analyze": "/api/v1/funnel/analyze",
            "suggest_schema": "/api/v1/funnel/suggest-schema",
            "preview_google_sheets": "/api/v1/funnel/preview/google-sheets",
            "docs": "/docs",
        },
    }


@app.get("/health")
async def health_check() -> Dict[str, Any]:
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    from shared.models.requests import ApiResponse

    return ApiResponse.health_check(
        service_name="funnel", version="0.1.0", description="íƒ€ì… ì¶”ë¡  ë° ìŠ¤í‚¤ë§ˆ ì œì•ˆ ì„œë¹„ìŠ¤"
    ).to_dict()


# Note: CORS debug endpointëŠ” service_factoryì—ì„œ ìë™ ì œê³µë¨


if __name__ == "__main__":
    # Service Factoryë¥¼ ì‚¬ìš©í•œ ê°„ì†Œí™”ëœ ì„œë¹„ìŠ¤ ì‹¤í–‰
    run_service(app, FUNNEL_SERVICE_INFO, "funnel.main:app")
