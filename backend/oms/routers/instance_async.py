"""
OMS ë¹„ë™ê¸° ì¸ìŠ¤í„´ìŠ¤ ë¼ìš°í„° - Command Pattern ê¸°ë°˜
ì¸ìŠ¤í„´ìŠ¤ ë°ì´í„°ì˜ ëª…ë ¹ì„ ì €ìž¥í•˜ê³  ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬í•˜ëŠ” API
"""

import logging
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional
from uuid import UUID, uuid4

from fastapi import APIRouter, BackgroundTasks, Depends, HTTPException, status
from pydantic import BaseModel, Field

from oms.dependencies import (
    JSONLDConverterDep,
    LabelMapperDep,
    TerminusServiceDep,
    OutboxServiceDep,
    EventStoreDep,  # Added for S3/MinIO Event Store
    CommandStatusServiceDep,
    ValidatedDatabaseName,
    ValidatedClassId,
    ensure_database_exists
)
from oms.services.migration_helper import migration_helper
from shared.dependencies.providers import RedisServiceDep
from oms.database.postgres import db as postgres_db
from oms.database.outbox import MessageType, OutboxService
from shared.models.commands import CommandType, InstanceCommand, CommandResult, CommandStatus
from shared.models.common import BaseResponse
from shared.services.command_status_service import CommandStatusService
from shared.services.redis_service import RedisService
from shared.security.input_sanitizer import (
    SecurityViolationError,
    sanitize_input,
    validate_class_id,
    validate_db_name,
    validate_instance_id,
)

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/instances/{db_name}/async", tags=["Async Instance Management"])


# Request Models
class InstanceCreateRequest(BaseModel):
    """ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ìš”ì²­"""
    data: Dict[str, Any] = Field(..., description="ì¸ìŠ¤í„´ìŠ¤ ë°ì´í„°")
    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict, description="ë©”íƒ€ë°ì´í„°")
    

class InstanceUpdateRequest(BaseModel):
    """ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ì • ìš”ì²­"""
    data: Dict[str, Any] = Field(..., description="ìˆ˜ì •í•  ë°ì´í„°")
    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict, description="ë©”íƒ€ë°ì´í„°")
    

class BulkInstanceCreateRequest(BaseModel):
    """ëŒ€ëŸ‰ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ìš”ì²­"""
    instances: List[Dict[str, Any]] = Field(..., description="ì¸ìŠ¤í„´ìŠ¤ ë°ì´í„° ëª©ë¡")
    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict, description="ë©”íƒ€ë°ì´í„°")


@router.post("/{class_id}/create", response_model=CommandResult, status_code=status.HTTP_202_ACCEPTED)
async def create_instance_async(
    db_name: str = Depends(ensure_database_exists),
    class_id: str = Depends(ValidatedClassId),
    request: InstanceCreateRequest = ...,
    outbox_service: Optional[OutboxService] = OutboxServiceDep,
    command_status_service: Optional[CommandStatusService] = CommandStatusServiceDep,
    user_id: Optional[str] = None,
):
    """
    ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ëª…ë ¹ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
    
    ì´ APIëŠ” Commandë§Œ ì €ìž¥í•˜ê³  ì¦‰ì‹œ ì‘ë‹µí•©ë‹ˆë‹¤.
    ì‹¤ì œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ì€ Workerê°€ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    try:
        # ìž…ë ¥ ê²€ì¦
        sanitized_data = sanitize_input(request.data)
        
        # Command ìƒì„±
        command = InstanceCommand(
            command_type=CommandType.CREATE_INSTANCE,
            db_name=db_name,
            class_id=class_id,
            payload=sanitized_data,
            metadata={
                **request.metadata,
                "user_id": user_id,
                "created_at": datetime.now(timezone.utc).isoformat()
            },
            created_by=user_id
        )
        
        # ðŸ”¥ MIGRATION: Use migration helper for gradual S3 adoption
        from shared.config.app_config import AppConfig
        
        if outbox_service:
            async with postgres_db.transaction() as conn:
                # Use migration helper for dual-write pattern
                migration_result = await migration_helper.handle_command_with_migration(
                    connection=conn,
                    command=command,
                    outbox_service=outbox_service,
                    topic=AppConfig.INSTANCE_COMMANDS_TOPIC,
                    actor=user_id
                )
                
                # Log migration status for monitoring
                logger.info(f"Migration result: {migration_result['migration_mode']} - "
                          f"Storage: {', '.join(migration_result['storage'])}")
        
        # Redisì— ìƒíƒœ ì €ìž¥ (if available)
        if command_status_service:
            await command_status_service.set_command_status(
                command_id=str(command.command_id),
                status=CommandStatus.PENDING,
                metadata={
                    "command_type": command.command_type,
                    "db_name": db_name,
                    "class_id": class_id,
                    "aggregate_id": command.aggregate_id,
                    "created_at": command.created_at.isoformat(),
                    "created_by": user_id
                }
            )
        else:
            logger.warning(f"Command status tracking disabled for command {command.command_id}")
        
        # ì‘ë‹µ
        return CommandResult(
            command_id=command.command_id,
            status=CommandStatus.PENDING,
            result={
                "message": f"Instance creation command accepted for class '{class_id}'",
                "class_id": class_id,
                "db_name": db_name
            }
        )
        
    except SecurityViolationError as e:
        logger.warning(f"Security violation in instance creation: {e}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        logger.error(f"Error creating instance command: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to create instance command: {str(e)}"
        )


@router.put("/{class_id}/{instance_id}/update", response_model=CommandResult, status_code=status.HTTP_202_ACCEPTED)
async def update_instance_async(
    db_name: str = Depends(ensure_database_exists),
    class_id: str = Depends(ValidatedClassId),
    instance_id: str = ...,
    request: InstanceUpdateRequest = ...,
    outbox_service: Optional[OutboxService] = OutboxServiceDep,
    command_status_service: Optional[CommandStatusService] = CommandStatusServiceDep,
    user_id: Optional[str] = None,
):
    """
    ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ì • ëª…ë ¹ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
    """
    try:
        # ìž…ë ¥ ê²€ì¦
        validate_instance_id(instance_id)
        sanitized_data = sanitize_input(request.data)
        
        # Command ìƒì„±
        command = InstanceCommand(
            command_type=CommandType.UPDATE_INSTANCE,
            db_name=db_name,
            class_id=class_id,
            instance_id=instance_id,
            payload=sanitized_data,
            metadata={
                **request.metadata,
                "user_id": user_id,
                "updated_at": datetime.now(timezone.utc).isoformat()
            },
            created_by=user_id
        )
        
        # ðŸ”¥ MIGRATION: Use migration helper for gradual S3 adoption
        from shared.config.app_config import AppConfig
        
        if outbox_service:
            async with postgres_db.transaction() as conn:
                # Use migration helper for dual-write pattern
                migration_result = await migration_helper.handle_command_with_migration(
                    connection=conn,
                    command=command,
                    outbox_service=outbox_service,
                    topic=AppConfig.INSTANCE_COMMANDS_TOPIC,
                    actor=user_id
                )
                
                logger.info(f"Migration: {migration_result['migration_mode']}")
        
        # Redisì— ìƒíƒœ ì €ìž¥
        await command_status_service.set_command_status(
            command_id=str(command.command_id),
            status=CommandStatus.PENDING,
            metadata={
                "command_type": command.command_type,
                "db_name": db_name,
                "class_id": class_id,
                "instance_id": instance_id,
                "aggregate_id": command.aggregate_id,
                "updated_at": datetime.now(timezone.utc).isoformat(),
                "updated_by": user_id
            }
        )
        
        return CommandResult(
            command_id=command.command_id,
            status=CommandStatus.PENDING,
            result={
                "message": f"Instance update command accepted for '{instance_id}'",
                "instance_id": instance_id,
                "class_id": class_id,
                "db_name": db_name
            }
        )
        
    except SecurityViolationError as e:
        logger.warning(f"Security violation in instance update: {e}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        logger.error(f"Error updating instance command: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to update instance command: {str(e)}"
        )


@router.delete("/{class_id}/{instance_id}/delete", response_model=CommandResult, status_code=status.HTTP_202_ACCEPTED)
async def delete_instance_async(
    db_name: str = Depends(ensure_database_exists),
    class_id: str = Depends(ValidatedClassId),
    instance_id: str = ...,
    outbox_service: Optional[OutboxService] = OutboxServiceDep,
    command_status_service: Optional[CommandStatusService] = CommandStatusServiceDep,
    user_id: Optional[str] = None,
):
    """
    ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ ëª…ë ¹ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
    """
    try:
        # ìž…ë ¥ ê²€ì¦
        validate_instance_id(instance_id)
        
        # Command ìƒì„±
        command = InstanceCommand(
            command_type=CommandType.DELETE_INSTANCE,
            db_name=db_name,
            class_id=class_id,
            instance_id=instance_id,
            payload={},  # ì‚­ì œëŠ” payload í•„ìš” ì—†ìŒ
            metadata={
                "user_id": user_id,
                "deleted_at": datetime.now(timezone.utc).isoformat()
            },
            created_by=user_id
        )
        
        # ðŸ”¥ MIGRATION: Use migration helper for gradual S3 adoption
        from shared.config.app_config import AppConfig
        
        if outbox_service:
            async with postgres_db.transaction() as conn:
                # Use migration helper for dual-write pattern
                migration_result = await migration_helper.handle_command_with_migration(
                    connection=conn,
                    command=command,
                    outbox_service=outbox_service,
                    topic=AppConfig.INSTANCE_COMMANDS_TOPIC,
                    actor=user_id
                )
                
                logger.info(f"Migration: {migration_result['migration_mode']}")
        
        # Redisì— ìƒíƒœ ì €ìž¥
        await command_status_service.set_command_status(
            command_id=str(command.command_id),
            status=CommandStatus.PENDING,
            metadata={
                "command_type": command.command_type,
                "db_name": db_name,
                "class_id": class_id,
                "instance_id": instance_id,
                "aggregate_id": command.aggregate_id,
                "deleted_at": datetime.now(timezone.utc).isoformat(),
                "deleted_by": user_id
            }
        )
        
        return CommandResult(
            command_id=command.command_id,
            status=CommandStatus.PENDING,
            result={
                "message": f"Instance deletion command accepted for '{instance_id}'",
                "instance_id": instance_id,
                "class_id": class_id,
                "db_name": db_name
            }
        )
        
    except SecurityViolationError as e:
        logger.warning(f"Security violation in instance deletion: {e}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        logger.error(f"Error deleting instance command: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to delete instance command: {str(e)}"
        )


@router.post("/{class_id}/bulk-create", response_model=CommandResult, status_code=status.HTTP_202_ACCEPTED)
async def bulk_create_instances_async(
    db_name: str = Depends(ensure_database_exists),
    class_id: str = Depends(ValidatedClassId),
    request: BulkInstanceCreateRequest = ...,
    background_tasks: BackgroundTasks = BackgroundTasks(),
    outbox_service: Optional[OutboxService] = OutboxServiceDep,
    command_status_service: Optional[CommandStatusService] = CommandStatusServiceDep,
    user_id: Optional[str] = None,
):
    """
    ëŒ€ëŸ‰ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ëª…ë ¹ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
    
    ì´ ì—”ë“œí¬ì¸íŠ¸ëŠ” ì¦‰ì‹œ 202 Acceptedë¥¼ ë°˜í™˜í•˜ê³ ,
    ì‹¤ì œ ì²˜ë¦¬ëŠ” ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§„í–‰ë©ë‹ˆë‹¤.
    """
    try:
        # ìž…ë ¥ ê²€ì¦
        sanitized_instances = [sanitize_input(instance) for instance in request.instances]
        
        # Command ìƒì„±
        command = InstanceCommand(
            command_type=CommandType.BULK_CREATE_INSTANCES,
            db_name=db_name,
            class_id=class_id,
            payload={
                "instances": sanitized_instances,
                "count": len(sanitized_instances)
            },
            metadata={
                **request.metadata,
                "user_id": user_id,
                "created_at": datetime.now(timezone.utc).isoformat()
            },
            created_by=user_id
        )
        
        # ðŸ”¥ MIGRATION: Use migration helper for gradual S3 adoption
        from shared.config.app_config import AppConfig
        
        if outbox_service:
            async with postgres_db.transaction() as conn:
                # Use migration helper for dual-write pattern
                migration_result = await migration_helper.handle_command_with_migration(
                    connection=conn,
                    command=command,
                    outbox_service=outbox_service,
                    topic=AppConfig.INSTANCE_COMMANDS_TOPIC,
                    actor=user_id
                )
                
                logger.info(f"Migration: {migration_result['migration_mode']}")
        
        # Redisì— ìƒíƒœ ì €ìž¥
        await command_status_service.set_command_status(
            command_id=str(command.command_id),
            status=CommandStatus.PENDING,
            metadata={
                "command_type": command.command_type,
                "db_name": db_name,
                "class_id": class_id,
                "instance_count": len(sanitized_instances),
                "aggregate_id": command.aggregate_id,
                "created_at": command.created_at.isoformat(),
                "created_by": user_id
            }
        )
        
        # Add background task for progress tracking
        if len(sanitized_instances) > 10:  # Only for large batches
            background_tasks.add_task(
                _track_bulk_create_progress,
                command_id=str(command.command_id),
                total_instances=len(sanitized_instances),
                command_status_service=command_status_service
            )
        
        return CommandResult(
            command_id=command.command_id,
            status=CommandStatus.PENDING,
            result={
                "message": f"Bulk instance creation command accepted for {len(sanitized_instances)} instances",
                "class_id": class_id,
                "db_name": db_name,
                "instance_count": len(sanitized_instances),
                "note": "Large batches are processed in background with progress tracking" if len(sanitized_instances) > 10 else None
            }
        )
        
    except SecurityViolationError as e:
        logger.warning(f"Security violation in bulk instance creation: {e}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        logger.error(f"Error creating bulk instance command: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to create bulk instance command: {str(e)}"
        )


@router.get("/command/{command_id}/status", response_model=CommandResult)
async def get_instance_command_status(
    db_name: str = Depends(ensure_database_exists),
    command_id: str = ...,
    command_status_service: Optional[CommandStatusService] = CommandStatusServiceDep,
):
    """
    ì¸ìŠ¤í„´ìŠ¤ ëª…ë ¹ì˜ ìƒíƒœ ì¡°íšŒ
    """
    try:
        # Redisì—ì„œ ìƒíƒœ ì¡°íšŒ
        status_info = await command_status_service.get_command_status(command_id)
        
        if not status_info:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Command not found: {command_id}"
            )
        
        # ê²°ê³¼ ì¡°íšŒ
        result = await command_status_service.get_command_result(command_id)
        
        return CommandResult(
            command_id=UUID(command_id),
            status=CommandStatus(status_info.get("status", CommandStatus.PENDING)),
            result=result or {
                "message": f"Command is {status_info.get('status', 'PENDING')}",
                **status_info
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting command status: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get command status: {str(e)}"
        )


# Background task helpers
async def _track_bulk_create_progress(
    command_id: str,
    total_instances: int,
    command_status_service: CommandStatusService
) -> None:
    """
    Track progress of bulk create operation in background.
    
    This demonstrates proper background task usage instead of fire-and-forget.
    """
    import asyncio
    
    try:
        logger.info(f"Starting progress tracking for bulk create command {command_id}")
        
        # Simulate progress updates (in real scenario, this would monitor actual progress)
        for i in range(0, total_instances + 1, max(1, total_instances // 10)):
            # Update progress
            progress_percentage = (i / total_instances) * 100 if total_instances > 0 else 100
            
            await command_status_service.set_command_status(
                command_id=command_id,
                status=CommandStatus.PROCESSING,
                metadata={
                    "progress": {
                        "current": i,
                        "total": total_instances,
                        "percentage": progress_percentage,
                        "message": f"Processing instance {i} of {total_instances}"
                    }
                }
            )
            
            # Simulate processing time
            await asyncio.sleep(0.5)
            
        logger.info(f"Completed progress tracking for bulk create command {command_id}")
        
    except Exception as e:
        logger.error(f"Error in bulk create progress tracking for {command_id}: {e}")
        # Don't raise - this is a background task


@router.post("/{class_id}/bulk-create-tracked", response_model=Dict[str, Any])
async def bulk_create_instances_with_tracking(
    db_name: str = Depends(ensure_database_exists),
    class_id: str = Depends(ValidatedClassId),
    request: BulkInstanceCreateRequest = ...,
    background_tasks: BackgroundTasks = BackgroundTasks(),
    outbox_service: Optional[OutboxService] = OutboxServiceDep,
    command_status_service: Optional[CommandStatusService] = CommandStatusServiceDep,
    user_id: Optional[str] = None,
):
    """
    Enhanced bulk instance creation with proper background task tracking.
    
    This endpoint demonstrates the improved pattern for handling long-running
    operations by immediately returning a task ID that can be monitored.
    """
    # Generate task ID
    task_id = str(uuid4())
    
    # Validate input
    sanitized_instances = [sanitize_input(instance) for instance in request.instances]
    
    # Add the actual bulk creation to background tasks
    background_tasks.add_task(
        _process_bulk_create_in_background,
        task_id=task_id,
        db_name=db_name,
        class_id=class_id,
        instances=sanitized_instances,
        metadata=request.metadata,
        user_id=user_id,
        outbox_service=outbox_service,
        command_status_service=command_status_service
    )
    
    # Return immediately with 202 Accepted
    return {
        "task_id": task_id,
        "status": "accepted",
        "message": f"Bulk creation task started for {len(sanitized_instances)} instances",
        "status_url": f"/api/v1/tasks/{task_id}/status",
        "instance_count": len(sanitized_instances)
    }


async def _process_bulk_create_in_background(
    task_id: str,
    db_name: str,
    class_id: str,
    instances: List[Dict[str, Any]],
    metadata: Dict[str, Any],
    user_id: Optional[str],
    outbox_service: Optional[OutboxService],
    command_status_service: CommandStatusService
) -> None:
    """
    Process bulk create operation in background with proper error handling.
    """
    try:
        # Create command
        command = InstanceCommand(
            command_type=CommandType.BULK_CREATE_INSTANCES,
            db_name=db_name,
            class_id=class_id,
            payload={
                "instances": instances,
                "count": len(instances),
                "task_id": task_id
            },
            metadata={
                **metadata,
                "user_id": user_id,
                "created_at": datetime.now(timezone.utc).isoformat(),
                "background_task_id": task_id
            },
            created_by=user_id
        )
        
        # Save to outbox
        if outbox_service:
            from oms.database.postgres import db as postgres_db
            async with postgres_db.transaction() as conn:
                await outbox_service.publish_command(conn, command)
        
        # Update task status
        await command_status_service.set_command_status(
            command_id=task_id,
            status=CommandStatus.COMPLETED,
            metadata={
                "command_id": str(command.command_id),
                "result": "Bulk create command published successfully"
            }
        )
        
    except Exception as e:
        logger.error(f"Background bulk create failed for task {task_id}: {e}")
        await command_status_service.set_command_status(
            command_id=task_id,
            status=CommandStatus.FAILED,
            metadata={
                "error": str(e),
                "error_type": type(e).__name__
            }
        )