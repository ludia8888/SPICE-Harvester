"""
Async TerminusDB ì„œë¹„ìŠ¤ ëª¨ë“ˆ - Clean Facade
httpxë¥¼ ì‚¬ìš©í•œ ë¹„ë™ê¸° TerminusDB í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
ëª¨ë“ˆí™”ëœ ì„œë¹„ìŠ¤ë“¤ì„ í†µí•©í•˜ëŠ” ê¹”ë”í•œ íŒŒì‚¬ë“œ íŒ¨í„´
"""

import asyncio
import json
import logging
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional

import httpx

from oms.exceptions import (
    ConnectionError,
    CriticalDataLossRisk,
    DuplicateOntologyError,
    OntologyNotFoundError,
    OntologyValidationError,
)
from oms.utils.terminus_retry import build_async_retry

# Import utils modules
from oms.utils.circular_reference_detector import CircularReferenceDetector
from oms.utils.relationship_path_tracker import PathQuery, PathType, RelationshipPathTracker
from oms.validators.relationship_validator import RelationshipValidator, ValidationSeverity
from shared.config.service_config import ServiceConfig
from shared.models.common import DataType
from shared.models.config import ConnectionConfig
from shared.models.ontology import OntologyBase, OntologyResponse, Relationship, Property

# Import new relationship management components
from .relationship_manager import RelationshipManager
from .property_to_relationship_converter import PropertyToRelationshipConverter

# Import new TerminusDB schema type support
from oms.utils.terminus_schema_types import (
    TerminusSchemaBuilder, 
    TerminusSchemaConverter, 
    TerminusConstraintProcessor,
    create_basic_class_schema,
    create_subdocument_schema,
    convert_simple_schema
)

# Import constraint and default value extraction
from oms.utils.constraint_extractor import ConstraintExtractor

# Import modular TerminusDB services
from .terminus import (
    BaseTerminusService,
    DatabaseService,
    QueryService,
    InstanceService,
    OntologyService,
    VersionControlService,
    DocumentService
)

logger = logging.getLogger(__name__)

# Atomic update specific exceptions
class AtomicUpdateError(Exception):
    """Base exception for atomic update operations"""
    pass

class PatchUpdateError(AtomicUpdateError):
    """Exception for PATCH-based update failures"""
    pass

class TransactionUpdateError(AtomicUpdateError):
    """Exception for transaction-based update failures"""
    pass

class WOQLUpdateError(AtomicUpdateError):
    """Exception for WOQL-based update failures"""
    pass

class BackupCreationError(Exception):
    """Exception for backup creation failures"""
    pass

class RestoreError(Exception):
    """Exception for restore operation failures"""
    pass

class BackupRestoreError(Exception):
    """Exception for backup and restore operation failures"""
    pass

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
OntologyNotFoundError = OntologyNotFoundError
DuplicateOntologyError = DuplicateOntologyError
OntologyValidationError = OntologyValidationError
DatabaseError = ConnectionError


async_terminus_retry = build_async_retry(
    retry_exceptions=(httpx.ConnectError, httpx.TimeoutException, ConnectionError),
    backoff="exponential",
    logger=logger,
    on_failure=lambda exc, retries: ConnectionError(f"Failed after {retries} attempts: {exc}"),
)


class AsyncTerminusService:
    """
    ë¹„ë™ê¸° TerminusDB ì„œë¹„ìŠ¤ í´ëž˜ìŠ¤ - Clean Facade Pattern
    
    ì´ í´ëž˜ìŠ¤ëŠ” modular service patternì„ ì‚¬ìš©í•˜ì—¬ ê¸°ëŠ¥ë³„ë¡œ ë¶„ë¦¬ëœ ì„œë¹„ìŠ¤ë¥¼ í†µí•©í•©ë‹ˆë‹¤:
    - DatabaseService: ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ (ìƒì„±, ì‚­ì œ, ëª©ë¡)
    - QueryService: WOQL/SPARQL ì¿¼ë¦¬ ì‹¤í–‰
    - InstanceService: ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ ìµœì í™” (N+1 query í•´ê²°)
    - OntologyService: ì˜¨í†¨ë¡œì§€/ìŠ¤í‚¤ë§ˆ CRUD
    - VersionControlService: ë¸Œëžœì¹˜/ì»¤ë°‹ ê´€ë¦¬
    - DocumentService: ë¬¸ì„œ(ì¸ìŠ¤í„´ìŠ¤) CRUD
    
    ëª¨ë“  ë ˆê±°ì‹œ ì½”ë“œì™€ deprecated ë©”ì„œë“œëŠ” ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.
    """

    def __init__(self, connection_info: Optional[ConnectionConfig] = None):
        """
        ì´ˆê¸°í™”

        Args:
            connection_info: ì—°ê²° ì •ë³´ ê°ì²´
        """
        # Use environment variables if no connection info provided
        self.connection_info = connection_info or ConnectionConfig.from_env()

        self._client = None
        self._auth_token = None
        self._db_cache = set()

        # Initialize modular TerminusDB services
        self.database_service = DatabaseService(connection_info)
        self.query_service = QueryService(connection_info)
        self.instance_service = InstanceService(connection_info)
        self.ontology_service = OntologyService(connection_info)
        self.version_control_service = VersionControlService(connection_info)
        self.document_service = DocumentService(connection_info)

        # Initialize relationship management components
        self.relationship_manager = RelationshipManager()
        self.relationship_validator = RelationshipValidator()
        self.circular_detector = CircularReferenceDetector()
        self.path_tracker = RelationshipPathTracker()
        self.property_converter = PropertyToRelationshipConverter()

        # Relationship cache for performance
        self._ontology_cache: Dict[str, List[OntologyResponse]] = {}

        # Stateless HTTP APIì—ì„œ "current branch"ëŠ” ì„œë²„ì— ì¡´ìž¬í•˜ì§€ ì•Šì§€ë§Œ,
        # ì¼ë¶€ ë¼ìš°í„°ê°€ UX ëª©ì ìœ¼ë¡œ ì‚¬ìš©í•˜ë¯€ë¡œ ì„œë¹„ìŠ¤ ë ˆë²¨ì—ì„œ best-effortë¡œ ì¶”ì .
        self._current_branch_by_db: Dict[str, str] = {}
        
        # ë™ì‹œ ìš”ì²­ ì œí•œìœ¼ë¡œ TerminusDB ë¶€í•˜ ì¡°ì ˆ
        self._request_semaphore = asyncio.Semaphore(50)  # ìµœëŒ€ 50ê°œ ë™ì‹œ ìš”ì²­
        
        # ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ ìºì‹œë¡œ ì„±ëŠ¥ ìµœì í™”
        self._metadata_schema_cache: set = set()  # ì´ë¯¸ ìƒì„±ëœ DBì˜ ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ

    async def check_connection(self) -> bool:
        """ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            # database_serviceë¥¼ í†µí•´ ì—°ê²° í™•ì¸
            if hasattr(self.database_service, 'check_connection'):
                return await self.database_service.check_connection()
            else:
                # ê¸°ë³¸ì ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒë¡œ ì—°ê²° í™•ì¸
                await self.list_databases()
                return True
        except Exception:
            return False

    async def connect(self) -> None:
        """ì—°ê²° ì„¤ì •"""
        # database_serviceë¥¼ í†µí•´ ì—°ê²°
        if hasattr(self.database_service, 'connect'):
            await self.database_service.connect()

    async def disconnect(self) -> None:
        """ì—°ê²° í•´ì œ"""
        await self.close()

    async def close(self):
        """ëª¨ë“  ì„œë¹„ìŠ¤ ì¢…ë£Œ"""
        # Close all modular services using disconnect method
        for service in [
            self.database_service,
            self.query_service,
            self.instance_service,
            self.ontology_service,
            self.version_control_service,
            self.document_service
        ]:
            if hasattr(service, 'disconnect'):
                await service.disconnect()
            elif hasattr(service, 'close'):
                await service.close()
        
        # Close HTTP client if exists
        if self._client:
            await self._client.aclose()
            self._client = None

    # ==========================================
    # Database Management - Facade Methods
    # ==========================================
    
    @async_terminus_retry(max_retries=3)
    async def create_database(self, db_name: str, description: str = "") -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±"""
        result = await self.database_service.create_database(db_name, description)
        
        # ì„±ê³µ ì‹œ ìºì‹œ ê°±ì‹  ë° True ë°˜í™˜
        if result and isinstance(result, dict):
            self._db_cache.add(db_name)
            return True
        
        return False

    @async_terminus_retry(max_retries=3)
    async def database_exists(self, db_name: str) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ì¡´ìž¬ ì—¬ë¶€ í™•ì¸"""
        return await self.database_service.database_exists(db_name)

    async def list_databases(self) -> List[Dict[str, Any]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ"""
        return await self.database_service.list_databases()

    @async_terminus_retry(max_retries=3)
    async def delete_database(self, db_name: str) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ"""
        return await self.database_service.delete_database(db_name)

    # ==========================================
    # Query Execution - Facade Methods
    # ==========================================
    
    async def execute_query(self, db_name: str, query_dict: Dict[str, Any]) -> Dict[str, Any]:
        """Query execution (query-spec or raw WOQL passthrough)."""
        return await self.query_service.execute_query(db_name, query_dict)

    async def execute_sparql(
        self, 
        db_name: str, 
        sparql_query: str, 
        limit: Optional[int] = None,
        offset: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """SPARQL ì¿¼ë¦¬ ì§ì ‘ ì‹¤í–‰"""
        return await self.query_service.execute_sparql(db_name, sparql_query, limit, offset)

    # ==========================================
    # Instance Operations - Facade Methods
    # ==========================================
    
    async def get_class_instances_optimized(
        self, 
        db_name: str, 
        class_id: str, 
        branch: str = "main",
        limit: Optional[int] = None,
        offset: Optional[int] = None,
        filter_conditions: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """íŠ¹ì • í´ëž˜ìŠ¤ì˜ ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì¡°íšŒ"""
        # Extract search from filter_conditions if present
        search = None
        if filter_conditions and isinstance(filter_conditions, dict):
            search = filter_conditions.get("search")
        
        return await self.instance_service.get_class_instances_optimized(
            db_name=db_name,
            class_id=class_id,
            branch=branch,
            limit=limit or 100,
            offset=offset or 0,
            search=search,
        )

    async def get_instance_optimized(
        self, 
        db_name: str, 
        instance_id: str, 
        branch: str = "main",
        class_id: Optional[str] = None
    ) -> Optional[Dict[str, Any]]:
        """ê°œë³„ ì¸ìŠ¤í„´ìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì¡°íšŒ"""
        return await self.instance_service.get_instance_optimized(
            db_name=db_name,
            instance_id=instance_id,
            branch=branch,
            class_id=class_id,
        )

    async def count_class_instances(
        self, 
        db_name: str, 
        class_id: str, 
        branch: str = "main",
        filter_conditions: Optional[Dict[str, Any]] = None
    ) -> int:
        """íŠ¹ì • í´ëž˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤ ê°œìˆ˜ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì¡°íšŒ"""
        return await self.instance_service.count_class_instances(
            db_name=db_name,
            class_id=class_id,
            branch=branch,
            filter_conditions=filter_conditions,
        )

    # ==========================================
    # Ontology Operations - Facade Methods
    # ==========================================
    
    async def get_ontology(
        self, 
        db_name: str, 
        class_id: Optional[str] = None, 
        raise_if_missing: bool = True,
        *,
        branch: str = "main",
    ) -> Any:
        """ì˜¨í†¨ë¡œì§€ ì¡°íšŒ (branch-aware).

        Compatibility:
        - If `class_id` is provided: returns a single OntologyResponse or None.
        - If `class_id` is None: returns a list of OntologyResponse.
        """
        if not class_id:
            return await self.ontology_service.list_ontologies(db_name, branch=branch, limit=1000, offset=0)
        return await self.ontology_service.get_ontology(db_name, class_id, branch=branch)

    async def create_ontology(
        self, db_name: str, ontology_data: OntologyBase, *, branch: str = "main"
    ) -> OntologyResponse:
        """ì˜¨í†¨ë¡œì§€ ìƒì„±"""
        # Create ontology using TerminusDB service
        try:
            result = await self.ontology_service.create_ontology(db_name, ontology_data, branch=branch)
            logger.info(f"Successfully created ontology '{ontology_data.id}' in database '{db_name}'")
            return result
        except Exception as e:
            logger.error(f"Failed to create ontology '{ontology_data.id}': {e}")
            raise

    async def create_ontology_with_advanced_relationships(
        self,
        db_name: str,
        ontology_data: OntologyBase,
        *,
        branch: str = "main",
        auto_generate_inverse: bool = False,
        validate_relationships: bool = True,
        check_circular_references: bool = True
    ) -> OntologyResponse:
        try:
            if auto_generate_inverse:
                raise OntologyValidationError(
                    "auto_generate_inverse is not implemented yet. TerminusDB schema documents discard "
                    "per-property custom metadata, so inverse metadata needs a dedicated projection store."
                )

            # 2) Optional: validate relationship integrity against current DB schema.
            existing_ontologies: List[OntologyResponse] = []
            if validate_relationships or check_circular_references:
                try:
                    existing = await self.get_ontology(db_name, class_id=None, raise_if_missing=False, branch=branch)
                    existing_ontologies = existing if isinstance(existing, list) else []
                except Exception as e:
                    # Validation is part of the "advanced" contract; fail fast if we can't
                    # obtain the reference graph (prevents silent schema corruption).
                    raise OntologyValidationError(
                        f"Failed to load existing ontologies for validation (db={db_name}, branch={branch}): {e}"
                    )

            if validate_relationships and ontology_data.relationships:
                validator = RelationshipValidator(existing_ontologies=existing_ontologies)
                ontology_for_validation = OntologyResponse(**ontology_data.model_dump(mode="json"))
                results = validator.validate_ontology_relationships(ontology_for_validation)
                errors = [r for r in results if r.severity == ValidationSeverity.ERROR]
                if errors:
                    raise OntologyValidationError(
                        "Relationship validation failed: "
                        + "; ".join(f"{e.code}: {e.message}" for e in errors[:20])
                    )

            # 3) Optional: prevent introducing critical cycles.
            if check_circular_references and ontology_data.relationships:
                detector = CircularReferenceDetector(max_cycle_depth=10)
                detector.build_relationship_graph(existing_ontologies)

                critical_cycles = []
                for rel in ontology_data.relationships:
                    cycles = detector.detect_cycle_for_new_relationship(
                        source=ontology_data.id,
                        target=rel.target,
                        predicate=rel.predicate,
                    )
                    critical_cycles.extend([c for c in cycles if c.severity == "critical"])

                if critical_cycles:
                    first = critical_cycles[0]
                    raise OntologyValidationError(
                        f"Schema cycle check failed (critical cycle): {first.message}"
                    )

            result = await self.ontology_service.create_ontology(db_name, ontology_data, branch=branch)
            logger.info(
                f"Successfully created ontology '{ontology_data.id}' with advanced relationship options "
                f"(db={db_name}, branch={branch})"
            )
            return result
        except Exception as e:
            logger.error(f"Failed to create ontology with advanced relationships '{ontology_data.id}': {e}")
            raise

    async def update_ontology(
        self, 
        db_name: str, 
        class_id: str, 
        ontology_data: OntologyBase,
        *,
        branch: str = "main",
    ) -> OntologyResponse:
        """ì˜¨í†¨ë¡œì§€ ì—…ë°ì´íŠ¸ - Atomic ë²„ì „"""
        return await self.ontology_service.update_ontology(db_name, class_id, ontology_data, branch=branch)

    async def delete_ontology(self, db_name: str, class_id: str, *, branch: str = "main") -> bool:
        """ì˜¨í†¨ë¡œì§€ ì‚­ì œ"""
        return await self.ontology_service.delete_ontology(db_name, class_id, branch=branch)

    async def list_ontology_classes(self, db_name: str) -> List[OntologyResponse]:
        """ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  ì˜¨í†¨ë¡œì§€ ëª©ë¡ ì¡°íšŒ"""
        # Use default limit and offset values
        return await self.ontology_service.list_ontologies(db_name, limit=100, offset=0)

    # ==========================================
    # Version Control - Facade Methods
    # ==========================================
    
    async def create_branch(self, db_name: str, branch_name: str, from_branch: str = "main") -> bool:
        """ë¸Œëžœì¹˜ ìƒì„±"""
        await self.version_control_service.create_branch(db_name, branch_name, from_branch)
        return True

    async def list_branches(self, db_name: str) -> List[str]:
        """ë¸Œëžœì¹˜ ëª©ë¡ ì¡°íšŒ"""
        branches = await self.version_control_service.list_branches(db_name)
        if branches and isinstance(branches[0], dict):
            return [b.get("name") for b in branches if isinstance(b, dict) and b.get("name")]
        return [str(b) for b in branches] if isinstance(branches, list) else []

    async def get_current_branch(self, db_name: str) -> str:
        """í˜„ìž¬ ë¸Œëžœì¹˜ (best-effort, ê¸°ë³¸ê°’: main)"""
        return self._current_branch_by_db.get(db_name, "main")

    async def delete_branch(self, db_name: str, branch_name: str) -> bool:
        """ë¸Œëžœì¹˜ ì‚­ì œ"""
        return await self.version_control_service.delete_branch(db_name, branch_name)

    async def checkout_branch(self, db_name: str, branch_name: str) -> bool:
        """ë¸Œëžœì¹˜ ì²´í¬ì•„ì›ƒ"""
        ok = await self.version_control_service.checkout_branch(db_name, branch_name)
        if ok:
            self._current_branch_by_db[db_name] = branch_name
        return ok

    async def checkout(self, db_name: str, target: str, target_type: str = "branch") -> bool:
        """Router í˜¸í™˜ checkout (branch/commit)."""
        if target_type == "branch":
            return await self.checkout_branch(db_name, target)
        # commit checkout is stateless; accept for compatibility
        return True

    async def merge_branches(
        self, 
        db_name: str, 
        source_branch: str, 
        target_branch: str,
        message: Optional[str] = None,
        author: Optional[str] = None
    ) -> Dict[str, Any]:
        """ë¸Œëžœì¹˜ ë³‘í•©"""
        return await self.version_control_service.merge(
            db_name,
            source_branch=source_branch,
            target_branch=target_branch,
            author=author,
            message=message,
        )

    async def commit(
        self, 
        db_name: str, 
        message: str, 
        author: str = "admin",
        branch: Optional[str] = None
    ) -> str:
        """ì»¤ë°‹ ìƒì„±"""
        return await self.version_control_service.commit(db_name, message, author, branch)

    async def get_commit_history(
        self, 
        db_name: str, 
        branch: str = "main", 
        limit: int = 10,
        offset: int = 0,
    ) -> List[Dict[str, Any]]:
        """ì»¤ë°‹ ížˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        return await self.version_control_service.get_commit_history(db_name, branch, limit, offset)

    async def diff(self, db_name: str, from_ref: str, to_ref: str) -> Any:
        """ì°¨ì´ì  ì¡°íšŒ"""
        return await self.version_control_service.diff(db_name, from_ref, to_ref)

    async def merge(
        self,
        db_name: str,
        *,
        source_branch: str,
        target_branch: str,
        strategy: str = "auto",
    ) -> Dict[str, Any]:
        """Router í˜¸í™˜ merge API."""
        return await self.version_control_service.merge(
            db_name,
            source_branch=source_branch,
            target_branch=target_branch,
            strategy=strategy,
        )

    async def rebase(
        self, 
        db_name: str, 
        *,
        onto: str,
        branch: str,
        message: Optional[str] = None,
    ) -> Dict[str, Any]:
        """Router í˜¸í™˜ rebase API (branch -> onto)."""
        return await self.version_control_service.rebase(db_name, branch=branch, onto=onto, message=message)

    async def rollback(self, db_name: str, target: str) -> Dict[str, Any]:
        """Router í˜¸í™˜ rollback API (reset current branch to target)."""
        branch = await self.get_current_branch(db_name)
        return await self.version_control_service.reset_branch(db_name, branch_name=branch, commit_id=target)

    async def find_common_ancestor(
        self, db_name: str, branch1: str, branch2: str
    ) -> Optional[str]:
        """ê³µí†µ ì¡°ìƒ ì°¾ê¸° (í˜„ìž¬ëŠ” best-effort ë¯¸êµ¬í˜„)."""
        return None

    # ==========================================
    # Document Operations - Facade Methods
    # ==========================================
    
    async def create_instance(
        self, 
        db_name: str, 
        class_id: str, 
        instance_data: Dict[str, Any],
        *,
        branch: str = "main",
    ) -> Dict[str, Any]:
        """ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        return await self.document_service.create_instance(db_name, class_id, instance_data, branch=branch)

    async def update_instance(
        self, 
        db_name: str, 
        class_id: str, 
        instance_id: str,
        update_data: Dict[str, Any],
        *,
        branch: str = "main",
    ) -> Dict[str, Any]:
        """ì¸ìŠ¤í„´ìŠ¤ ì—…ë°ì´íŠ¸"""
        return await self.document_service.update_instance(
            db_name, class_id, instance_id, update_data, branch=branch
        )

    async def delete_instance(
        self, 
        db_name: str, 
        class_id: str, 
        instance_id: str,
        *,
        branch: str = "main",
    ) -> bool:
        """ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ"""
        return await self.document_service.delete_instance(db_name, class_id, instance_id, branch=branch)

    # ==========================================
    # Relationship Management - Direct Methods
    # ==========================================
    
    async def validate_relationships(
        self,
        db_name: str,
        ontology_data: Dict[str, Any],
        *,
        branch: str = "main",
        fix_issues: bool = False,
    ) -> Dict[str, Any]:
        """Validate ontology relationships against current schema (no write)."""
        existing = await self.get_ontology(db_name, class_id=None, raise_if_missing=False, branch=branch)
        existing_ontologies: List[OntologyResponse] = existing if isinstance(existing, list) else []

        payload = dict(ontology_data or {})
        if not payload.get("id"):
            from shared.utils.id_generator import generate_simple_id

            label_value = payload.get("label") or "UnnamedClass"
            label_str = ""
            if isinstance(label_value, str):
                label_str = label_value.strip()
            elif isinstance(label_value, dict):
                label_str = (
                    str(label_value.get("en") or "").strip()
                    or str(label_value.get("ko") or "").strip()
                    or next((str(v).strip() for v in label_value.values() if v and str(v).strip()), "")
                )

            payload["id"] = generate_simple_id(
                label=label_str,
                use_timestamp_for_korean=True,
                default_fallback="UnnamedClass",
            )

        candidate = OntologyResponse(**OntologyBase(**payload).model_dump(mode="json"))

        validator = RelationshipValidator(existing_ontologies=existing_ontologies)
        results = validator.validate_ontology_relationships(candidate)

        def _serialize(result: Any) -> Dict[str, Any]:
            severity = result.severity.value if hasattr(result.severity, "value") else str(result.severity)
            return {
                "severity": severity,
                "code": result.code,
                "message": result.message,
                "field": result.field,
                "related_objects": result.related_objects,
            }

        serialized = [_serialize(r) for r in results]
        errors = [r for r in serialized if r["severity"] == ValidationSeverity.ERROR.value]
        warnings = [r for r in serialized if r["severity"] == ValidationSeverity.WARNING.value]
        info = [r for r in serialized if r["severity"] == ValidationSeverity.INFO.value]

        if fix_issues:
            # No automatic fixer exists yet; be explicit so this never becomes a silent no-op.
            logger.info("fix_issues requested but no fixer is implemented; returning analysis only")

        return {
            "ok": len(errors) == 0,
            "db_name": db_name,
            "branch": branch,
            "class_id": candidate.id,
            "issues": serialized,
            "errors": errors,
            "warnings": warnings,
            "info": info,
            "summary": {
                "total": len(serialized),
                "errors": len(errors),
                "warnings": len(warnings),
                "info": len(info),
                "fix_issues_requested": bool(fix_issues),
                "fix_issues_applied": False,
            },
            "analysis_timestamp": datetime.now(timezone.utc).isoformat(),
        }

    async def detect_circular_references(
        self,
        db_name: str,
        *,
        branch: str = "main",
        include_new_ontology: Optional[Dict[str, Any]] = None,
        max_cycle_depth: int = 10,
    ) -> Dict[str, Any]:
        """Detect circular references across ontology relationship graph (no write)."""
        existing = await self.get_ontology(db_name, class_id=None, raise_if_missing=False, branch=branch)
        ontologies: List[OntologyResponse] = existing if isinstance(existing, list) else []

        if include_new_ontology:
            payload = dict(include_new_ontology)
            if not payload.get("id"):
                from shared.utils.id_generator import generate_simple_id

                label_value = payload.get("label") or "UnnamedClass"
                label_str = ""
                if isinstance(label_value, str):
                    label_str = label_value.strip()
                elif isinstance(label_value, dict):
                    label_str = (
                        str(label_value.get("en") or "").strip()
                        or str(label_value.get("ko") or "").strip()
                        or next((str(v).strip() for v in label_value.values() if v and str(v).strip()), "")
                    )
                payload["id"] = generate_simple_id(
                    label=label_str,
                    use_timestamp_for_korean=True,
                    default_fallback="UnnamedClass",
                )

            candidate = OntologyResponse(**OntologyBase(**payload).model_dump(mode="json"))
            ontologies = [*ontologies, candidate]

        detector = CircularReferenceDetector(max_cycle_depth=max_cycle_depth)
        detector.build_relationship_graph(ontologies)
        cycles = detector.detect_all_cycles()

        serialized_cycles: List[Dict[str, Any]] = []
        for cycle in cycles:
            serialized_cycles.append(
                {
                    "cycle_type": cycle.cycle_type.value if hasattr(cycle.cycle_type, "value") else str(cycle.cycle_type),
                    "path": cycle.path,
                    "predicates": cycle.predicates,
                    "length": cycle.length,
                    "severity": cycle.severity,
                    "message": cycle.message,
                    "can_break": cycle.can_break,
                }
            )

        critical = [c for c in serialized_cycles if c.get("severity") == "critical"]
        warning = [c for c in serialized_cycles if c.get("severity") == "warning"]
        info = [c for c in serialized_cycles if c.get("severity") not in {"critical", "warning"}]

        return {
            "db_name": db_name,
            "branch": branch,
            "cycles": serialized_cycles,
            "summary": {
                "total_cycles": len(serialized_cycles),
                "critical_cycles": len(critical),
                "warning_cycles": len(warning),
                "info_cycles": len(info),
                "max_cycle_depth": max_cycle_depth,
            },
            "analysis_timestamp": datetime.now(timezone.utc).isoformat(),
        }

    async def find_relationship_paths(
        self,
        *,
        db_name: str,
        start_entity: str,
        end_entity: Optional[str] = None,
        max_depth: int = 5,
        path_type: str = "shortest",
        branch: str = "main",
    ) -> Dict[str, Any]:
        """Find relationship paths between entities in the ontology graph (no write)."""
        existing = await self.get_ontology(db_name, class_id=None, raise_if_missing=False, branch=branch)
        ontologies: List[OntologyResponse] = existing if isinstance(existing, list) else []

        tracker = RelationshipPathTracker()
        tracker.build_graph(ontologies)

        pt_norm = str(path_type or "").strip().lower()
        if pt_norm in {"shortest"}:
            pt = PathType.SHORTEST
        elif pt_norm in {"all", "all_paths", "allpaths"}:
            pt = PathType.ALL_PATHS
        elif pt_norm in {"weighted"}:
            pt = PathType.WEIGHTED
        elif pt_norm in {"semantic"}:
            pt = PathType.SEMANTIC
        else:
            raise ValueError(f"Unsupported path_type: {path_type}")

        query = PathQuery(
            start_entity=start_entity,
            end_entity=end_entity,
            max_depth=max_depth,
            path_type=pt,
        )
        paths = tracker.find_paths(query)

        serialized_paths: List[Dict[str, Any]] = []
        lengths: List[int] = []
        for path in paths:
            serialized_paths.append(
                {
                    "start_entity": path.start_entity,
                    "end_entity": path.end_entity,
                    "entities": path.entities,
                    "predicates": path.predicates,
                    "length": path.length,
                    "total_weight": path.total_weight,
                    "path_type": path.path_type.value if hasattr(path.path_type, "value") else str(path.path_type),
                    "confidence": path.confidence,
                    "semantic_score": path.semantic_score,
                    "readable": path.to_readable_string(),
                }
            )
            lengths.append(int(path.length))

        avg_len = (sum(lengths) / len(lengths)) if lengths else 0.0

        return {
            "db_name": db_name,
            "branch": branch,
            "query": {
                "start_entity": start_entity,
                "end_entity": end_entity,
                "max_depth": max_depth,
                "path_type": pt.value,
            },
            "paths": serialized_paths,
            "statistics": {
                "total_paths": len(serialized_paths),
                "min_length": min(lengths) if lengths else 0,
                "max_length": max(lengths) if lengths else 0,
                "average_length": avg_len,
            },
            "analysis_timestamp": datetime.now(timezone.utc).isoformat(),
        }

    async def analyze_relationship_network(
        self,
        db_name: str,
        *,
        branch: str = "main",
    ) -> Dict[str, Any]:
        """Analyze relationship network health and statistics (no write)."""
        existing = await self.get_ontology(db_name, class_id=None, raise_if_missing=False, branch=branch)
        ontologies: List[OntologyResponse] = existing if isinstance(existing, list) else []

        all_relationships: List[Relationship] = []
        relationship_types: set[str] = set()
        entities: set[str] = set()

        for ontology in ontologies:
            entities.add(ontology.id)
            for rel in ontology.relationships or []:
                all_relationships.append(rel)
                relationship_types.add(rel.predicate)
                if rel.target:
                    entities.add(rel.target)

        summary = self.relationship_manager.generate_relationship_summary(all_relationships)

        validator = RelationshipValidator(existing_ontologies=ontologies)
        validation_results = validator.validate_multiple_ontologies(ontologies) if ontologies else []
        error_count = sum(1 for r in validation_results if r.severity == ValidationSeverity.ERROR)
        warning_count = sum(1 for r in validation_results if r.severity == ValidationSeverity.WARNING)

        detector = CircularReferenceDetector(max_cycle_depth=10)
        detector.build_relationship_graph(ontologies)
        cycles = detector.detect_all_cycles()
        critical_cycles = [c for c in cycles if c.severity == "critical"]
        warning_cycles = [c for c in cycles if c.severity == "warning"]

        total_entities = len(entities) if entities else len(ontologies)
        total_relationships = len(all_relationships)
        avg_connections = (total_relationships / total_entities) if total_entities else 0.0

        recommendations: List[str] = []
        if error_count:
            recommendations.append(f"âŒ Relationship validation errors detected: {error_count}")
        if warning_count:
            recommendations.append(f"âš ï¸ Relationship validation warnings detected: {warning_count}")
        if critical_cycles:
            recommendations.append(f"âŒ Critical cycles detected in relationship graph: {len(critical_cycles)}")
        if warning_cycles:
            recommendations.append(f"âš ï¸ Cycles detected (warning): {len(warning_cycles)}")
        if not recommendations:
            recommendations.append("ðŸ“ Relationship network looks healthy")

        return {
            "db_name": db_name,
            "branch": branch,
            "ontology_count": len(ontologies),
            "summary": summary,
            "graph_structure": {
                "total_entities": total_entities,
                "total_relationships": total_relationships,
                "relationship_types": sorted(relationship_types),
                "average_connections_per_entity": avg_connections,
            },
            "validation": {
                "errors": error_count,
                "warnings": warning_count,
                "issues_sample": [
                    {
                        "severity": r.severity.value if hasattr(r.severity, "value") else str(r.severity),
                        "code": r.code,
                        "message": r.message,
                        "field": r.field,
                    }
                    for r in validation_results[:25]
                ],
            },
            "cycle_analysis": {
                "total_cycles": len(cycles),
                "critical_cycles": len(critical_cycles),
                "warning_cycles": len(warning_cycles),
                "cycles_sample": [
                    {
                        "cycle_type": c.cycle_type.value if hasattr(c.cycle_type, "value") else str(c.cycle_type),
                        "path": c.path,
                        "predicates": c.predicates,
                        "length": c.length,
                        "severity": c.severity,
                        "message": c.message,
                    }
                    for c in cycles[:10]
                ],
            },
            "recommendations": recommendations,
            "analysis_timestamp": datetime.now(timezone.utc).isoformat(),
        }

    def convert_properties_to_relationships(
        self, 
        ontology: OntologyResponse
    ) -> OntologyResponse:
        """ì†ì„±ì„ ê´€ê³„ë¡œ ë³€í™˜"""
        return self.property_converter.convert(ontology)

    # ==========================================
    # Utility Methods
    # ==========================================
    
    def clear_cache(self, db_name: Optional[str] = None):
        """ìºì‹œ ì´ˆê¸°í™”"""
        if db_name:
            self._ontology_cache.pop(db_name, None)
        else:
            self._ontology_cache.clear()

    async def ping(self) -> bool:
        """ì„œë²„ ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            # Try to list databases as a ping test
            await self.list_databases()
            return True
        except Exception:
            return False

    def get_connection_info(self) -> ConnectionConfig:
        """í˜„ìž¬ ì—°ê²° ì •ë³´ ë°˜í™˜"""
        return self.connection_info

    async def __aenter__(self):
        """Async context manager entry"""
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit"""
        await self.close()
