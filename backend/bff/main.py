"""
BFF (Backend for Frontend) Service
ì‚¬ìš©ì ì¹œí™”ì ì¸ ë ˆì´ë¸” ê¸°ë°˜ ì˜¨í†¨ë¡œì§€ ê´€ë¦¬ ì„œë¹„ìŠ¤
"""

# Load environment variables first (before other imports)
from dotenv import load_dotenv  # pylint: disable=wrong-import-order
load_dotenv()

# Standard library imports
import json
import logging
from contextlib import asynccontextmanager
from typing import Any, Dict, Optional

# Third party imports
import httpx
from fastapi import Depends, FastAPI, HTTPException, Request, status
from fastapi.responses import JSONResponse

# Shared service factory import
from shared.services.service_factory import BFF_SERVICE_INFO, create_fastapi_service, run_service
from shared.models.ontology import (
    OntologyCreateRequestBFF,
    OntologyResponse,
    OntologyUpdateRequest,
    QueryRequest,
    QueryResponse,
)
from shared.models.requests import (
    ApiResponse,
    BranchCreateRequest,
    CheckoutRequest,
    CommitRequest,
    MergeRequest,
    RollbackRequest,
)
from shared.security.input_sanitizer import (
    SecurityViolationError,
    sanitize_input,
    validate_class_id,
    validate_db_name,
)
from shared.utils.label_mapper import LabelMapper
from shared.dependencies import configure_type_inference_service

# Production middleware imports - temporarily disabled
# from middleware.error_handler import setup_error_handlers
# from middleware.validation_middleware import setup_validation_middleware

# Documentation enhancements - temporarily disabled
# from docs.openapi_enhancements import setup_enhanced_openapi


# ê³µí†µ ìœ í‹¸ë¦¬í‹° import - temporarily disabled
# from utils.language import get_accept_language


# Fallback function
def get_accept_language(request):
    return "ko"


# OMS í´ë¼ì´ì–¸íŠ¸ ë˜í¼ import

# BFF specific imports
from bff.dependencies import (
    TerminusService,
    get_label_mapper,
    get_oms_client,
    get_terminus_service,
    set_label_mapper,
    set_oms_client,
)
from bff.routers import database, health, mapping, merge_conflict, ontology, query, instances, instance_async, websocket
from bff.services.funnel_type_inference_adapter import FunnelHTTPTypeInferenceAdapter
from bff.services.oms_client import OMSClient

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, 
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    force=True
)
logger = logging.getLogger(__name__)

# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
oms_client: Optional[OMSClient] = None
label_mapper: Optional[LabelMapper] = None
websocket_notification_service = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬"""
    # ì‹œì‘ ì‹œ
    global oms_client, label_mapper, websocket_notification_service

    logger.info("BFF ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")

    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    import os
    oms_base_url = os.getenv("OMS_BASE_URL", "http://localhost:8000")
    oms_client = OMSClient(oms_base_url)
    label_mapper = LabelMapper()

    # dependenciesì— ì„œë¹„ìŠ¤ ì„¤ì •
    set_oms_client(oms_client)
    set_label_mapper(label_mapper)

    try:
        # OMS ì„œë¹„ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
        is_healthy = await oms_client.check_health()
        if is_healthy:
            logger.info("OMS ì„œë¹„ìŠ¤ ì—°ê²° ì„±ê³µ")
        else:
            logger.warning("OMS ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨ - ì„œë¹„ìŠ¤ëŠ” ê³„ì† ì‹œì‘ë©ë‹ˆë‹¤")
    except (httpx.HTTPError, httpx.TimeoutException, ConnectionError) as e:
        logger.error(f"OMS ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        # ì—°ê²° ì‹¤íŒ¨í•´ë„ ì„œë¹„ìŠ¤ëŠ” ì‹œì‘ (ë‚˜ì¤‘ì— ì¬ì—°ê²° ì‹œë„)

    # Configure type inference service with Funnel HTTP implementation
    logger.info("Configuring type inference service...")
    type_inference_adapter = FunnelHTTPTypeInferenceAdapter()
    configure_type_inference_service(type_inference_adapter)
    logger.info("Type inference service configured successfully")

    # Initialize WebSocket notification service
    try:
        logger.info("Initializing WebSocket notification service...")
        from shared.services import create_redis_service, get_notification_service
        
        # Create Redis service for WebSocket
        redis_service = create_redis_service()
        await redis_service.connect()
        
        # Create and start WebSocket notification service
        websocket_notification_service = get_notification_service(redis_service)
        await websocket_notification_service.start()
        
        logger.info("WebSocket notification service started successfully")
    except Exception as e:
        logger.error(f"Failed to initialize WebSocket services: {e}")
        # Continue without WebSocket - service can still work without real-time updates

    logger.info("BFF Service startup complete")

    yield

    # ì¢…ë£Œ ì‹œ
    logger.info("BFF ì„œë¹„ìŠ¤ ì¢…ë£Œ ì¤‘...")
    if oms_client:
        await oms_client.close()
    if hasattr(type_inference_adapter, "close"):
        await type_inference_adapter.close()
    if websocket_notification_service:
        await websocket_notification_service.stop()
        logger.info("WebSocket notification service stopped")


# FastAPI ì•± ìƒì„± - Service Factory ì‚¬ìš©
app = create_fastapi_service(
    service_info=BFF_SERVICE_INFO,
    custom_lifespan=lifespan,
    include_health_check=False,  # ê¸°ì¡´ ë¼ìš°í„°ì—ì„œ ì²˜ë¦¬
    include_logging_middleware=True
)


# ì˜ì¡´ì„± ì£¼ì…


# Production-grade error handling is now managed by middleware
# See setup_error_handlers() and setup_validation_middleware() above


# API ì—”ë“œí¬ì¸íŠ¸
# Note: Root and health endpoints moved to health router


# Note: Database endpoints moved to database router


# Note: Database creation moved to database router (POST /api/v1/databases)


# ğŸ”¥ THINK ULTRA! Commented out duplicate route - using router version instead
# @app.post("/database/{db_name}/ontology", response_model=OntologyResponse)
# async def create_ontology(
#     db_name: str,
#     ontology_data: OntologyCreateRequestBFF,
#     request: Request,
#     oms: OMSClient = Depends(get_oms_client),
#     mapper: LabelMapper = Depends(get_label_mapper),
# ):
#     """ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ìƒì„±"""
#     lang = get_accept_language(request)
# 
#     try:
        # ì…ë ¥ ë°ì´í„° ë³´ì•ˆ ê²€ì¦
#         db_name = validate_db_name(db_name)
# 
        # ì˜¨í†¨ë¡œì§€ ë°ì´í„° ì •í™”
#         sanitized_data = sanitize_input(ontology_data.dict())
# 
        # ê³µí†µ ID ìƒì„± ìœ í‹¸ë¦¬í‹° ì‚¬ìš©
#         from shared.utils.id_generator import generate_ontology_id
# 
        # ë ˆì´ë¸”ë¡œë¶€í„° ID ìƒì„±
#         class_id = generate_ontology_id(
#             label=sanitized_data.get("label"),
#             preserve_camel_case=True,
#             handle_korean=True,
#             default_fallback="UnnamedClass",
#         )
# 
        # ìƒì„±ëœ IDë¥¼ ë°ì´í„°ì— ì¶”ê°€
#         sanitized_data["id"] = class_id
# 
        # í´ë˜ìŠ¤ ID ê²€ì¦
#         sanitized_data["id"] = validate_class_id(sanitized_data["id"])
# 
        # Label ë§¤í•‘ ë“±ë¡
#         await mapper.register_class(
#             db_name=db_name,
#             class_id=sanitized_data.get("id"),
#             label=sanitized_data.get("label"),
#             description=sanitized_data.get("description"),
#         )
# 
        # ì†ì„± ë§¤í•‘ ë“±ë¡ (ì •í™”ëœ ë°ì´í„° ì‚¬ìš©)
#         for prop in sanitized_data.get("properties", []):
#             prop_sanitized = sanitize_input(prop) if isinstance(prop, dict) else prop
#             await mapper.register_property(
#                 db_name=db_name,
#                 class_id=sanitized_data.get("id"),
#                 property_id=(
#                     prop_sanitized.get("name")
#                     if isinstance(prop_sanitized, dict)
#                     else getattr(prop_sanitized, "name", None)
#                 ),
#                 label=(
#                     prop_sanitized.get("label")
#                     if isinstance(prop_sanitized, dict)
#                     else getattr(prop_sanitized, "label", None)
#                 ),
#             )
# 
        # ê´€ê³„ ë§¤í•‘ ë“±ë¡ (ì •í™”ëœ ë°ì´í„° ì‚¬ìš©)
#         for rel in sanitized_data.get("relationships", []):
#             rel_sanitized = sanitize_input(rel) if isinstance(rel, dict) else rel
#             await mapper.register_relationship(
#                 db_name=db_name,
#                 predicate=(
#                     rel_sanitized.get("predicate")
#                     if isinstance(rel_sanitized, dict)
#                     else getattr(rel_sanitized, "predicate", None)
#                 ),
#                 label=(
#                     rel_sanitized.get("label")
#                     if isinstance(rel_sanitized, dict)
#                     else getattr(rel_sanitized, "label", None)
#                 ),
#             )
# 
        # ğŸ”¥ THINK ULTRA! Transform properties for OMS compatibility
        # Convert 'target' to 'linkTarget' for link-type properties
#         def transform_properties_for_oms(data):
#             if 'properties' in data and isinstance(data['properties'], list):
#                 for prop in data['properties']:
#                     if isinstance(prop, dict):
                        # Convert target to linkTarget for link type properties
#                         if prop.get('type') == 'link' and 'target' in prop:
#                             prop['linkTarget'] = prop.pop('target')
#                             logger.info(f"ğŸ”§ Converted property '{prop.get('name')}' target -> linkTarget: {prop.get('linkTarget')}")
#                         
                        # Handle array properties with link items
#                         if prop.get('type') == 'array' and 'items' in prop:
#                             items = prop['items']
#                             if isinstance(items, dict) and items.get('type') == 'link' and 'target' in items:
#                                 items['linkTarget'] = items.pop('target')
#                                 logger.info(f"ğŸ”§ Converted array property '{prop.get('name')}' items target -> linkTarget: {items.get('linkTarget')}")
#         
        # Apply transformation
#         transform_properties_for_oms(sanitized_data)
#         
        # OMSë¥¼ í†µí•´ ì˜¨í†¨ë¡œì§€ ìƒì„± (ìƒì„±ëœ IDë¥¼ í¬í•¨í•œ ì •í™”ëœ ë°ì´í„° ì‚¬ìš©)
#         logger.info(
#             f"Sending to OMS create_ontology: {json.dumps(sanitized_data, ensure_ascii=False)}"
#         )
#         result = await oms.create_ontology(db_name, sanitized_data)
# 
        # ì‘ë‹µ ìƒì„±
#         label_text = sanitized_data.get("label", "")
#         if isinstance(label_text, dict):
            # Multilingual label - get by language with fallback
#             label_text = label_text.get(lang) or label_text.get("ko") or label_text.get("en") or ""
# 
        # OMS ì‘ë‹µì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
        # OMSëŠ” dataì— class ID ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•¨
#         oms_data = result.get("data", [])
#         if isinstance(oms_data, list) and len(oms_data) > 0:
#             created_class_id = oms_data[0]
#         else:
#             created_class_id = sanitized_data.get("id")
# 
        # Create OntologyBase object
#         from shared.models.ontology import OntologyBase
# 
#         ontology_base = OntologyBase(
#             id=created_class_id,
#             label=ontology_data.label,
#             description=ontology_data.description,
#             properties=ontology_data.properties,
#             relationships=ontology_data.relationships,
#             metadata={"created": True, "database": db_name},
#         )
# 
#         return OntologyResponse(
#             status="success",
#             message=f"'{label_text}' ì˜¨í†¨ë¡œì§€ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤",
#             data=ontology_base,
#         )
# 
#     except SecurityViolationError as e:
#         logger.warning(f"Security violation in create_ontology: {e}")
#         raise HTTPException(
#             status_code=status.HTTP_400_BAD_REQUEST,
#             detail="ì…ë ¥ ë°ì´í„°ì— ë³´ì•ˆ ìœ„ë°˜ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤",
#         )
#     except HTTPException:
#         raise
#     except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
#         logger.error(f"Failed to create ontology: {e}")
#         import traceback
# 
#         logger.error(f"Traceback: {traceback.format_exc()}")
#         raise HTTPException(
#             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
#             detail=f"ì˜¨í†¨ë¡œì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
#         )


@app.get("/database/{db_name}/ontology/{class_label}")
async def get_ontology(
    db_name: str,
    class_label: str,
    request: Request,
    oms: OMSClient = Depends(get_oms_client),
    mapper: LabelMapper = Depends(get_label_mapper),
):
    """ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ì¡°íšŒ (ë ˆì´ë¸” ê¸°ë°˜)"""
    lang = get_accept_language(request)

    try:
        # ë ˆì´ë¸”ì„ IDë¡œ ë³€í™˜
        class_id = await mapper.get_class_id(db_name, class_label, lang)
        if not class_id:
            # ë‹¤ë¥¸ ì–¸ì–´ë¡œ ì‹œë„
            for fallback_lang in ["ko", "en", "ja", "zh"]:
                class_id = await mapper.get_class_id(db_name, class_label, fallback_lang)
                if class_id:
                    break

        if not class_id:
            # class_labelì´ ì´ë¯¸ IDì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            class_id = class_label
            logger.warning(f"No label mapping found for '{class_label}', using as ID directly")

        # OMSì—ì„œ ì¡°íšŒ
        ontology = await oms.get_ontology(db_name, class_id)

        if not ontology:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"'{class_label}' ì˜¨í†¨ë¡œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
            )

        # Extract the actual ontology data from OMS response
        if isinstance(ontology, dict) and "data" in ontology:
            ontology_data = ontology["data"]
        else:
            ontology_data = ontology

        # ë ˆì´ë¸” ì •ë³´ ì¶”ê°€
        display_result = await mapper.convert_to_display(db_name, ontology_data, lang)

        # Ensure required fields for OntologyBase
        if not display_result.get("id"):
            display_result["id"] = class_id
        if not display_result.get("label"):
            display_result["label"] = class_label

        # Use simple English strings for labels and descriptions
        from shared.models.ontology import OntologyBase
        
        label_value = display_result.get("label")
        if isinstance(label_value, str):
            # Use string directly
            label_value = label_value
        elif isinstance(label_value, dict):
            # Extract English label from dict
            label_value = label_value.get("en", label_value.get("ko", class_label))
        elif not label_value:
            # Fallback to class_label
            label_value = class_label
        
        desc_value = display_result.get("description")
        if isinstance(desc_value, str):
            # Use string directly
            desc_value = desc_value
        elif isinstance(desc_value, dict):
            # Extract English description from dict
            desc_value = desc_value.get("en", desc_value.get("ko", None))
        else:
            desc_value = None

        # Return the ontology data directly as a dictionary
        ontology_result = {
            "id": display_result.get("id"),
            "label": label_value,
            "description": desc_value,
            "properties": display_result.get("properties", []),
            "relationships": display_result.get("relationships", []),
            "parent_class": display_result.get("parent_class"),
            "abstract": display_result.get("abstract", False),
            "metadata": display_result.get("metadata"),
            "created_at": display_result.get("created_at"),
            "updated_at": display_result.get("updated_at"),
        }
        
        return ontology_result

    except HTTPException:
        raise
    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to get ontology: {e}")
        import traceback

        logger.error(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì˜¨í†¨ë¡œì§€ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
        )


@app.put("/database/{db_name}/ontology/{class_label}")
async def update_ontology(
    db_name: str,
    class_label: str,
    ontology_data: OntologyUpdateRequest,
    request: Request,
    oms: OMSClient = Depends(get_oms_client),
    mapper: LabelMapper = Depends(get_label_mapper),
):
    """ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ì—…ë°ì´íŠ¸"""
    lang = get_accept_language(request)

    try:
        # ë ˆì´ë¸”ì„ IDë¡œ ë³€í™˜
        class_id = await mapper.get_class_id(db_name, class_label, lang)
        if not class_id:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"'{class_label}' ì˜¨í†¨ë¡œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
            )

        # ë§¤í•‘ ì—…ë°ì´íŠ¸
        await mapper.update_mappings(db_name, ontology_data.dict(exclude_unset=True))

        # OMSë¥¼ í†µí•´ ì—…ë°ì´íŠ¸
        result = await oms.update_ontology(db_name, class_id, ontology_data)

        return OntologyResponse(
            status="success", message=f"'{class_label}' ì˜¨í†¨ë¡œì§€ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤", data=result
        )

    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to update ontology: {e}")
        raise


@app.delete("/database/{db_name}/ontology/{class_label}")
async def delete_ontology(
    db_name: str,
    class_label: str,
    request: Request,
    oms: OMSClient = Depends(get_oms_client),
    mapper: LabelMapper = Depends(get_label_mapper),
):
    """ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ì‚­ì œ"""
    lang = get_accept_language(request)

    try:
        # ë ˆì´ë¸”ì„ IDë¡œ ë³€í™˜
        class_id = await mapper.get_class_id(db_name, class_label, lang)
        if not class_id:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"'{class_label}' ì˜¨í†¨ë¡œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
            )

        # OMSë¥¼ í†µí•´ ì‚­ì œ
        await oms.delete_ontology(db_name, class_id)

        # ë§¤í•‘ ì •ë³´ ì‚­ì œ
        await mapper.remove_class(db_name, class_id)

        return OntologyResponse(
            status="success",
            message=f"'{class_label}' ì˜¨í†¨ë¡œì§€ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤",
            data={"deleted_class": class_label},
        )

    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to delete ontology: {e}")
        raise


@app.get("/database/{db_name}/ontologies")
async def list_ontologies(
    db_name: str,
    request: Request,
    class_type: str = "sys:Class",
    oms: OMSClient = Depends(get_oms_client),
    mapper: LabelMapper = Depends(get_label_mapper),
):
    """ì˜¨í†¨ë¡œì§€ ëª©ë¡ ì¡°íšŒ"""
    lang = get_accept_language(request)

    try:
        # OMSì—ì„œ ì¡°íšŒ
        response = await oms.list_ontologies(db_name)
        
        # Extract the actual ontology list from the response
        if isinstance(response, dict) and "data" in response and "ontologies" in response["data"]:
            ontologies = response["data"]["ontologies"]
        else:
            ontologies = []

        # ê° ì˜¨í†¨ë¡œì§€ì— ë ˆì´ë¸” ì •ë³´ ì¶”ê°€ - CRITICAL BUG FIX: ë™ê¸°í™” ì˜¤ë¥˜ í•´ê²°
        display_results = []
        for ontology in ontologies:
            try:
                # CRITICAL: ë°˜ë“œì‹œ dict íƒ€ì…ì¸ì§€ ë¨¼ì € í™•ì¸
                if not isinstance(ontology, dict):
                    logger.error(f"CRITICAL SYNC ERROR: Non-dict ontology received: {type(ontology)} = {ontology}")
                    continue
                    
                display_result = await mapper.convert_to_display(db_name, ontology, lang)
                display_results.append(display_result)
            except (ValueError, KeyError, AttributeError) as e:
                # ontologyê°€ dictì¸ì§€ í™•ì¸
                ontology_id = ontology.get('id', 'unknown') if isinstance(ontology, dict) else str(ontology)
                logger.warning(f"Failed to convert ontology {ontology_id}: {e}")
                # ê¸°ë³¸ê°’ìœ¼ë¡œ ìµœì†Œí•œì˜ ì •ë³´ ì œê³µ (ì›ë³¸ ë°ì´í„°ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
                fallback_ontology = {
                    "id": ontology_id,
                    "label": {"ko": ontology_id, "en": ontology_id},
                    "description": {"ko": "ë ˆì´ë¸” ë³€í™˜ ì‹¤íŒ¨", "en": "Label conversion failed"},
                    "properties": {},
                }
                display_results.append(fallback_ontology)

        return {
            "ontologies": display_results,
            "count": len(display_results),
            "class_type": class_type,
        }

    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to list ontologies: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))


@app.post("/database/{db_name}/query", response_model=QueryResponse)
async def query_ontology(
    db_name: str,
    query: QueryRequest,
    request: Request,
    oms: OMSClient = Depends(get_oms_client),
    mapper: LabelMapper = Depends(get_label_mapper),
):
    """ë ˆì´ë¸” ê¸°ë°˜ ì¿¼ë¦¬ ì‹¤í–‰"""
    lang = get_accept_language(request)

    try:
        # ì¿¼ë¦¬ ê²€ì¦ - CRITICAL BUG FIX: í•­ìƒ ì‹¤í–‰ë˜ë„ë¡ ìˆ˜ì •
        # class_idì™€ class_label ëª¨ë‘ ì²˜ë¦¬í•˜ëŠ” ë¡œì§ ì¶”ê°€
        if query.class_id:
            # class_idê°€ ì œê³µëœ ê²½ìš° ì§ì ‘ ì‚¬ìš©
            class_id = query.class_id
            logger.debug(f"Using provided class_id: {class_id}")
        elif query.class_label:
            # class_labelì´ ì œê³µëœ ê²½ìš° ë§¤í•‘ì„ í†µí•´ class_id ì¡°íšŒ
            class_id = await mapper.get_class_id(db_name, query.class_label, lang)
            if not class_id:
                raise ValueError(f"í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {query.class_label}")
            logger.debug(f"Converted class_label '{query.class_label}' to class_id: {class_id}")
        else:
            raise ValueError("class_id ë˜ëŠ” class_labelì´ ì œê³µë˜ì–´ì•¼ í•©ë‹ˆë‹¤")

        # ë ˆì´ë¸” ê¸°ë°˜ ì¿¼ë¦¬ë¥¼ ë‚´ë¶€ ID ê¸°ë°˜ìœ¼ë¡œ ë³€í™˜
        internal_query = await mapper.convert_query_to_internal(db_name, query.dict(), lang)

        # ì¿¼ë¦¬ ì‹¤í–‰
        results = await oms.query_ontologies(db_name, internal_query)

        # ê²°ê³¼ë¥¼ ë ˆì´ë¸” ê¸°ë°˜ìœ¼ë¡œ ë³€í™˜ - CRITICAL BUG FIX: OMS ì‘ë‹µ í˜•ì‹ ì²˜ë¦¬
        display_results = []
        
        # OMS ì‘ë‹µ í˜•ì‹ ì •ê·œí™”
        if isinstance(results, list):
            # OMSê°€ ì§ì ‘ listë¥¼ ë°˜í™˜í•œ ê²½ìš°
            result_items = results
        elif isinstance(results, dict):
            # OMSê°€ dict í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•œ ê²½ìš°
            result_items = results.get("data", {}).get("results", []) if isinstance(results.get("data"), dict) else results.get("data", [])
        else:
            result_items = []
            
        for item in result_items:
            display_item = await mapper.convert_to_display(db_name, item, lang)
            display_results.append(display_item)

        return QueryResponse(
            status="success",
            message="ì¿¼ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤",
            data=display_results,
            count=len(display_results),
        )

    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to execute query: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))


@app.get("/database/{db_name}/ontology/{class_id}/schema")
async def get_property_schema(
    db_name: str,
    class_id: str,
    request: Request,
    oms: OMSClient = Depends(get_oms_client),
    mapper: LabelMapper = Depends(get_label_mapper),
):
    """í´ë˜ìŠ¤ì˜ ì†ì„± ìŠ¤í‚¤ë§ˆ ì¡°íšŒ"""
    lang = get_accept_language(request)

    try:
        # ì˜¨í†¨ë¡œì§€ ì •ë³´ ì¡°íšŒ (ìŠ¤í‚¤ë§ˆ í¬í•¨)
        ontology = await oms.get_ontology(db_name, class_id)

        if not ontology:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"ì˜¨í†¨ë¡œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {class_id}",
            )

        # ë ˆì´ë¸” ì •ë³´ ì¶”ê°€
        schema = ontology.get("data", {})
        for prop_id, prop_info in schema.get("properties", {}).items():
            prop_label = await mapper.get_property_label(db_name, class_id, prop_id, lang)
            if prop_label:
                prop_info["label"] = prop_label

        return {"status": "success", "data": schema}

    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to get property schema: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))


@app.post("/database/{db_name}/mappings/export")
async def export_mappings(db_name: str, mapper: LabelMapper = Depends(get_label_mapper)):
    """ë ˆì´ë¸” ë§¤í•‘ ë‚´ë³´ë‚´ê¸°"""
    try:
        mappings = await mapper.export_mappings(db_name)
        return {
            "status": "success",
            "message": f"'{db_name}' ë°ì´í„°ë² ì´ìŠ¤ì˜ ë§¤í•‘ì„ ë‚´ë³´ëƒˆìŠµë‹ˆë‹¤",
            "data": mappings,
        }
    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to export mappings: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))


@app.post("/database/{db_name}/mappings/import")
async def import_mappings(
    db_name: str, mappings: Dict[str, Any], mapper: LabelMapper = Depends(get_label_mapper)
):
    """ë ˆì´ë¸” ë§¤í•‘ ê°€ì ¸ì˜¤ê¸°"""
    try:
        # DB ì´ë¦„ ì¼ì¹˜ í™•ì¸
        if mappings.get("db_name") != db_name:
            raise ValueError("ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")

        await mapper.import_mappings(mappings)

        return {"status": "success", "message": f"'{db_name}' ë°ì´í„°ë² ì´ìŠ¤ì˜ ë§¤í•‘ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤"}
    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to import mappings: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))


# ===== ë²„ì „ ê´€ë¦¬ API (Git-like features) =====


@app.get("/database/{db_name}/branches")
async def list_branches(db_name: str, oms: OMSClient = Depends(get_oms_client)):
    """ë¸Œëœì¹˜ ëª©ë¡ ì¡°íšŒ"""
    try:
        # ì‹¤ì œ OMS API í˜¸ì¶œ
        response = await oms.list_branches(db_name)
        branches = response.get("data", {}).get("branches", [])
        return {"branches": branches, "count": len(branches)}
    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to list branches: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))


@app.post("/database/{db_name}/branch", response_model=ApiResponse)
async def create_branch(
    db_name: str,
    request: BranchCreateRequest,
    terminus: TerminusService = Depends(get_terminus_service),
):
    """
    ìƒˆ ë¸Œëœì¹˜ ìƒì„±

    Pydantic modelì„ ì‚¬ìš©í•œ íƒ€ì… ì•ˆì „ ì—”ë“œí¬ì¸íŠ¸
    """
    # RBAC ê²€ì‚¬ (í–¥í›„ êµ¬í˜„)
    # TODO: ì‚¬ìš©ì ê¶Œí•œ í™•ì¸
    # - ë¸Œëœì¹˜ ìƒì„± ê¶Œí•œ í™•ì¸
    # - íŠ¹ì • ë„¤ì´ë° ê·œì¹™ ì ìš© (ì˜ˆ: feature/*, hotfix/*)

    try:
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ ê²€ì¦ (Pydanticì´ request ìœ íš¨ì„± ê²€ì¦ ì²˜ë¦¬)
        validated_db_name = validate_db_name(db_name)

        # Pydantic ëª¨ë¸ì—ì„œ ì§ì ‘ ê°’ ì ‘ê·¼ (ìë™ ê²€ì¦ë¨)
        result = await terminus.create_branch(
            validated_db_name, request.branch_name, request.from_branch
        )

        return {
            "status": "success",
            "message": f"ë¸Œëœì¹˜ '{request.branch_name}'ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤",
            "data": result,
        }
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to create branch: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))


@app.delete("/database/{db_name}/branch/{branch_name}")
async def delete_branch(
    db_name: str, branch_name: str, terminus: TerminusService = Depends(get_terminus_service)
):
    """ë¸Œëœì¹˜ ì‚­ì œ"""
    # RBAC ê²€ì‚¬ (í–¥í›„ êµ¬í˜„)
    # TODO: ë¸Œëœì¹˜ ì‚­ì œ ê¶Œí•œ í™•ì¸
    # - main, production ë“± ë³´í˜¸ëœ ë¸Œëœì¹˜ ì‚­ì œ ë°©ì§€
    # - ë¸Œëœì¹˜ ì†Œìœ ì ë˜ëŠ” ê´€ë¦¬ìë§Œ ì‚­ì œ ê°€ëŠ¥

    try:
        result = await terminus.delete_branch(db_name, branch_name)

        return {
            "status": "success",
            "message": f"ë¸Œëœì¹˜ '{branch_name}'ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤",
            "data": result,
        }
    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to delete branch: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))


@app.post("/database/{db_name}/checkout", response_model=ApiResponse)
async def checkout(
    db_name: str,
    request: CheckoutRequest,
    terminus: TerminusService = Depends(get_terminus_service),
):
    """
    ë¸Œëœì¹˜ ë˜ëŠ” ì»¤ë°‹ìœ¼ë¡œ ì²´í¬ì•„ì›ƒ

    Pydantic modelì„ ì‚¬ìš©í•œ íƒ€ì… ì•ˆì „ ì—”ë“œí¬ì¸íŠ¸
    """
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ ê²€ì¦ (Pydanticì´ request ìœ íš¨ì„± ê²€ì¦ ì²˜ë¦¬)
        validated_db_name = validate_db_name(db_name)

        # Pydantic ëª¨ë¸ì—ì„œ ì§ì ‘ ê°’ ì ‘ê·¼ (ìë™ ê²€ì¦ë¨)
        result = await terminus.checkout(validated_db_name, request.target, request.target_type)

        return {
            "status": "success",
            "message": f"{request.target_type} '{request.target}'ë¡œ ì²´í¬ì•„ì›ƒí–ˆìŠµë‹ˆë‹¤",
            "data": result,
        }
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to checkout: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))


@app.post("/database/{db_name}/commit", response_model=ApiResponse)
async def commit_changes(
    db_name: str, request: CommitRequest, terminus: TerminusService = Depends(get_terminus_service)
):
    """
    í˜„ì¬ ë³€ê²½ì‚¬í•­ ì»¤ë°‹

    Pydantic modelì„ ì‚¬ìš©í•œ íƒ€ì… ì•ˆì „ ì—”ë“œí¬ì¸íŠ¸
    """
    # RBAC ê²€ì‚¬ (í–¥í›„ êµ¬í˜„)
    # TODO: ì»¤ë°‹ ê¶Œí•œ í™•ì¸
    # - ë³´í˜¸ëœ ë¸Œëœì¹˜(main, production)ì— ëŒ€í•œ ì§ì ‘ ì»¤ë°‹ ë°©ì§€
    # - ë¸Œëœì¹˜ë³„ ì»¤ë°‹ ê¶Œí•œ í™•ì¸

    try:
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ ê²€ì¦ (Pydanticì´ request ìœ íš¨ì„± ê²€ì¦ ì²˜ë¦¬)
        validated_db_name = validate_db_name(db_name)

        # Pydantic ëª¨ë¸ì—ì„œ ì§ì ‘ ê°’ ì ‘ê·¼ (ìë™ ê²€ì¦ë¨)
        result = await terminus.commit_changes(
            validated_db_name, request.message, request.author, None  # Use current branch
        )

        return {"status": "success", "message": "ë³€ê²½ì‚¬í•­ì´ ì»¤ë°‹ë˜ì—ˆìŠµë‹ˆë‹¤", "data": result}
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to commit: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))


@app.get("/database/{db_name}/history")
async def get_commit_history(
    db_name: str,
    branch: Optional[str] = None,
    limit: int = 50,
    offset: int = 0,
    terminus: TerminusService = Depends(get_terminus_service),
):
    """ì»¤ë°‹ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    try:
        commits = await terminus.get_commit_history(db_name, branch, limit, offset)

        return {"commits": commits, "count": len(commits), "limit": limit, "offset": offset}
    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to get commit history: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))


@app.get("/database/{db_name}/diff")
async def get_diff(
    db_name: str, base: str, compare: str, terminus: TerminusService = Depends(get_terminus_service)
):
    """
    ë‘ ë¸Œëœì¹˜/ì»¤ë°‹ ê°„ ì°¨ì´ ë¹„êµ

    Query params:
    - base: ê¸°ì¤€ ë¸Œëœì¹˜ ë˜ëŠ” ì»¤ë°‹
    - compare: ë¹„êµ ë¸Œëœì¹˜ ë˜ëŠ” ì»¤ë°‹
    """
    try:
        if not base or not compare:
            raise ValueError("baseì™€ compareëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤")

        diff = await terminus.get_diff(db_name, base, compare)

        return {"status": "success", "data": diff}
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to get diff: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))


@app.post("/database/{db_name}/merge", response_model=ApiResponse)
async def merge_branches(
    db_name: str, request: MergeRequest, terminus: TerminusService = Depends(get_terminus_service)
):
    """
    ë¸Œëœì¹˜ ë³‘í•©

    Body:
    {
        "source_branch": "feature-color",
        "target_branch": "main",
        "strategy": "merge",  # "merge" or "rebase"
        "message": "Merge feature-color into main",  # optional
        "author": "user@example.com"  # optional
    }
    """
    # RBAC ê²€ì‚¬ (í–¥í›„ êµ¬í˜„)
    # TODO: ë³‘í•© ê¶Œí•œ í™•ì¸
    # - íƒ€ê²Ÿ ë¸Œëœì¹˜ì— ëŒ€í•œ ì“°ê¸° ê¶Œí•œ í™•ì¸
    # - ë³´í˜¸ëœ ë¸Œëœì¹˜ ë³‘í•© ì‹œ ìŠ¹ì¸ í”„ë¡œì„¸ìŠ¤ í™•ì¸
    # - Pull Request ìŠ¤íƒ€ì¼ì˜ ë¦¬ë·° í”„ë¡œì„¸ìŠ¤ ê³ ë ¤

    try:
        # Enhanced business logic validation
        if request.source_branch == request.target_branch:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Source and target branches cannot be the same",
            )

        # Validate database name
        validate_db_name(db_name)

        # Check if branches exist before attempting merge
        try:
            # This will throw an exception if branch doesn't exist
            await terminus.get_branch_info(db_name, request.source_branch)
            await terminus.get_branch_info(db_name, request.target_branch)
        except Exception as e:
            if "not found" in str(e).lower() or "does not exist" in str(e).lower():
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"One or both branches do not exist: {str(e)}",
                )
            raise

        # Protected branch validation
        protected_branches = ["main", "master", "production", "prod"]
        if request.target_branch.lower() in protected_branches:
            logger.warning(
                f"Merge attempt to protected branch '{request.target_branch}' from '{request.source_branch}'"
            )
            # In production, this would check user permissions

        # Check for potential conflicts before merge
        if request.strategy == "rebase" and not request.author:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Author is required for rebase strategy",
            )

        result = await terminus.merge_branches(
            db_name,
            request.source_branch,
            request.target_branch,
            request.strategy,
            request.message,
            request.author,
        )

        if result.get("status") == "conflict":
            return JSONResponse(status_code=status.HTTP_409_CONFLICT, content=result)

        return {
            "status": "success",
            "message": f"'{request.source_branch}'ê°€ '{request.target_branch}'ë¡œ ë³‘í•©ë˜ì—ˆìŠµë‹ˆë‹¤",
            "data": result,
        }
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to merge branches: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))


@app.post("/database/{db_name}/rollback", response_model=ApiResponse)
async def rollback(
    db_name: str,
    request: RollbackRequest,
    terminus: TerminusService = Depends(get_terminus_service),
):
    """
    íŠ¹ì • ì»¤ë°‹ìœ¼ë¡œ ë¡¤ë°±

    Body:
    {
        "target_commit": "commit_123",
        "create_branch": true,  # optional, default: true
        "branch_name": "rollback-123"  # optional
    }
    """
    # RBAC ê²€ì‚¬ (í–¥í›„ êµ¬í˜„)
    # TODO: ë¡¤ë°± ê¶Œí•œ í™•ì¸
    # - ë¡¤ë°± ê¶Œí•œì„ ê°€ì§„ ì‚¬ìš©ìë§Œ ìˆ˜í–‰ ê°€ëŠ¥
    # - í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ì¶”ê°€ ìŠ¹ì¸ í•„ìš”

    try:
        # Enhanced rollback validation
        validate_db_name(db_name)

        # Validate commit ID format (should be hexadecimal and minimum length)
        if len(request.target_commit) < 7:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Commit ID must be at least 7 characters long",
            )

        # Branch name validation when creating new branch
        if request.create_branch and request.branch_name:
            # Prevent overwriting existing branches
            try:
                await terminus.get_branch_info(db_name, request.branch_name)
                # If we get here, branch exists
                raise HTTPException(
                    status_code=status.HTTP_409_CONFLICT,
                    detail=f"Branch '{request.branch_name}' already exists. Choose a different name.",
                )
            except Exception as e:
                # Branch doesn't exist, which is what we want
                if "not found" not in str(e).lower() and "does not exist" not in str(e).lower():
                    # Some other error occurred
                    raise

        # Generate default rollback branch name if not provided
        if request.create_branch and not request.branch_name:
            from datetime import datetime

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            request.branch_name = f"rollback_{request.target_commit[:8]}_{timestamp}"

        # Safety check: Verify the target commit exists
        try:
            # This would verify commit exists in the database
            # In a real implementation, you'd check commit history
            pass  # Placeholder for commit existence validation
        except Exception as e:
            if "not found" in str(e).lower():
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"Commit '{request.target_commit}' not found",
                )

        # Protected branch safety checks
        current_branch = "main"  # In real implementation, get current branch
        protected_branches = ["main", "master", "production", "prod"]
        if not request.create_branch and current_branch.lower() in protected_branches:
            logger.warning(
                f"Attempting rollback on protected branch '{current_branch}' to commit '{request.target_commit}'"
            )
            # In production, this would require additional confirmations

        result = await terminus.rollback(
            db_name, request.target_commit, request.create_branch, request.branch_name
        )

        return {
            "status": "success",
            "message": f"ì»¤ë°‹ '{request.target_commit}'ë¡œ ë¡¤ë°±í–ˆìŠµë‹ˆë‹¤",
            "data": result,
        }
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    except (httpx.HTTPError, httpx.TimeoutException, ValueError, KeyError) as e:
        logger.error(f"Failed to rollback: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=str(e))


# BFF íŠ¹ë³„ ë””ë²„ê·¸ ì—”ë“œí¬ì¸íŠ¸ (ê°œë°œ í™˜ê²½ì—ì„œë§Œ í™œì„±í™”)
# Note: CORS debug endpointëŠ” service_factoryì—ì„œ ìë™ ì œê³µë¨
from shared.config.service_config import ServiceConfig

if not ServiceConfig.is_production():
    @app.post("/debug/test")
    async def debug_test(data: Dict[str, Any]):
        """POST ìš”ì²­ ë””ë²„ê·¸ í…ŒìŠ¤íŠ¸"""
        logger.info(f"ğŸ”¥ DEBUG TEST - Received POST: {data}")
        return {"received": data, "status": "ok"}



# Google Sheets data connector import - removed (router.py deleted)


app.include_router(database.router, prefix="/api/v1", tags=["database"])
app.include_router(ontology.router, prefix="/api/v1", tags=["ontology"])
app.include_router(query.router, prefix="/api/v1", tags=["query"])
app.include_router(mapping.router, prefix="/api/v1", tags=["mapping"])
app.include_router(health.router, prefix="/api/v1", tags=["health"])
app.include_router(merge_conflict.router, prefix="/api/v1", tags=["merge-conflict"])
app.include_router(instances.router, prefix="/api/v1", tags=["instances"])
app.include_router(instance_async.router, prefix="/api/v1", tags=["async-instances"])
app.include_router(websocket.router, prefix="/api/v1", tags=["websocket"])

# Health endpointë¥¼ ë£¨íŠ¸ ê²½ë¡œì—ë„ ë“±ë¡ (í˜¸í™˜ì„±ì„ ìœ„í•´)
app.include_router(health.router, tags=["health"])

# Google Sheets data connector ë¼ìš°í„° ì œê±°ë¨


# Startup event moved to lifespan context


if __name__ == "__main__":
    # Service Factoryë¥¼ ì‚¬ìš©í•œ ê°„ì†Œí™”ëœ ì„œë¹„ìŠ¤ ì‹¤í–‰
    run_service(app, BFF_SERVICE_INFO, "bff.main:app")
