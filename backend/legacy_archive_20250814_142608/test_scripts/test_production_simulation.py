"""
ğŸ”¥ ULTRA PRODUCTION SIMULATION TEST
ì‹¤ì œ ìš´ì˜í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜ ë° ê³ ë‚œì´ë„ ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì¢…í•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
"""

import asyncio
import httpx
import json
import sys
import time
import os
import random
import tracemalloc
import psutil
import subprocess
import concurrent.futures
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from collections import defaultdict
import statistics

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent))


@dataclass
class TestResult:
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ í´ë˜ìŠ¤"""
    test_name: str
    success_count: int
    failure_count: int
    avg_response_time: float
    max_response_time: float
    min_response_time: float
    p95_response_time: float
    p99_response_time: float
    error_types: Dict[str, int]
    start_time: datetime
    end_time: datetime
    
    @property
    def total_requests(self) -> int:
        return self.success_count + self.failure_count
    
    @property
    def success_rate(self) -> float:
        if self.total_requests == 0:
            return 0.0
        return (self.success_count / self.total_requests) * 100
    
    @property
    def duration(self) -> float:
        return (self.end_time - self.start_time).total_seconds()
    
    @property
    def requests_per_second(self) -> float:
        if self.duration == 0:
            return 0.0
        return self.total_requests / self.duration


class ServiceManager:
    """ì„œë¹„ìŠ¤ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬"""
    
    def __init__(self):
        self.processes = {}
        self.start_times = {}
        
    async def start_service(self, name: str, module: str, port: int) -> bool:
        """ì„œë¹„ìŠ¤ ì‹œì‘"""
        try:
            # ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
            subprocess.run(f"pkill -f 'python.*{module}'", shell=True, capture_output=True)
            await asyncio.sleep(1)
            
            # ìƒˆ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
            env = os.environ.copy()
            env["PYTHONUNBUFFERED"] = "1"
            
            cmd = f"python -m {module}"
            process = subprocess.Popen(
                cmd.split(),
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                cwd=Path(__file__).parent,
                env=env
            )
            
            self.processes[name] = process
            self.start_times[name] = time.time()
            
            # ì„œë¹„ìŠ¤ê°€ ì‹œì‘ë  ë•Œê¹Œì§€ ëŒ€ê¸°
            for i in range(20):
                try:
                    async with httpx.AsyncClient() as client:
                        response = await client.get(f"http://localhost:{port}/health", timeout=2.0)
                        if response.status_code == 200:
                            print(f"âœ… {name} ì„œë¹„ìŠ¤ ì‹œì‘ ì„±ê³µ (í¬íŠ¸: {port}, ì‹œì‘ ì‹œê°„: {i+1}ì´ˆ)")
                            return True
                except:
                    await asyncio.sleep(1)
                    
            print(f"âŒ {name} ì„œë¹„ìŠ¤ ì‹œì‘ ì‹¤íŒ¨")
            return False
            
        except Exception as e:
            print(f"âŒ {name} ì„œë¹„ìŠ¤ ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def get_service_metrics(self, name: str) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        if name not in self.processes:
            return {}
            
        process = self.processes[name]
        try:
            p = psutil.Process(process.pid)
            return {
                "cpu_percent": p.cpu_percent(),
                "memory_mb": p.memory_info().rss / 1024 / 1024,
                "num_threads": p.num_threads(),
                "uptime_seconds": time.time() - self.start_times[name]
            }
        except:
            return {}
    
    def stop_all(self):
        """ëª¨ë“  ì„œë¹„ìŠ¤ ì¢…ë£Œ"""
        for name, process in self.processes.items():
            try:
                process.terminate()
                process.wait(timeout=5)
                print(f"âœ… {name} ì„œë¹„ìŠ¤ ì¢…ë£Œ")
            except:
                process.kill()
                print(f"âš ï¸ {name} ì„œë¹„ìŠ¤ ê°•ì œ ì¢…ë£Œ")
        
        # ì¶”ê°€ ì •ë¦¬
        subprocess.run("pkill -f 'python.*oms.main'", shell=True, capture_output=True)
        subprocess.run("pkill -f 'python.*bff.main'", shell=True, capture_output=True)
        subprocess.run("pkill -f 'python.*funnel.main'", shell=True, capture_output=True)


class ProductionSimulator:
    """ìš´ì˜í™˜ê²½ ì‹œë®¬ë ˆì´í„°"""
    
    def __init__(self):
        self.manager = ServiceManager()
        self.results = []
        self.test_data = self._generate_test_data()
        
    def _generate_test_data(self) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±"""
        return {
            "databases": [f"test_db_{i}" for i in range(10)],
            "ontologies": [
                {
                    "id": f"Class_{i}",
                    "label": f"í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ {i}",
                    "description": f"í…ŒìŠ¤íŠ¸ ì„¤ëª… {i}" * 10,
                    "properties": [
                        {
                            "id": f"prop_{j}",
                            "label": f"ì†ì„± {j}",
                            "type": random.choice(["xsd:string", "xsd:integer", "xsd:decimal", "xsd:boolean"])
                        } for j in range(5)
                    ],
                    "relationships": [
                        {
                            "type": "subClassOf",
                            "target": f"Class_{(i+1)%100}"
                        }
                    ]
                } for i in range(100)
            ],
            "malicious_inputs": [
                "'; DROP TABLE users; --",
                "../../../etc/passwd",
                "<script>alert('xss')</script>",
                "test\x00null",
                "test%00null",
                "A" * 10000,  # ë§¤ìš° ê¸´ ë¬¸ìì—´
                {"@id": "x" * 1000},  # ê¸´ ID
                {"nested": {"nested": {"nested": {"nested": {}}}}},  # ê¹Šì€ ì¤‘ì²©
            ]
        }
    
    async def measure_request(self, client: httpx.AsyncClient, method: str, url: str, 
                            json_data: Optional[Dict] = None) -> Tuple[float, Optional[int], Optional[str]]:
        """ë‹¨ì¼ ìš”ì²­ ì¸¡ì •"""
        start_time = time.time()
        try:
            if method == "GET":
                response = await client.get(url, timeout=30.0)
            elif method == "POST":
                response = await client.post(url, json=json_data, timeout=30.0)
            elif method == "DELETE":
                response = await client.delete(url, timeout=30.0)
            else:
                raise ValueError(f"Unsupported method: {method}")
                
            response_time = time.time() - start_time
            return response_time, response.status_code, None
            
        except httpx.TimeoutException:
            return time.time() - start_time, None, "Timeout"
        except Exception as e:
            return time.time() - start_time, None, str(type(e).__name__)
    
    async def run_concurrent_load(self, num_requests: int, num_workers: int, 
                                test_func) -> TestResult:
        """ë™ì‹œì„± ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"\në™ì‹œ ìš”ì²­ ìˆ˜: {num_requests}, ì›Œì»¤ ìˆ˜: {num_workers}")
        
        response_times = []
        errors = defaultdict(int)
        success_count = 0
        failure_count = 0
        start_time = datetime.now()
        
        # ì›Œì»¤ë³„ ì‘ì—… ë¶„ë°°
        tasks_per_worker = num_requests // num_workers
        remaining_tasks = num_requests % num_workers
        
        async def worker(worker_id: int, num_tasks: int):
            nonlocal success_count, failure_count
            
            async with httpx.AsyncClient(timeout=30.0) as client:
                for i in range(num_tasks):
                    response_time, status_code, error = await test_func(client, worker_id, i)
                    response_times.append(response_time)
                    
                    if error:
                        failure_count += 1
                        errors[error] += 1
                    elif status_code and 200 <= status_code < 300:
                        success_count += 1
                    else:
                        failure_count += 1
                        errors[f"HTTP_{status_code}"] += 1
        
        # ëª¨ë“  ì›Œì»¤ ë™ì‹œ ì‹¤í–‰
        workers = []
        for i in range(num_workers):
            tasks = tasks_per_worker + (1 if i < remaining_tasks else 0)
            workers.append(worker(i, tasks))
        
        await asyncio.gather(*workers)
        
        end_time = datetime.now()
        
        # í†µê³„ ê³„ì‚°
        if response_times:
            response_times.sort()
            avg_time = statistics.mean(response_times)
            p95_time = response_times[int(len(response_times) * 0.95)]
            p99_time = response_times[int(len(response_times) * 0.99)]
        else:
            avg_time = p95_time = p99_time = 0.0
        
        return TestResult(
            test_name="Concurrent Load Test",
            success_count=success_count,
            failure_count=failure_count,
            avg_response_time=avg_time,
            max_response_time=max(response_times) if response_times else 0.0,
            min_response_time=min(response_times) if response_times else 0.0,
            p95_response_time=p95_time,
            p99_response_time=p99_time,
            error_types=dict(errors),
            start_time=start_time,
            end_time=end_time
        )
    
    async def test_high_concurrency(self):
        """1. ê³ ë¶€í•˜ ë™ì‹œì„± í…ŒìŠ¤íŠ¸"""
        print("\n=== 1. ê³ ë¶€í•˜ ë™ì‹œì„± í…ŒìŠ¤íŠ¸ ===")
        
        async def ontology_create_test(client: httpx.AsyncClient, worker_id: int, task_id: int):
            """ì˜¨í†¨ë¡œì§€ ìƒì„± í…ŒìŠ¤íŠ¸"""
            db_name = f"concurrent_db_{worker_id % 5}"
            ontology_data = self.test_data["ontologies"][task_id % len(self.test_data["ontologies"])].copy()
            ontology_data["id"] = f"{ontology_data['id']}_w{worker_id}_t{task_id}"
            
            return await self.measure_request(
                client, "POST",
                f"http://localhost:8000/api/v1/ontology/{db_name}/create",
                ontology_data
            )
        
        # ì ì§„ì  ë¶€í•˜ ì¦ê°€
        for num_requests, num_workers in [(100, 10), (500, 50), (1000, 100)]:
            result = await self.run_concurrent_load(num_requests, num_workers, ontology_create_test)
            self.results.append(result)
            
            print(f"âœ… {num_requests} ìš”ì²­ ì™„ë£Œ:")
            print(f"   - ì„±ê³µë¥ : {result.success_rate:.2f}%")
            print(f"   - í‰ê·  ì‘ë‹µì‹œê°„: {result.avg_response_time:.3f}ì´ˆ")
            print(f"   - P95 ì‘ë‹µì‹œê°„: {result.p95_response_time:.3f}ì´ˆ")
            print(f"   - P99 ì‘ë‹µì‹œê°„: {result.p99_response_time:.3f}ì´ˆ")
            print(f"   - RPS: {result.requests_per_second:.2f}")
            
            # ì„œë¹„ìŠ¤ ë©”íŠ¸ë¦­ ì¶œë ¥
            for service in ["OMS", "BFF", "Funnel"]:
                metrics = self.manager.get_service_metrics(service)
                if metrics:
                    print(f"   - {service}: CPU {metrics['cpu_percent']:.1f}%, "
                          f"ë©”ëª¨ë¦¬ {metrics['memory_mb']:.1f}MB, "
                          f"ìŠ¤ë ˆë“œ {metrics['num_threads']}")
    
    async def test_large_data_processing(self):
        """2. ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        print("\n=== 2. ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ===")
        
        async with httpx.AsyncClient(timeout=60.0) as client:
            # í…ŒìŠ¤íŠ¸ DB ìƒì„±
            await client.post("http://localhost:8000/api/v1/database/create",
                            json={"name": "large_data_test", "description": "ëŒ€ìš©ëŸ‰ í…ŒìŠ¤íŠ¸"})
            
            # 10,000ê°œ ì˜¨í†¨ë¡œì§€ ìƒì„±
            print("10,000ê°œ ì˜¨í†¨ë¡œì§€ ìƒì„± ì¤‘...")
            batch_size = 100
            total_time = 0
            
            for batch in range(100):
                batch_start = time.time()
                tasks = []
                
                for i in range(batch_size):
                    idx = batch * batch_size + i
                    ontology = {
                        "id": f"LargeClass_{idx}",
                        "label": f"ëŒ€ìš©ëŸ‰ í´ë˜ìŠ¤ {idx}",
                        "description": f"ì„¤ëª… {idx}" * 50,
                        "properties": [
                            {
                                "id": f"large_prop_{j}",
                                "label": f"ëŒ€ìš©ëŸ‰ ì†ì„± {j}",
                                "type": "xsd:string"
                            } for j in range(20)
                        ]
                    }
                    
                    tasks.append(
                        self.measure_request(
                            client, "POST",
                            "http://localhost:8000/api/v1/ontology/large_data_test/create",
                            ontology
                        )
                    )
                
                results = await asyncio.gather(*tasks)
                batch_time = time.time() - batch_start
                total_time += batch_time
                
                success = sum(1 for _, status, error in results if status and 200 <= status < 300)
                print(f"   ë°°ì¹˜ {batch+1}/100 ì™„ë£Œ: {success}/{batch_size} ì„±ê³µ, {batch_time:.2f}ì´ˆ")
            
            print(f"\nâœ… 10,000ê°œ ì˜¨í†¨ë¡œì§€ ìƒì„± ì™„ë£Œ: ì´ {total_time:.2f}ì´ˆ")
            
            # ëŒ€ìš©ëŸ‰ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
            print("\nëŒ€ìš©ëŸ‰ ë°ì´í„° ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸...")
            
            # ì „ì²´ ëª©ë¡ ì¡°íšŒ
            start_time = time.time()
            response = await client.get("http://localhost:8000/api/v1/ontology/large_data_test/list")
            list_time = time.time() - start_time
            
            if response.status_code == 200:
                data = response.json()
                ontology_count = len(data.get("data", {}).get("ontologies", []))
                print(f"âœ… ì „ì²´ ëª©ë¡ ì¡°íšŒ: {ontology_count}ê°œ, {list_time:.3f}ì´ˆ")
            
            # ë³µì¡í•œ ì¿¼ë¦¬
            complex_query = {
                "filters": {
                    "label": {"contains": "ëŒ€ìš©ëŸ‰"},
                    "properties": {"size": {"gte": 10}}
                },
                "limit": 1000
            }
            
            start_time = time.time()
            response = await client.post(
                "http://localhost:8000/api/v1/ontology/large_data_test/query",
                json=complex_query
            )
            query_time = time.time() - start_time
            print(f"âœ… ë³µì¡í•œ ì¿¼ë¦¬ ì‹¤í–‰: {query_time:.3f}ì´ˆ")
            
            # ì •ë¦¬
            await client.delete("http://localhost:8000/api/v1/database/large_data_test")
    
    async def test_failure_recovery(self):
        """3. ì¥ì•  ë³µêµ¬ ë° ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        print("\n=== 3. ì¥ì•  ë³µêµ¬ ë° ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ===")
        
        async with httpx.AsyncClient(timeout=10.0) as client:
            # 3-1. ì„œë¹„ìŠ¤ ì¬ì‹œì‘ í…ŒìŠ¤íŠ¸
            print("\n3-1. ì„œë¹„ìŠ¤ ì¬ì‹œì‘ ì¤‘ ìš”ì²­ ì²˜ë¦¬")
            
            # OMS ì„œë¹„ìŠ¤ ì¤‘ë‹¨
            if "OMS" in self.manager.processes:
                process = self.manager.processes["OMS"]
                process.terminate()
                print("âš ï¸ OMS ì„œë¹„ìŠ¤ ì¤‘ë‹¨ë¨")
            
            # ì¤‘ë‹¨ëœ ìƒíƒœì—ì„œ ìš”ì²­
            failed_requests = 0
            for i in range(5):
                try:
                    response = await client.get("http://localhost:8000/health", timeout=2.0)
                    if response.status_code != 200:
                        failed_requests += 1
                except:
                    failed_requests += 1
                await asyncio.sleep(0.5)
            
            print(f"   ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ì¤‘ ì‹¤íŒ¨í•œ ìš”ì²­: {failed_requests}/5")
            
            # OMS ì¬ì‹œì‘
            await self.manager.start_service("OMS", "oms.main", 8000)
            
            # ì¬ì‹œì‘ í›„ ìš”ì²­
            success_requests = 0
            for i in range(5):
                try:
                    response = await client.get("http://localhost:8000/health", timeout=2.0)
                    if response.status_code == 200:
                        success_requests += 1
                except:
                    pass
                await asyncio.sleep(0.5)
            
            print(f"   ì„œë¹„ìŠ¤ ì¬ì‹œì‘ í›„ ì„±ê³µí•œ ìš”ì²­: {success_requests}/5")
            
            # 3-2. ì•…ì„± ì…ë ¥ ì²˜ë¦¬
            print("\n3-2. ì•…ì„± ì…ë ¥ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
            
            blocked_count = 0
            for malicious_input in self.test_data["malicious_inputs"]:
                try:
                    if isinstance(malicious_input, str):
                        # ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ìœ¼ë¡œ ì•…ì„± ì…ë ¥
                        response = await client.post(
                            "http://localhost:8000/api/v1/database/create",
                            json={"name": malicious_input, "description": "test"}
                        )
                    else:
                        # ì˜¨í†¨ë¡œì§€ ë°ì´í„°ë¡œ ì•…ì„± ì…ë ¥
                        response = await client.post(
                            "http://localhost:8000/api/v1/ontology/test_db/create",
                            json=malicious_input
                        )
                    
                    if response.status_code in [400, 422]:
                        blocked_count += 1
                except:
                    blocked_count += 1
            
            print(f"âœ… ì•…ì„± ì…ë ¥ ì°¨ë‹¨: {blocked_count}/{len(self.test_data['malicious_inputs'])}")
            
            # 3-3. íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
            print("\n3-3. íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
            
            # ë§¤ìš° í° ë°ì´í„°ë¡œ íƒ€ì„ì•„ì›ƒ ìœ ë„
            huge_data = {
                "id": "TimeoutTest",
                "label": "íƒ€ì„ì•„ì›ƒ í…ŒìŠ¤íŠ¸",
                "description": "A" * 1000000,  # 1MB í…ìŠ¤íŠ¸
                "properties": [
                    {"id": f"prop_{i}", "label": f"ì†ì„± {i}", "type": "xsd:string"}
                    for i in range(1000)
                ]
            }
            
            timeout_count = 0
            for i in range(3):
                try:
                    response = await client.post(
                        "http://localhost:8000/api/v1/ontology/test_db/create",
                        json=huge_data,
                        timeout=2.0  # 2ì´ˆ íƒ€ì„ì•„ì›ƒ
                    )
                except httpx.TimeoutException:
                    timeout_count += 1
            
            print(f"âœ… íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬: {timeout_count}/3 ìš”ì²­ì´ íƒ€ì„ì•„ì›ƒë¨")
    
    async def test_memory_and_resources(self):
        """4. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ í…ŒìŠ¤íŠ¸"""
        print("\n=== 4. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ í…ŒìŠ¤íŠ¸ ===")
        
        # ë©”ëª¨ë¦¬ ì¶”ì  ì‹œì‘
        tracemalloc.start()
        initial_memory = {}
        
        # ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ
        for service in ["OMS", "BFF", "Funnel"]:
            metrics = self.manager.get_service_metrics(service)
            if metrics:
                initial_memory[service] = metrics["memory_mb"]
                print(f"{service} ì´ˆê¸° ë©”ëª¨ë¦¬: {metrics['memory_mb']:.1f}MB")
        
        async with httpx.AsyncClient() as client:
            # 1000íšŒ ë°˜ë³µ ìš”ì²­ìœ¼ë¡œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í™•ì¸
            print("\n1000íšŒ ë°˜ë³µ ìš”ì²­ ì‹¤í–‰ ì¤‘...")
            
            for i in range(10):
                tasks = []
                for j in range(100):
                    # ë‹¤ì–‘í•œ ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ
                    if j % 3 == 0:
                        tasks.append(client.get("http://localhost:8000/api/v1/database/list"))
                    elif j % 3 == 1:
                        tasks.append(client.get("http://localhost:8002/api/v1/databases"))
                    else:
                        tasks.append(client.get("http://localhost:8003/health"))
                
                await asyncio.gather(*tasks, return_exceptions=True)
                
                if (i + 1) % 2 == 0:
                    print(f"   {(i + 1) * 100}íšŒ ì™„ë£Œ")
                    
                    # ë©”ëª¨ë¦¬ ì²´í¬
                    for service in ["OMS", "BFF", "Funnel"]:
                        metrics = self.manager.get_service_metrics(service)
                        if metrics and service in initial_memory:
                            memory_increase = metrics["memory_mb"] - initial_memory[service]
                            print(f"   {service}: {metrics['memory_mb']:.1f}MB "
                                  f"(+{memory_increase:.1f}MB)")
        
        # ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ
        print("\nìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ:")
        memory_leaks = []
        
        for service in ["OMS", "BFF", "Funnel"]:
            metrics = self.manager.get_service_metrics(service)
            if metrics and service in initial_memory:
                memory_increase = metrics["memory_mb"] - initial_memory[service]
                print(f"{service}: {metrics['memory_mb']:.1f}MB (+{memory_increase:.1f}MB)")
                
                # 50MB ì´ìƒ ì¦ê°€ì‹œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì˜ì‹¬
                if memory_increase > 50:
                    memory_leaks.append(f"{service} (+{memory_increase:.1f}MB)")
        
        if memory_leaks:
            print(f"\nâš ï¸ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì˜ì‹¬: {', '.join(memory_leaks)}")
        else:
            print("\nâœ… ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì—†ìŒ")
        
        # ë©”ëª¨ë¦¬ ìŠ¤ëƒ…ìƒ·
        snapshot = tracemalloc.take_snapshot()
        top_stats = snapshot.statistics('lineno')[:5]
        
        print("\në©”ëª¨ë¦¬ ì‚¬ìš© ìƒìœ„ 5ê°œ:")
        for stat in top_stats:
            print(f"   {stat}")
        
        tracemalloc.stop()
    
    async def test_network_issues(self):
        """5. ë„¤íŠ¸ì›Œí¬ ì§€ì—° ë° íƒ€ì„ì•„ì›ƒ ì‹œë‚˜ë¦¬ì˜¤"""
        print("\n=== 5. ë„¤íŠ¸ì›Œí¬ ì§€ì—° ë° íƒ€ì„ì•„ì›ƒ ì‹œë‚˜ë¦¬ì˜¤ ===")
        
        # ë‹¤ì–‘í•œ íƒ€ì„ì•„ì›ƒ ì„¤ì •ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        timeout_scenarios = [
            (0.5, "ê·¹ë„ë¡œ ì§§ì€ íƒ€ì„ì•„ì›ƒ"),
            (1.0, "ì§§ì€ íƒ€ì„ì•„ì›ƒ"),
            (5.0, "ë³´í†µ íƒ€ì„ì•„ì›ƒ"),
            (30.0, "ê¸´ íƒ€ì„ì•„ì›ƒ")
        ]
        
        for timeout, description in timeout_scenarios:
            print(f"\n{description} ({timeout}ì´ˆ) í…ŒìŠ¤íŠ¸:")
            
            success_count = 0
            timeout_count = 0
            
            async with httpx.AsyncClient(timeout=timeout) as client:
                for i in range(10):
                    try:
                        # ë³µì¡í•œ ì¿¼ë¦¬ë¡œ ì²˜ë¦¬ ì‹œê°„ ì¦ê°€
                        response = await client.post(
                            "http://localhost:8000/api/v1/ontology/test_db/query",
                            json={
                                "filters": {"label": {"contains": "test"}},
                                "limit": 1000
                            }
                        )
                        if response.status_code == 200:
                            success_count += 1
                    except httpx.TimeoutException:
                        timeout_count += 1
                    except Exception:
                        pass
            
            print(f"   ì„±ê³µ: {success_count}/10, íƒ€ì„ì•„ì›ƒ: {timeout_count}/10")
        
        # ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜ (í”„ë¡ì‹œ ì‚¬ìš©)
        print("\në„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜:")
        
        # ì¸ìœ„ì  ì§€ì—° ì¶”ê°€
        async def delayed_request(delay: float):
            await asyncio.sleep(delay)
            async with httpx.AsyncClient() as client:
                return await client.get("http://localhost:8000/health")
        
        delays = [0.1, 0.5, 1.0, 2.0]
        for delay in delays:
            start_time = time.time()
            try:
                response = await delayed_request(delay)
                total_time = time.time() - start_time
                print(f"   {delay}ì´ˆ ì§€ì—°: ì´ {total_time:.2f}ì´ˆ, ìƒíƒœ {response.status_code}")
            except Exception as e:
                print(f"   {delay}ì´ˆ ì§€ì—°: ì‹¤íŒ¨ - {type(e).__name__}")
    
    async def test_service_communication(self):
        """6. ì„œë¹„ìŠ¤ ê°„ í†µì‹  ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤"""
        print("\n=== 6. ì„œë¹„ìŠ¤ ê°„ í†µì‹  ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ ===")
        
        async with httpx.AsyncClient() as client:
            # 6-1. OMS ì¤‘ë‹¨ ì‹œ BFF ë™ì‘
            print("\n6-1. OMS ì¤‘ë‹¨ ì‹œ BFF ì‘ë‹µ:")
            
            # OMS ì¤‘ë‹¨
            if "OMS" in self.manager.processes:
                self.manager.processes["OMS"].terminate()
                await asyncio.sleep(2)
            
            # BFF ìš”ì²­
            try:
                response = await client.get("http://localhost:8002/api/v1/databases")
                print(f"   BFF ì‘ë‹µ: {response.status_code}")
                if response.status_code >= 500:
                    print("   âœ… BFFê°€ OMS ì¥ì• ë¥¼ ì ì ˆíˆ ì²˜ë¦¬í•¨")
            except Exception as e:
                print(f"   BFF ì˜¤ë¥˜: {type(e).__name__}")
            
            # OMS ì¬ì‹œì‘
            await self.manager.start_service("OMS", "oms.main", 8000)
            
            # 6-2. Funnel ì¤‘ë‹¨ ì‹œ BFF ë™ì‘
            print("\n6-2. Funnel ì¤‘ë‹¨ ì‹œ BFF íƒ€ì… ì¶”ë¡ :")
            
            # Funnel ì¤‘ë‹¨
            if "Funnel" in self.manager.processes:
                self.manager.processes["Funnel"].terminate()
                await asyncio.sleep(2)
            
            # BFFì—ì„œ íƒ€ì… ì¶”ë¡  ìš”ì²­
            try:
                response = await client.post(
                    "http://localhost:8002/api/v1/type-inference/infer",
                    json={"data": ["2024-01-01", "2024-01-02", "2024-01-03"]}
                )
                print(f"   íƒ€ì… ì¶”ë¡  ì‘ë‹µ: {response.status_code}")
            except Exception as e:
                print(f"   âœ… Funnel ì¥ì•  ì‹œ ì ì ˆí•œ ì—ëŸ¬: {type(e).__name__}")
            
            # Funnel ì¬ì‹œì‘
            await self.manager.start_service("Funnel", "funnel.main", 8003)
    
    async def test_database_pool_exhaustion(self):
        """7. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ê³ ê°ˆ í…ŒìŠ¤íŠ¸"""
        print("\n=== 7. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ê³ ê°ˆ í…ŒìŠ¤íŠ¸ ===")
        
        # ë™ì‹œì— ë§ì€ DB ì‘ì—… ìš”ì²­
        async def db_heavy_operation(client: httpx.AsyncClient, op_id: int):
            operations = [
                # DB ìƒì„±
                ("POST", "http://localhost:8000/api/v1/database/create", 
                 {"name": f"pool_test_{op_id}", "description": "í’€ í…ŒìŠ¤íŠ¸"}),
                # ì˜¨í†¨ë¡œì§€ ìƒì„±
                ("POST", f"http://localhost:8000/api/v1/ontology/pool_test_{op_id}/create",
                 {"id": f"PoolClass_{op_id}", "label": "í’€ í´ë˜ìŠ¤"}),
                # ì¿¼ë¦¬
                ("POST", f"http://localhost:8000/api/v1/ontology/pool_test_{op_id}/query",
                 {"filters": {}, "limit": 100}),
                # ì‚­ì œ
                ("DELETE", f"http://localhost:8000/api/v1/database/pool_test_{op_id}", None)
            ]
            
            results = []
            for method, url, data in operations:
                response_time, status, error = await self.measure_request(client, method, url, data)
                results.append((response_time, status, error))
            
            return results
        
        # 100ê°œ ë™ì‹œ DB ì‘ì—…
        print("100ê°œ ë™ì‹œ DB ì‘ì—… ì‹¤í–‰ ì¤‘...")
        
        start_time = time.time()
        async with httpx.AsyncClient(timeout=30.0) as client:
            tasks = [db_heavy_operation(client, i) for i in range(100)]
            results = await asyncio.gather(*tasks, return_exceptions=True)
        
        total_time = time.time() - start_time
        
        # ê²°ê³¼ ë¶„ì„
        success_count = 0
        error_count = 0
        timeout_count = 0
        
        for result in results:
            if isinstance(result, Exception):
                error_count += 1
            else:
                for _, status, error in result:
                    if error == "Timeout":
                        timeout_count += 1
                    elif error:
                        error_count += 1
                    elif status and 200 <= status < 300:
                        success_count += 1
        
        print(f"\nâœ… DB í’€ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ({total_time:.2f}ì´ˆ):")
        print(f"   ì„±ê³µ: {success_count}")
        print(f"   ì˜¤ë¥˜: {error_count}")
        print(f"   íƒ€ì„ì•„ì›ƒ: {timeout_count}")
    
    async def generate_report(self):
        """ì¢…í•© ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n" + "="*80)
        print("ğŸ“Š ì¢…í•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸")
        print("="*80)
        
        # ì „ì²´ í…ŒìŠ¤íŠ¸ ìš”ì•½
        total_requests = sum(r.total_requests for r in self.results)
        total_success = sum(r.success_count for r in self.results)
        overall_success_rate = (total_success / total_requests * 100) if total_requests > 0 else 0
        
        print(f"\nì „ì²´ ìš”ì•½:")
        print(f"- ì´ ìš”ì²­ ìˆ˜: {total_requests:,}")
        print(f"- ì„±ê³µ ìš”ì²­: {total_success:,}")
        print(f"- ì „ì²´ ì„±ê³µë¥ : {overall_success_rate:.2f}%")
        
        # ì‘ë‹µ ì‹œê°„ í†µê³„
        all_response_times = []
        for r in self.results:
            if r.avg_response_time > 0:
                all_response_times.extend([r.avg_response_time] * r.total_requests)
        
        if all_response_times:
            print(f"\nì‘ë‹µ ì‹œê°„ í†µê³„:")
            print(f"- í‰ê· : {statistics.mean(all_response_times):.3f}ì´ˆ")
            print(f"- ì¤‘ì•™ê°’: {statistics.median(all_response_times):.3f}ì´ˆ")
            print(f"- í‘œì¤€í¸ì°¨: {statistics.stdev(all_response_times):.3f}ì´ˆ")
        
        # ì„œë¹„ìŠ¤ë³„ ìµœì¢… ìƒíƒœ
        print(f"\nì„œë¹„ìŠ¤ ìƒíƒœ:")
        for service in ["OMS", "BFF", "Funnel"]:
            metrics = self.manager.get_service_metrics(service)
            if metrics:
                print(f"- {service}:")
                print(f"  - CPU: {metrics['cpu_percent']:.1f}%")
                print(f"  - ë©”ëª¨ë¦¬: {metrics['memory_mb']:.1f}MB")
                print(f"  - ìŠ¤ë ˆë“œ: {metrics['num_threads']}")
                print(f"  - ê°€ë™ì‹œê°„: {metrics['uptime_seconds']:.0f}ì´ˆ")
        
        # ì£¼ìš” ë°œê²¬ì‚¬í•­
        print(f"\nì£¼ìš” ë°œê²¬ì‚¬í•­:")
        
        # ì„±ëŠ¥ ì´ìŠˆ ì²´í¬
        performance_issues = []
        for r in self.results:
            if r.p99_response_time > 5.0:
                performance_issues.append(f"P99 ì‘ë‹µì‹œê°„ {r.p99_response_time:.1f}ì´ˆ")
            if r.success_rate < 95.0:
                performance_issues.append(f"ì„±ê³µë¥  {r.success_rate:.1f}%")
        
        if performance_issues:
            print("âš ï¸ ì„±ëŠ¥ ì´ìŠˆ:")
            for issue in performance_issues[:5]:
                print(f"  - {issue}")
        else:
            print("âœ… ì‹¬ê°í•œ ì„±ëŠ¥ ì´ìŠˆ ì—†ìŒ")
        
        # ì—ëŸ¬ ë¶„ì„
        all_errors = defaultdict(int)
        for r in self.results:
            for error_type, count in r.error_types.items():
                all_errors[error_type] += count
        
        if all_errors:
            print("\nâš ï¸ ë°œìƒí•œ ì—ëŸ¬ ìœ í˜•:")
            for error_type, count in sorted(all_errors.items(), key=lambda x: x[1], reverse=True)[:5]:
                print(f"  - {error_type}: {count}íšŒ")
        
        print("\n" + "="*80)
    
    async def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        try:
            # ì„œë¹„ìŠ¤ ì‹œì‘
            print("ì„œë¹„ìŠ¤ ì‹œì‘ ì¤‘...")
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
            os.environ["TERMINUS_URL"] = "http://localhost:6364"
            os.environ["TERMINUS_USER"] = "admin"
            os.environ["TERMINUS_ACCOUNT"] = "admin"
            os.environ["TERMINUS_KEY"] = "admin"
            
            # ì„œë¹„ìŠ¤ ì‹œì‘
            if not await self.manager.start_service("OMS", "oms.main", 8000):
                print("âŒ OMS ì‹œì‘ ì‹¤íŒ¨. í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨.")
                return
            
            await asyncio.sleep(2)
            
            if not await self.manager.start_service("BFF", "bff.main", 8002):
                print("âŒ BFF ì‹œì‘ ì‹¤íŒ¨. í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨.")
                return
                
            await asyncio.sleep(2)
            
            if not await self.manager.start_service("Funnel", "funnel.main", 8004):
                print("âŒ Funnel ì‹œì‘ ì‹¤íŒ¨. í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨.")
                return
                
            await asyncio.sleep(2)
            
            # í…ŒìŠ¤íŠ¸ DB ì¤€ë¹„
            async with httpx.AsyncClient() as client:
                for db_name in ["test_db", "concurrent_db_0", "concurrent_db_1", 
                               "concurrent_db_2", "concurrent_db_3", "concurrent_db_4"]:
                    try:
                        await client.post(
                            "http://localhost:8000/api/v1/database/create",
                            json={"name": db_name, "description": "í…ŒìŠ¤íŠ¸ DB"}
                        )
                    except:
                        pass
            
            print("\ní…ŒìŠ¤íŠ¸ ì‹œì‘...\n")
            
            # ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            await self.test_high_concurrency()
            await self.test_large_data_processing()
            await self.test_failure_recovery()
            await self.test_memory_and_resources()
            await self.test_network_issues()
            await self.test_service_communication()
            await self.test_database_pool_exhaustion()
            
            # ë¦¬í¬íŠ¸ ìƒì„±
            await self.generate_report()
            
        except Exception as e:
            print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            
        finally:
            print("\nì„œë¹„ìŠ¤ ì¢…ë£Œ ì¤‘...")
            self.manager.stop_all()
            await asyncio.sleep(2)


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    simulator = ProductionSimulator()
    await simulator.run_all_tests()


if __name__ == "__main__":
    print("ğŸ”¥ ULTRA PRODUCTION SIMULATION TEST ì‹œì‘")
    print("ì‹¤ì œ ìš´ì˜í™˜ê²½ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” ê³ ë‚œì´ë„ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸\n")
    
    asyncio.run(main())