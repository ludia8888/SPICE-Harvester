#!/usr/bin/env python3
"""
THINK ULTRA - ì™„ì „í•œ Event Sourcing íŒŒì´í”„ë¼ì¸ ê²€ì¦
ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ ì‹¤ì œë¡œ ì‹¤í–‰í•˜ê³  ë°ì´í„° íë¦„ í™•ì¸
"""

import asyncio
import aiohttp
import asyncpg
import json
import os
import sys
from datetime import datetime
from confluent_kafka import Consumer, Producer

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["POSTGRES_HOST"] = "localhost"
os.environ["POSTGRES_PORT"] = "5433"
os.environ["KAFKA_HOST"] = "127.0.0.1"
os.environ["KAFKA_PORT"] = "9092"
os.environ["REDIS_HOST"] = "localhost"
os.environ["REDIS_PORT"] = "6379"
os.environ["ELASTICSEARCH_HOST"] = "localhost"
os.environ["ELASTICSEARCH_PORT"] = "9201"
os.environ["TERMINUS_SERVER_URL"] = "http://localhost:6363"
os.environ["TERMINUS_USER"] = "admin"
os.environ["TERMINUS_ACCOUNT"] = "admin"
os.environ["TERMINUS_KEY"] = "admin"
os.environ["MINIO_ENDPOINT_URL"] = "http://localhost:9000"
os.environ["MINIO_ACCESS_KEY"] = "minioadmin"
os.environ["MINIO_SECRET_KEY"] = "minioadmin123"
os.environ["DOCKER_CONTAINER"] = "false"

sys.path.insert(0, "/Users/isihyeon/Desktop/SPICE HARVESTER/backend")

import logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class CompletePipelineTest:
    """ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    
    def __init__(self):
        self.test_db_name = f"complete_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.test_class_id = "CompleteTestProduct"
        self.test_command_id = None
        self.test_instance_id = None
        
    async def step1_create_database(self):
        """Step 1: ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±"""
        logger.info("=" * 60)
        logger.info("Step 1: ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±")
        logger.info("=" * 60)
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://localhost:8000/api/v1/database/create",
                json={
                    "name": self.test_db_name,
                    "description": "Complete Pipeline Test"
                }
            ) as resp:
                if resp.status in [200, 202]:
                    data = await resp.json()
                    logger.info(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±: {self.test_db_name}")
                    return True
                else:
                    logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {resp.status}")
                    return False
    
    async def step2_create_command(self):
        """Step 2: Instance Command ìƒì„±"""
        logger.info("\n" + "=" * 60)
        logger.info("Step 2: Instance Command ìƒì„±")
        logger.info("=" * 60)
        
        test_data = {
            "data": {
                "product_name": "Complete Pipeline Test",
                "price": 999.99,
                "test_id": "COMPLETE_TEST",
                "created_at": datetime.utcnow().isoformat()
            },
            "metadata": {
                "test": "complete_pipeline"
            }
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"http://localhost:8000/api/v1/instances/{self.test_db_name}/async/{self.test_class_id}/create",
                json=test_data
            ) as resp:
                if resp.status == 202:
                    data = await resp.json()
                    self.test_command_id = data.get('command_id')
                    logger.info(f"âœ… Command ìƒì„±: {self.test_command_id}")
                    return True
                else:
                    logger.error(f"âŒ Command ìƒì„± ì‹¤íŒ¨: {resp.status}")
                    return False
    
    async def step3_run_message_relay(self):
        """Step 3: Message Relay ì‹¤í–‰"""
        logger.info("\n" + "=" * 60)
        logger.info("Step 3: Message Relay ì‹¤í–‰")
        logger.info("=" * 60)
        
        from message_relay.main import MessageRelay
        
        relay = MessageRelay()
        await relay.initialize()
        
        # Outbox ì²˜ë¦¬
        processed = await relay.process_events()
        logger.info(f"âœ… Message Relay: {processed}ê°œ ë©”ì‹œì§€ ì²˜ë¦¬")
        
        await relay.shutdown()
        return processed > 0
    
    async def step4_process_command(self):
        """Step 4: Instance Workerë¡œ Command ì²˜ë¦¬"""
        logger.info("\n" + "=" * 60)
        logger.info("Step 4: Instance Workerë¡œ Command ì²˜ë¦¬")
        logger.info("=" * 60)
        
        # Kafkaì—ì„œ Command ì½ê¸°
        consumer = Consumer({
            'bootstrap.servers': '127.0.0.1:9092',
            'group.id': 'test-processor',
            'auto.offset.reset': 'earliest',
            'enable.auto.commit': False,
            'session.timeout.ms': 6000,
            'max.poll.interval.ms': 300000
        })
        
        consumer.subscribe(['instance_commands'])
        
        # Command ì°¾ê¸°
        command_data = None
        for i in range(10):
            msg = consumer.poll(timeout=1.0)
            if msg and not msg.error():
                data = json.loads(msg.value().decode('utf-8'))
                if data.get('command_id') == self.test_command_id:
                    command_data = data
                    logger.info(f"âœ… Command ë°œê²¬: {self.test_command_id}")
                    break
        
        consumer.close()
        
        if not command_data:
            logger.error("âŒ Commandë¥¼ Kafkaì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return False
        
        # Instance Worker ì´ˆê¸°í™”
        from instance_worker.main import InstanceWorker
        
        worker = InstanceWorker()
        await worker.initialize()
        
        try:
            # Command ì²˜ë¦¬
            logger.info("Command ì²˜ë¦¬ ì¤‘...")
            await worker.process_command(command_data)
            logger.info("âœ… Command ì²˜ë¦¬ ì™„ë£Œ")
            
            # Event ë°œí–‰ í™•ì¸ì„ ìœ„í•´ ì ì‹œ ëŒ€ê¸°
            await asyncio.sleep(2)
            
            # ì •ë¦¬
            if worker.producer:
                worker.producer.flush()
            if worker.redis_service:
                await worker.redis_service.disconnect()
            if worker.terminus_service:
                await worker.terminus_service.disconnect()
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Command ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False
    
    async def step5_check_event(self):
        """Step 5: Event ë°œí–‰ í™•ì¸"""
        logger.info("\n" + "=" * 60)
        logger.info("Step 5: Event ë°œí–‰ í™•ì¸")
        logger.info("=" * 60)
        
        # Kafka instance_events í† í”½ í™•ì¸
        consumer = Consumer({
            'bootstrap.servers': '127.0.0.1:9092',
            'group.id': 'test-event-check',
            'auto.offset.reset': 'earliest',
            'enable.auto.commit': False,
            'session.timeout.ms': 6000,
            'max.poll.interval.ms': 300000
        })
        
        consumer.subscribe(['instance_events'])
        
        event_found = False
        for i in range(10):
            msg = consumer.poll(timeout=1.0)
            if msg and not msg.error():
                try:
                    data = json.loads(msg.value().decode('utf-8'))
                    if data.get('command_id') == self.test_command_id:
                        event_found = True
                        self.test_instance_id = data.get('instance_id')
                        logger.info(f"âœ… Event ë°œê²¬:")
                        logger.info(f"   Event Type: {data.get('event_type')}")
                        logger.info(f"   Instance ID: {self.test_instance_id}")
                        break
                except:
                    pass
        
        consumer.close()
        
        if not event_found:
            logger.warning("âš ï¸  Eventê°€ ì•„ì§ ë°œí–‰ë˜ì§€ ì•ŠìŒ")
        
        return event_found
    
    async def step6_run_projection(self):
        """Step 6: Projection Worker ì‹¤í–‰"""
        logger.info("\n" + "=" * 60)
        logger.info("Step 6: Projection Worker ì‹¤í–‰")
        logger.info("=" * 60)
        
        try:
            from projection_worker.main import ProjectionWorker
            
            worker = ProjectionWorker()
            await worker.initialize()
            
            # Event ì²˜ë¦¬
            logger.info("Projection ì²˜ë¦¬ ì¤‘...")
            
            # ìˆ˜ë™ìœ¼ë¡œ í•œ ë²ˆ ì²˜ë¦¬
            # ì‹¤ì œë¡œëŠ” worker.run()ì„ í˜¸ì¶œí•´ì•¼ í•˜ì§€ë§Œ 
            # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì§ì ‘ ì²˜ë¦¬
            
            logger.info("âœ… Projection Worker ì´ˆê¸°í™” ì™„ë£Œ")
            
            # ì •ë¦¬
            if hasattr(worker, 'consumer'):
                worker.consumer.close()
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Projection Worker ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return False
    
    async def step7_verify_elasticsearch(self):
        """Step 7: Elasticsearch ë°ì´í„° í™•ì¸"""
        logger.info("\n" + "=" * 60)
        logger.info("Step 7: Elasticsearch ë°ì´í„° í™•ì¸")
        logger.info("=" * 60)
        
        index_name = f"instances_{self.test_db_name.replace('-', '_')}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(
                f"http://localhost:9201/{index_name}/_search",
                json={
                    "query": {
                        "match_all": {}
                    }
                }
            ) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    hits = data.get('hits', {}).get('hits', [])
                    
                    if hits:
                        logger.info(f"âœ… Elasticsearchì— {len(hits)}ê°œ ë¬¸ì„œ ì¡´ì¬")
                        for hit in hits:
                            logger.info(f"   Document ID: {hit['_id']}")
                        return True
                    else:
                        logger.warning("âš ï¸  Elasticsearchì— ë¬¸ì„œ ì—†ìŒ")
                        return False
                else:
                    logger.error(f"âŒ Elasticsearch ì¡°íšŒ ì‹¤íŒ¨: {resp.status}")
                    return False
    
    async def step8_verify_command_status(self):
        """Step 8: Command ìƒíƒœ í™•ì¸"""
        logger.info("\n" + "=" * 60)
        logger.info("Step 8: Command ìƒíƒœ í™•ì¸")
        logger.info("=" * 60)
        
        import redis.asyncio as redis
        
        client = redis.Redis(
            host="localhost",
            port=6379,
            decode_responses=True
        )
        
        try:
            status_key = f"command:{self.test_command_id}:status"
            status_data = await client.get(status_key)
            
            if status_data:
                status = json.loads(status_data)
                logger.info(f"âœ… Command ìƒíƒœ: {status.get('status')}")
                
                if status.get('status') == 'COMPLETED':
                    logger.info("   ì²˜ë¦¬ ì™„ë£Œ!")
                    return True
                else:
                    logger.warning(f"   ìƒíƒœ: {status.get('status')}")
                    return False
            else:
                logger.error("âŒ Command ìƒíƒœ ì—†ìŒ")
                return False
                
        finally:
            await client.aclose()
    
    async def run_complete_test(self):
        """ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ğŸš€ COMPLETE EVENT SOURCING PIPELINE TEST")
        logger.info("=" * 60)
        
        results = {
            "database_created": False,
            "command_created": False,
            "message_relayed": False,
            "command_processed": False,
            "event_published": False,
            "projection_done": False,
            "elasticsearch_data": False,
            "command_status": False
        }
        
        try:
            # Step 1: ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
            results["database_created"] = await self.step1_create_database()
            if not results["database_created"]:
                logger.error("ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨ - í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨")
                return results
            
            await asyncio.sleep(2)
            
            # Step 2: Command ìƒì„±
            results["command_created"] = await self.step2_create_command()
            if not results["command_created"]:
                logger.error("Command ìƒì„± ì‹¤íŒ¨ - í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨")
                return results
            
            await asyncio.sleep(1)
            
            # Step 3: Message Relay
            results["message_relayed"] = await self.step3_run_message_relay()
            
            # Step 4: Command ì²˜ë¦¬
            results["command_processed"] = await self.step4_process_command()
            
            # Step 5: Event í™•ì¸
            results["event_published"] = await self.step5_check_event()
            
            # Step 6: Projection
            results["projection_done"] = await self.step6_run_projection()
            
            # Step 7: Elasticsearch
            results["elasticsearch_data"] = await self.step7_verify_elasticsearch()
            
            # Step 8: Command Status
            results["command_status"] = await self.step8_verify_command_status()
            
        except Exception as e:
            logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
        
        # ê²°ê³¼ ìš”ì•½
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        logger.info("=" * 60)
        
        for step, success in results.items():
            status = "âœ…" if success else "âŒ"
            logger.info(f"{status} {step}: {success}")
        
        all_success = all(results.values())
        
        if all_success:
            logger.info("\nğŸ‰ ì „ì²´ Event Sourcing íŒŒì´í”„ë¼ì¸ ì •ìƒ ì‘ë™!")
        else:
            logger.info("\nâš ï¸  ì¼ë¶€ ë‹¨ê³„ ì‹¤íŒ¨")
            failed = [k for k, v in results.items() if not v]
            logger.info(f"   ì‹¤íŒ¨í•œ ë‹¨ê³„: {', '.join(failed)}")
        
        return results


async def main():
    tester = CompletePipelineTest()
    results = await tester.run_complete_test()
    
    # ì„±ê³µ ì—¬ë¶€ ë°˜í™˜
    return all(results.values())


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)