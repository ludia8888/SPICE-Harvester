# 🏗️ SPICE HARVESTER 아키텍처 문서
## Event Sourcing + CQRS 기반 엔터프라이즈 데이터 관리 플랫폼

이 문서는 SPICE HARVESTER의 전체 시스템 아키텍처를 상세히 설명합니다. 본 시스템은 **이벤트 소싱(Event Sourcing) + CQRS** 패턴을 기반으로 하며, 데이터의 특성에 따라 **하이브리드 저장 전략**을 적용하여 최적의 성능과 확장성을 달성합니다.

---

## 📋 목차

1. [아키텍처 개요](#1-아키텍처-개요)
2. [핵심 설계 원칙](#2-핵심-설계-원칙)
3. [하이브리드 데이터 아키텍처](#3-하이브리드-데이터-아키텍처)
4. [시스템 컴포넌트 상세](#4-시스템-컴포넌트-상세)
5. [데이터 흐름 및 통신](#5-데이터-흐름-및-통신)
6. [저장소별 역할 및 책임](#6-저장소별-역할-및-책임)
7. [CQRS 구현 상세](#7-cqrs-구현-상세)
8. [Event Sourcing 구현 상세](#8-event-sourcing-구현-상세)
9. [성능 최적화 전략](#9-성능-최적화-전략)
10. [확장성 및 고가용성](#10-확장성-및-고가용성)

---

## 1. 아키텍처 개요

### 🎯 **아키텍처 철학**

SPICE HARVESTER는 **"데이터의 모든 변화를 추적하고 관리한다"**는 핵심 철학 하에 설계되었습니다. 이를 위해 다음과 같은 아키텍처 전략을 채택했습니다:

- **하이브리드 데이터 관리**: 데이터 특성에 따른 최적화된 저장 전략
- **완전한 감사 추적**: 모든 데이터 변경 이력의 불변 기록
- **읽기/쓰기 분리**: CQRS를 통한 성능 최적화
- **비동기 이벤트 기반**: 마이크로서비스 간 느슨한 결합

### 📊 **전체 시스템 아키텍처 - 초상세 구현 다이어그램**

```mermaid
graph TD
    subgraph "🖥️ 클라이언트 생태계"
        subgraph "Frontend Applications"
            REACT_UI[React Web UI<br/>📱 TypeScript + Blueprint.js<br/>🎨 GlobalSidebar + Accessibility<br/>🧪 Vitest + MSW Testing]
            MOBILE_APP[Mobile App<br/>📲 React Native (Future)]
            DESKTOP_APP[Desktop App<br/>🖥️ Electron (Future)]
        end
        
        subgraph "API Consumers"
            EXT_API[External API Clients<br/>🔌 REST API Consumers<br/>📊 Data Analytics Tools]
            CLI_TOOLS[Command Line Tools<br/>⌨️ spice-cli<br/>🔧 Admin Scripts]
            WEBHOOKS[Webhook Clients<br/>🪝 Event Notifications<br/>📨 Integration Partners]
        end
    end

    subgraph "🌐 API Gateway & Load Balancing"
        subgraph "Load Balancer"
            LB[HAProxy/Nginx<br/>⚖️ Load Balancer<br/>🔒 SSL Termination<br/>📊 Health Checks]
        end
        
        subgraph "BFF Cluster (Port 8002-8005)"
            BFF1[BFF Instance 1<br/>🚪 Port 8002<br/>🔐 JWT Authentication<br/>🌐 CORS Handler<br/>📝 Request Logging<br/>⚡ Connection Pool: 50/100]
            BFF2[BFF Instance 2<br/>🚪 Port 8003<br/>📊 Rate Limiting<br/>🔄 Circuit Breaker<br/>📈 Metrics Collection]
            BFF3[BFF Instance 3<br/>🚪 Port 8004<br/>🔍 Request Validation<br/>📋 Response Standardization<br/>⚡ Cache Management]
        end
    end

    subgraph "⚡ Core Services Layer"
        subgraph "OMS Cluster (Port 8000-8001)"
            OMS1[OMS Primary<br/>🚪 Port 8000<br/>🎯 Command Gateway<br/>✅ 18+ Type Validators<br/>🌳 Git Features (7/7)<br/>📦 Outbox Publisher]
            OMS2[OMS Replica<br/>🚪 Port 8001<br/>🔄 Failover Ready<br/>📊 Read Queries<br/>⚖️ Load Distribution]
        end
        
        subgraph "AI Services"
            FUNNEL1[Funnel Primary<br/>🚪 Port 8004<br/>🧠 AI Type Inference<br/>📊 1,048 Lines Algorithm<br/>🌍 Multi-language (4 langs)<br/>📋 18+ Complex Types<br/>🔗 Google Sheets Connector]
            FUNNEL2[Funnel Replica<br/>🚪 Port 8005<br/>🔄 ML Model Caching<br/>📈 Confidence Scoring<br/>⚡ Batch Processing]
        end
    end

    subgraph "📨 Messaging & Communication Layer"
        subgraph "Transactional Outbox (PostgreSQL)"
            OUTBOX_DB[(PostgreSQL DB<br/>🚪 Port 5432<br/>📦 Outbox Pattern<br/>🔒 ACID Transactions<br/>📊 WAL Replication<br/>⚡ Connection Pool: 20)]
            OUTBOX_TABLE[outbox Table<br/>📋 Schema:<br/>• id (UUID)<br/>• aggregate_id<br/>• event_type<br/>• payload (JSONB)<br/>• status<br/>• created_at<br/>• published_at]
        end
        
        subgraph "Message Relay Workers"
            RELAY1[Message Relay 1<br/>🔄 Outbox Poller<br/>⏱️ Poll Interval: 1s<br/>📤 Kafka Publisher<br/>💾 State Tracking]
            RELAY2[Message Relay 2<br/>🔄 Backup Poller<br/>🔀 Load Balancing<br/>📊 Metrics Collection]
        end
        
        subgraph "Kafka Cluster (Port 9092-9094)"
            KAFKA1[Kafka Broker 1<br/>🚪 Port 9092<br/>📊 Leader Partitions<br/>🔄 Replication Factor: 3<br/>⚡ EOS v2 (Exactly-Once)<br/>📈 Throughput: 500 events/sec]
            KAFKA2[Kafka Broker 2<br/>🚪 Port 9093<br/>📊 Follower Partitions<br/>🔄 Auto-Rebalancing<br/>📉 Consumer Lag Monitoring]
            KAFKA3[Kafka Broker 3<br/>🚪 Port 9094<br/>📊 Follower Partitions<br/>🛡️ Data Durability<br/>📊 Watermark Tracking]
            
            subgraph "Kafka Topics"
                TOPICS[📋 Topic Configuration:<br/>• ontology-commands (3 partitions)<br/>• instance-commands (6 partitions)<br/>• ontology-events (3 partitions)<br/>• instance-events (6 partitions)<br/>• dlq-ontology (1 partition)<br/>• dlq-instance (1 partition)]
            end
        end
    end

    subgraph "⚙️ Processing Workers Layer"
        subgraph "Instance Workers"
            IW1[Instance Worker 1<br/>📝 CQRS Command Handler<br/>🎯 Consumer Group: instance-workers<br/>📊 Partition Assignment: 0,1,2<br/>⚡ Event Sourcing (3-Step):<br/>1️⃣ Save to S3 (SSoT)<br/>2️⃣ Update TerminusDB<br/>3️⃣ Publish Domain Event]
            IW2[Instance Worker 2<br/>📝 Command Processing<br/>🎯 Consumer Group: instance-workers<br/>📊 Partition Assignment: 3,4,5<br/>🔄 ThreadPoolExecutor: 2 threads<br/>⚡ Performance: 50-100 cmd/sec]
        end
        
        subgraph "Ontology Workers" 
            OW1[Ontology Worker 1<br/>🗂️ Schema Management<br/>🎯 Consumer Group: ontology-workers<br/>📊 Git Operations (7/7):<br/>• Branch Management<br/>• Commit System<br/>• Diff & Merge<br/>• Rollback Support<br/>• History Tracking<br/>• Pull Requests<br/>• Conflict Resolution]
            OW2[Ontology Worker 2<br/>🗂️ Schema Validation<br/>🔍 Complex Type Validation<br/>📋 18+ Type Handlers<br/>⚡ Validation Speed: <100ms]
        end
        
        subgraph "Projection Workers"
            PW1[Projection Worker 1<br/>📊 Elasticsearch Indexer<br/>🎯 Consumer Group: projection-workers<br/>📋 Document Types:<br/>• instances-{db_name}<br/>• ontologies-{db_name}<br/>• search-metadata<br/>🔍 Full-text Indexing<br/>🌍 Multi-language Analysis]
            PW2[Projection Worker 2<br/>📊 Redis Cache Manager<br/>💨 Cache Strategies:<br/>• L1: In-Memory (5min TTL)<br/>• L2: Redis (1hr TTL)<br/>• L3: Database (fallback)<br/>🔄 Smart Invalidation<br/>⚡ Hit Ratio: 85%+]
            PW3[Projection Worker 3<br/>📊 Metrics & Analytics<br/>📈 Business Metrics<br/>🔍 Query Optimization<br/>📊 Performance Tracking]
        end
        
        subgraph "DLQ Handlers"
            DLQ1[DLQ Handler 1<br/>🚨 Dead Letter Queue<br/>🔄 Exponential Backoff<br/>⚡ ThreadPoolExecutor Fix<br/>📊 Retry Pattern: 1s, 2s, 4s<br/>🔧 Poison Message Detection<br/>📈 Recovery Rate: 5/5 (100%)]
            DLQ2[DLQ Handler 2<br/>🚨 Backup Handler<br/>📊 Metrics Collection<br/>🔔 Alert Generation<br/>📋 Manual Intervention Queue]
        end
    end

    subgraph "💾 데이터 저장소 생태계"
        subgraph "🔥 Single Source of Truth (SSoT)"
            subgraph "S3/MinIO Event Store"
                S3_PRIMARY[S3/MinIO Primary<br/>🚪 Port 9000<br/>📚 Event Store (SSoT)<br/>🗂️ Bucket: spice-event-store<br/>📂 Structure:<br/>  📁 events/year=2024/month=08/<br/>  📁 snapshots/aggregate={id}/<br/>  📁 indexes/by_date/<br/>💾 Storage: Append-Only<br/>🗜️ Compression: gzip (50% saving)<br/>⚡ Performance: 1000+ writes/sec]
                S3_REPLICA[S3/MinIO Replica<br/>🚪 Port 9001<br/>🔄 Cross-Region Replication<br/>🛡️ Disaster Recovery<br/>📊 Backup Schedule: 4x/day<br/>⚖️ Load Distribution]
            end
            
            subgraph "TerminusDB Cluster"
                TERMINUS_PRIMARY[TerminusDB Primary<br/>🚪 Port 6364<br/>🎯 Ontology SSoT<br/>📊 Graph Database<br/>🌳 Git Repository:<br/>  📋 7/7 Git Features<br/>  🌿 Branch Management<br/>  📝 Commit History<br/>  🔀 Merge Operations<br/>  ↩️ Rollback Support<br/>⚡ Query Performance: <100ms<br/>💾 Storage: 10GB+ schemas]
                TERMINUS_REPLICA[TerminusDB Replica<br/>🚪 Port 6365<br/>🔄 Read Replica<br/>📊 Load Balancing<br/>⚡ Query Optimization<br/>📈 Connection Pool: 50]
            end
        end
        
        subgraph "🔍 읽기 최적화 모델 (Read Models)"
            subgraph "Elasticsearch Cluster"
                ES_MASTER[Elasticsearch Master<br/>🚪 Port 9200<br/>🔍 Search Engine<br/>📊 Index Management:<br/>  📋 instances-* (6 shards)<br/>  📋 ontologies-* (3 shards)<br/>  📋 search-metadata (1 shard)<br/>🌍 Multi-language Analyzer<br/>⚡ Query Speed: <50ms<br/>📈 Index Size: 1GB+]
                ES_DATA1[Elasticsearch Data 1<br/>🚪 Port 9201<br/>📊 Data Node<br/>🔍 Full-text Search<br/>📈 Aggregation Queries<br/>💾 Hot Storage]
                ES_DATA2[Elasticsearch Data 2<br/>🚪 Port 9202<br/>📊 Data Node<br/>🔍 Faceted Search<br/>📊 Analytics Queries<br/>❄️ Warm Storage]
            end
            
            subgraph "Redis Cluster"
                REDIS_PRIMARY[Redis Primary<br/>🚪 Port 6379<br/>🚀 Cache Layer<br/>💨 Cache Types:<br/>  🔑 instance:{db}:{id}<br/>  🔑 ontology:{db}:{class}<br/>  🔑 search:{db}:{query_hash}<br/>  🔑 session:{user_id}<br/>  🔑 cmd:{command_id}<br/>⚡ Performance: <1ms<br/>💾 Memory: 8GB<br/>📊 Hit Ratio: 85%+]
                REDIS_REPLICA[Redis Replica<br/>🚪 Port 6380<br/>🔄 Read Replica<br/>📊 Backup & Failover<br/>⚡ Automatic Failover<br/>📈 Connection Pool: 100]
            end
        end
        
        subgraph "📊 관찰성 & 모니터링"
            subgraph "Monitoring Stack"
                PROMETHEUS[Prometheus<br/>🚪 Port 9090<br/>📊 Metrics Collection<br/>⏰ Scrape Interval: 15s<br/>📈 Metrics Storage<br/>🔔 Alerting Rules]
                GRAFANA[Grafana<br/>🚪 Port 3000<br/>📊 Visualization<br/>📋 Dashboards:<br/>  📈 System Health<br/>  📊 Business Metrics<br/>  ⚡ Performance Metrics<br/>🔔 Alert Management]
                JAEGER[Jaeger<br/>🚪 Port 16686<br/>🔍 Distributed Tracing<br/>📊 OpenTelemetry<br/>⚡ Trace Analysis<br/>🎯 Performance Bottlenecks]
            end
            
            subgraph "Logging Stack"
                ELASTICSEARCH_LOG[Elasticsearch Logs<br/>🚪 Port 9203<br/>📋 Log Aggregation<br/>🔍 Log Search<br/>📊 Log Analytics]
                KIBANA[Kibana<br/>🚪 Port 5601<br/>📊 Log Visualization<br/>🔍 Log Analysis<br/>📈 Error Tracking]
                FILEBEAT[Filebeat<br/>📋 Log Shipping<br/>📊 Log Collection<br/>🔄 Log Processing]
            end
        end
    end

    %% 클라이언트 → Load Balancer
    REACT_UI -->|HTTPS| LB
    EXT_API -->|REST API| LB
    CLI_TOOLS -->|HTTP/2| LB
    WEBHOOKS -->|Webhook Events| LB

    %% Load Balancer → BFF Cluster
    LB -->|Round Robin| BFF1
    LB -->|Weighted| BFF2
    LB -->|Health Check| BFF3

    %% BFF → Services (with detailed connections)
    BFF1 -->|Command Requests| OMS1
    BFF1 -->|AI Inference| FUNNEL1
    BFF2 -->|Failover| OMS2
    BFF2 -->|ML Processing| FUNNEL2
    BFF3 -->|Read Queries| OMS1

    %% OMS → Outbox Pattern
    OMS1 -->|INSERT Commands| OUTBOX_DB
    OMS2 -->|INSERT Commands| OUTBOX_DB
    OUTBOX_DB -->|Store in| OUTBOX_TABLE

    %% Message Relay → Kafka
    RELAY1 -->|Poll & Publish| KAFKA1
    RELAY2 -->|Backup Publishing| KAFKA2
    OUTBOX_TABLE -->|Polling| RELAY1
    OUTBOX_TABLE -->|Polling| RELAY2

    %% Kafka Internal Replication
    KAFKA1 <-->|Replication| KAFKA2
    KAFKA2 <-->|Replication| KAFKA3
    KAFKA3 <-->|Replication| KAFKA1

    %% Kafka → Workers (with topic-specific routing)
    KAFKA1 -.->|instance-commands| IW1
    KAFKA2 -.->|instance-commands| IW2
    KAFKA1 -.->|ontology-commands| OW1
    KAFKA3 -.->|ontology-commands| OW2
    KAFKA1 -.->|*-events| PW1
    KAFKA2 -.->|*-events| PW2
    KAFKA3 -.->|*-events| PW3

    %% DLQ Processing
    KAFKA1 -.->|dlq-*| DLQ1
    KAFKA2 -.->|dlq-*| DLQ2

    %% Instance Workers → Storage (3-step process)
    IW1 -->|1. Event Log| S3_PRIMARY
    IW1 -->|2. State Update| TERMINUS_PRIMARY
    IW1 -->|3. Domain Event| KAFKA1
    IW2 -->|1. Event Log| S3_REPLICA
    IW2 -->|2. State Update| TERMINUS_REPLICA
    IW2 -->|3. Domain Event| KAFKA2

    %% Ontology Workers → Storage
    OW1 -->|Schema Changes| TERMINUS_PRIMARY
    OW1 -->|Git Operations| TERMINUS_PRIMARY
    OW1 -->|Domain Events| KAFKA1
    OW2 -->|Validation| TERMINUS_REPLICA
    OW2 -->|Domain Events| KAFKA2

    %% Projection Workers → Read Models
    PW1 -->|Index Documents| ES_MASTER
    PW1 -->|Index Data| ES_DATA1
    PW2 -->|Cache Updates| REDIS_PRIMARY
    PW2 -->|Cache Replication| REDIS_REPLICA
    PW3 -->|Analytics Data| ES_DATA2

    %% BFF → Read Models (CQRS Read Path)
    BFF1 -.->|Search Queries| ES_MASTER
    BFF1 -.->|Direct Gets| TERMINUS_PRIMARY
    BFF1 -.->|Cache Queries| REDIS_PRIMARY
    BFF2 -.->|Load Balanced| ES_DATA1
    BFF2 -.->|Read Replica| TERMINUS_REPLICA
    BFF3 -.->|Cache Fallback| REDIS_REPLICA

    %% Storage Replication
    S3_PRIMARY <-->|Replication| S3_REPLICA
    TERMINUS_PRIMARY <-->|Replication| TERMINUS_REPLICA
    REDIS_PRIMARY <-->|Replication| REDIS_REPLICA
    ES_MASTER <-->|Cluster Sync| ES_DATA1
    ES_MASTER <-->|Cluster Sync| ES_DATA2

    %% Monitoring Connections
    PROMETHEUS -->|Scrape Metrics| BFF1
    PROMETHEUS -->|Scrape Metrics| OMS1
    PROMETHEUS -->|Scrape Metrics| KAFKA1
    FILEBEAT -->|Ship Logs| ELASTICSEARCH_LOG
    JAEGER -->|Collect Traces| BFF1
    JAEGER -->|Collect Traces| OMS1

    %% 스타일링 (상세 색상 구분)
    style LB fill:#ff6b6b,stroke:#d63031,stroke-width:3px,color:#fff
    style BFF1 fill:#74b9ff,stroke:#0984e3,stroke-width:3px,color:#fff
    style BFF2 fill:#74b9ff,stroke:#0984e3,stroke-width:2px,color:#fff
    style BFF3 fill:#74b9ff,stroke:#0984e3,stroke-width:2px,color:#fff
    
    style OMS1 fill:#00b894,stroke:#00a085,stroke-width:3px,color:#fff
    style OMS2 fill:#00b894,stroke:#00a085,stroke-width:2px,color:#fff
    style FUNNEL1 fill:#fdcb6e,stroke:#e17055,stroke-width:3px,color:#fff
    style FUNNEL2 fill:#fdcb6e,stroke:#e17055,stroke-width:2px,color:#fff
    
    style KAFKA1 fill:#a29bfe,stroke:#6c5ce7,stroke-width:3px,color:#fff
    style KAFKA2 fill:#a29bfe,stroke:#6c5ce7,stroke-width:2px,color:#fff
    style KAFKA3 fill:#a29bfe,stroke:#6c5ce7,stroke-width:2px,color:#fff
    
    style IW1 fill:#fd79a8,stroke:#e84393,stroke-width:2px,color:#fff
    style IW2 fill:#fd79a8,stroke:#e84393,stroke-width:2px,color:#fff
    style OW1 fill:#fd79a8,stroke:#e84393,stroke-width:2px,color:#fff
    style OW2 fill:#fd79a8,stroke:#e84393,stroke-width:2px,color:#fff
    style PW1 fill:#fd79a8,stroke:#e84393,stroke-width:2px,color:#fff
    style PW2 fill:#fd79a8,stroke:#e84393,stroke-width:2px,color:#fff
    style PW3 fill:#fd79a8,stroke:#e84393,stroke-width:2px,color:#fff
    
    style S3_PRIMARY fill:#e17055,stroke:#d63031,stroke-width:4px,color:#fff
    style S3_REPLICA fill:#e17055,stroke:#d63031,stroke-width:3px,color:#fff
    style TERMINUS_PRIMARY fill:#e17055,stroke:#d63031,stroke-width:4px,color:#fff
    style TERMINUS_REPLICA fill:#e17055,stroke:#d63031,stroke-width:3px,color:#fff
    
    style ES_MASTER fill:#0984e3,stroke:#74b9ff,stroke-width:3px,color:#fff
    style ES_DATA1 fill:#0984e3,stroke:#74b9ff,stroke-width:2px,color:#fff
    style ES_DATA2 fill:#0984e3,stroke:#74b9ff,stroke-width:2px,color:#fff
    style REDIS_PRIMARY fill:#00cec9,stroke:#00b894,stroke-width:3px,color:#fff
    style REDIS_REPLICA fill:#00cec9,stroke:#00b894,stroke-width:2px,color:#fff
    
    style DLQ1 fill:#fab1a0,stroke:#e17055,stroke-width:2px,color:#fff
    style DLQ2 fill:#fab1a0,stroke:#e17055,stroke-width:2px,color:#fff
```

### 🔄 **핵심 아키텍처 패턴**

| 패턴 | 목적 | 구현 위치 | 효과 |
|------|------|-----------|------|
| **CQRS** | 읽기/쓰기 분리 | BFF ↔ 각종 저장소 | 독립적 최적화 |
| **Event Sourcing** | 완전한 이력 추적 | Instance Worker → S3 | 무손실 감사 추적 |
| **Outbox Pattern** | 트랜잭션 안전성 | OMS → PostgreSQL → Kafka | 메시지 무손실 |
| **마이크로서비스** | 서비스 분리 | OMS, Funnel, Workers | 독립 배포/확장 |
| **Projection** | 읽기 모델 최적화 | Events → Elasticsearch | 쿼리 성능 최적화 |

---

## 2. 핵심 설계 원칙

### 🛡️ **데이터 무결성 및 일관성**

#### ✅ **불변성 원칙 (Immutability)**
```
인스턴스 데이터의 모든 변경은 새로운 이벤트로 S3에 추가(append-only)
→ 기존 데이터는 절대 수정/삭제되지 않음
→ 완벽한 감사 추적 및 시간 여행 기능 제공
```

#### ✅ **단일 진실 공급원 (Single Source of Truth)**
- **인스턴스 데이터 SSoT**: S3에 저장된 이벤트 로그
- **온톨로지 데이터 SSoT**: TerminusDB에 저장된 최신 스키마 상태
- **읽기 모델**: 모든 읽기 모델은 SSoT로부터 파생된 프로젝션

#### ✅ **최종 일관성 (Eventual Consistency)**
- 쓰기 모델과 읽기 모델 간의 일관성은 이벤트를 통해 비동기적으로 달성
- Kafka의 순서 보장을 통해 일관성 확보
- 파티션 키(aggregate_id)로 집계별 순서 보장

### ⚡ **성능 및 확장성**

#### ✅ **읽기/쓰기 최적화**
- **쓰기 경로**: 명령 처리에 최적화, 빠른 검증 및 이벤트 저장
- **읽기 경로**: 다양한 쿼리 패턴에 최적화된 여러 읽기 모델
- **캐시 전략**: 자주 조회되는 데이터는 Redis에 캐싱

#### ✅ **수평 확장성**
- **서비스별 독립 확장**: 각 마이크로서비스는 독립적으로 확장 가능
- **Kafka 파티셔닝**: 높은 처리량을 위한 분산 메시지 처리
- **읽기 모델 복제**: Elasticsearch 클러스터링으로 읽기 성능 향상

### 🔐 **보안 및 감사**

#### ✅ **완전한 감사 추적**
- 모든 명령은 사용자 ID, 타임스탬프, 이유와 함께 기록
- 이벤트 소싱으로 "누가, 언제, 무엇을, 왜" 변경했는지 완벽 추적
- 불변 로그로 데이터 위변조 방지

#### ✅ **접근 제어**
- JWT 기반 인증 및 인가
- API Gateway(BFF)에서 중앙화된 보안 정책 적용
- 서비스 간 통신은 내부 네트워크로 보호

---

## 3. 하이브리드 데이터 아키텍처

SPICE HARVESTER의 가장 혁신적인 특징은 **데이터 특성에 따른 최적화된 관리 전략**입니다.

### 📊 **데이터 분류 및 관리 전략**

```mermaid
graph TD
    subgraph "🗂️ 온톨로지 데이터"
        ONT_CHAR[특성:<br/>• 스키마 역할<br/>• 변경 빈도 낮음<br/>• 최신 상태 중요<br/>• 관계형 복잡]
        ONT_STRATEGY[관리 전략:<br/>상태 저장<br/>(State-Store)]
        ONT_STORAGE[저장소:<br/>TerminusDB<br/>Graph Database]
    end

    subgraph "📝 인스턴스 데이터"
        INS_CHAR[특성:<br/>• 실제 데이터<br/>• 변경 빈도 높음<br/>• 이력 추적 필수<br/>• 완전한 감사 필요]
        INS_STRATEGY[관리 전략:<br/>이벤트 소싱<br/>(Event Sourcing)]
        INS_STORAGE[저장소:<br/>S3 Event Store<br/>Append-only Log]
    end

    ONT_CHAR --> ONT_STRATEGY
    ONT_STRATEGY --> ONT_STORAGE

    INS_CHAR --> INS_STRATEGY
    INS_STRATEGY --> INS_STORAGE

    style ONT_STRATEGY fill:#e8f5e8
    style INS_STRATEGY fill:#fff3e0
```

### 🔄 **하이브리드 아키텍처의 장점**

#### ✅ **온톨로지 데이터 (상태 저장 방식)**
- **빠른 조회**: 최신 스키마 상태를 즉시 조회
- **관계형 쿼리**: 복잡한 온톨로지 관계를 효율적으로 탐색
- **일관성**: 스키마 변경 시 즉시 일관된 상태 유지
- **Git 기능**: 브랜치, 커밋, 병합 등 버전 관리 기능 완벽 지원

#### ✅ **인스턴스 데이터 (이벤트 소싱 방식)**
- **완전한 감사**: 모든 변경사항의 불변 기록
- **시간 여행**: 특정 시점의 데이터 상태 완벽 복원
- **데이터 계보**: 현재 상태가 어떤 변경들로 만들어졌는지 추적
- **무손실**: 실수로 삭제되거나 손상된 데이터 복구 가능

### 📈 **성능 비교**

| 작업 유형 | 전통적 방식 | SPICE HARVESTER | 개선 효과 |
|----------|------------|-----------------|-----------|
| 온톨로지 조회 | 복잡한 JOIN | Direct Graph Query | 5-10x 빠름 |
| 인스턴스 감사 | 별도 로그 테이블 | Event Log 직접 조회 | 무한 이력 추적 |
| 스키마 버전 관리 | 수동 관리 | Git-like 자동화 | 100% 자동화 |
| 데이터 복구 | 백업/복원 | Event Replay | 1초 내 복구 |

---

## 4. 시스템 컴포넌트 상세

### 🌐 **API 게이트웨이 레이어**

#### **BFF (Backend for Frontend) - Port 8002**
```python
# 핵심 책임
- 클라이언트 요청의 단일 진입점
- 요청 라우팅 및 집계
- 인증/인가 처리
- 읽기 모델 직접 조회
- 응답 표준화 (ApiResponse 형식)
```

**주요 API 엔드포인트:**
- `POST /api/v1/database` - 데이터베이스 생성
- `GET /api/v1/database/{db}/ontology/{class}` - 온톨로지 조회
- `POST /api/v1/database/{db}/ontology` - 온톨로지 생성
- `GET /api/v1/database/{db}/instances` - 인스턴스 검색
- `POST /api/v1/database/{db}/instances` - 인스턴스 생성

### ⚙️ **서비스 레이어**

#### **OMS (Ontology Management Service) - Port 8000**
```python
# 핵심 책임
- 모든 명령(Command)의 검증 및 처리
- Outbox 패턴을 통한 안전한 메시지 발행
- 온톨로지 스키마 직접 관리
- 복합 데이터 타입 검증 (18+ 타입)
- Git 기능 구현 (7/7 완성)
```

**Git 기능 구현 상세:**
- **브랜치 관리**: `create_branch()`, `switch_branch()`, `delete_branch()`
- **커밋 시스템**: `commit_changes()` with 메시지, 작성자, 타임스탬프
- **비교 기능**: `diff_branches()`, `diff_commits()` - 3단계 비교 (커밋/스키마/프로퍼티)
- **병합 기능**: `merge_branches()`, `rebase_branch()` with 충돌 해결
- **롤백 기능**: `rollback_to_commit()` - 안전한 되돌리기
- **히스토리**: `get_commit_history()` - 전체 변경 이력

#### **Funnel (AI Type Inference Service) - Port 8004**
```python
# 핵심 책임 (1,048라인 고급 알고리즘)
- 외부 데이터 소스 분석
- 18+ 복합 데이터 타입 자동 감지
- 다국어 패턴 인식 (한/영/일/중)
- 온톨로지 스키마 자동 생성
- 구글 시트 직접 분석 및 스키마 제안
```

**지원하는 복합 타입:**
- **EMAIL**: RFC 5322 완벽 검증
- **PHONE**: 국제 번호 형식 지원 (E164, NATIONAL)
- **MONEY**: 다중 통화 지원 (KRW, USD, EUR 등)
- **ARRAY**: 중첩 배열 및 타입별 검증
- **OBJECT**: 복잡한 중첩 객체 스키마
- **DATE/TIME**: ISO 8601 및 다양한 지역 형식
- **URL/URI**: RFC 3986 표준 검증
- 기타 12개 추가 복합 타입

### 📨 **메시징 레이어**

#### **PostgreSQL Outbox Pattern**
```sql
-- outbox 테이블 구조
CREATE TABLE outbox (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    aggregate_id VARCHAR(255) NOT NULL,
    event_type VARCHAR(100) NOT NULL,
    payload JSONB NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    published_at TIMESTAMP WITH TIME ZONE,
    status VARCHAR(20) DEFAULT 'PENDING'
);

-- 인덱스 최적화
CREATE INDEX idx_outbox_status_created ON outbox(status, created_at);
CREATE INDEX idx_outbox_aggregate_id ON outbox(aggregate_id);
```

**Outbox Pattern 장점:**
- ✅ **트랜잭션 안전성**: DB 변경과 메시지 발행의 원자성 보장
- ✅ **신뢰성**: 시스템 오류 시에도 메시지 손실 방지
- ✅ **순서 보장**: 동일 집계의 이벤트 순서 유지
- ✅ **재시도 기능**: 실패한 메시지 자동 재시도

#### **Message Relay Worker**
```python
class MessageRelay:
    async def poll_and_publish(self):
        """Outbox 패턴 핵심 로직"""
        # 1. PostgreSQL에서 미발행 이벤트 조회
        pending_events = await self.get_pending_events()
        
        for event in pending_events:
            try:
                # 2. Kafka로 이벤트 발행
                await self.kafka_producer.send(
                    topic=event.topic,
                    key=event.aggregate_id,  # 파티션 키
                    value=event.payload
                )
                
                # 3. 발행 완료 표시
                await self.mark_as_published(event.id)
                
            except Exception as e:
                # 4. 실패 시 재시도 대기열로
                await self.handle_publish_failure(event, e)
```

#### **Apache Kafka - 고성능 이벤트 버스**
```yaml
# Kafka 설정 (Exactly-Once Semantics v2)
transaction.timeout.ms: 300000
delivery.timeout.ms: 120000
acks: all
enable.idempotence: true
max.in.flight.requests.per.connection: 5

# 파티션 전략
partitioner.class: org.apache.kafka.clients.producer.internals.DefaultPartitioner
# 키 = aggregate_id로 동일 집계 이벤트의 순서 보장
```

**Kafka 토픽 구조:**
- `ontology-commands`: 온톨로지 변경 명령
- `instance-commands`: 인스턴스 변경 명령  
- `ontology-events`: 온톨로지 도메인 이벤트
- `instance-events`: 인스턴스 도메인 이벤트
- `dlq-*`: Dead Letter Queue 토픽들

### ⚙️ **워커 레이어**

#### **Instance Worker**
```python
class InstanceWorker:
    async def process_command(self, command):
        """인스턴스 명령 처리 - 3단계 프로세스"""
        
        # 1단계: S3에 명령 로그 저장 (SSoT)
        command_log = {
            "command_id": command.id,
            "aggregate_id": command.aggregate_id,
            "command_type": command.type,
            "payload": command.payload,
            "timestamp": command.timestamp,
            "user_id": command.user_id
        }
        await self.s3_client.put_object(
            bucket="spice-event-store",
            key=f"instances/{command.aggregate_id}/{command.id}.json",
            body=json.dumps(command_log)
        )
        
        # 2단계: TerminusDB 최신 상태 업데이트 (Write Model Cache)
        await self.terminus_client.execute_command(command)
        
        # 3단계: 도메인 이벤트 발행
        domain_event = self.create_domain_event(command)
        await self.kafka_producer.send("instance-events", domain_event)
```

#### **Ontology Worker**  
```python
class OntologyWorker:
    async def process_command(self, command):
        """온톨로지 명령 처리 - 직접 상태 업데이트"""
        
        # TerminusDB에 스키마 직접 변경 (SSoT)
        if command.type == "CREATE_ONTOLOGY":
            await self.terminus_client.create_class(
                database=command.database,
                class_definition=command.payload
            )
            
        elif command.type == "UPDATE_ONTOLOGY":
            await self.terminus_client.update_class(
                database=command.database,
                class_id=command.class_id,
                updates=command.payload
            )
            
        # Git 기능 업데이트
        await self.update_git_metadata(command)
        
        # 도메인 이벤트 발행
        domain_event = self.create_domain_event(command)
        await self.kafka_producer.send("ontology-events", domain_event)
```

#### **Projection Worker**
```python
class ProjectionWorker:
    async def handle_event(self, event):
        """도메인 이벤트를 읽기 모델로 프로젝션"""
        
        if event.type == "INSTANCE_CREATED":
            # Elasticsearch 검색 문서 생성
            search_doc = {
                "id": event.instance_id,
                "type": event.instance_type,
                "properties": self.flatten_for_search(event.data),
                "created_at": event.timestamp,
                "database": event.database
            }
            
            await self.elasticsearch.index(
                index=f"instances-{event.database}",
                doc_type="_doc",
                body=search_doc
            )
            
            # Redis 캐시 업데이트
            cache_key = f"instance:{event.database}:{event.instance_id}"
            await self.redis.setex(
                cache_key, 
                ttl=3600,  # 1시간 캐시
                value=json.dumps(event.data)
            )
            
        elif event.type == "ONTOLOGY_UPDATED":
            # 온톨로지 메타데이터 캐시 무효화
            pattern = f"ontology:{event.database}:*"
            await self.redis.delete_pattern(pattern)
```

---

## 5. 데이터 흐름 및 통신

### 📝 **명령 처리 흐름 (Write Path)**

```mermaid
sequenceDiagram
    participant Client
    participant BFF
    participant OMS
    participant PostgreSQL
    participant MessageRelay
    participant Kafka
    participant InstanceWorker
    participant S3
    participant TerminusDB as TerminusDB (Write)

    Client->>BFF: POST /api/v1/instances
    BFF->>OMS: Command Request
    
    Note over OMS: 명령 검증 및 처리
    OMS->>PostgreSQL: INSERT INTO outbox
    OMS-->>BFF: 202 Accepted (Command ID)
    BFF-->>Client: 202 Accepted
    
    loop Outbox Polling
        MessageRelay->>PostgreSQL: SELECT * FROM outbox WHERE status='PENDING'
        MessageRelay->>Kafka: Publish Command
        MessageRelay->>PostgreSQL: UPDATE outbox SET status='PUBLISHED'
    end
    
    InstanceWorker->>Kafka: Consume Command
    
    par 3단계 동시 처리
        InstanceWorker->>S3: 1. Save Command Log (SSoT)
    and
        InstanceWorker->>TerminusDB: 2. Update Write Model
    and
        InstanceWorker->>Kafka: 3. Publish Domain Event
    end
```

### 🔍 **조회 처리 흐름 (Read Path)**

```mermaid
sequenceDiagram
    participant Client
    participant BFF
    participant Elasticsearch
    participant TerminusDB as TerminusDB (Read)
    participant Redis

    Client->>BFF: GET /api/v1/instances?search=...
    
    alt 복잡한 검색 쿼리
        BFF->>Elasticsearch: Search Query
        Elasticsearch-->>BFF: Search Results
    else 직접 ID 조회
        BFF->>Redis: GET instance:{id}
        
        alt Cache Hit
            Redis-->>BFF: Cached Data
        else Cache Miss
            BFF->>TerminusDB: Direct Query
            TerminusDB-->>BFF: Data
            BFF->>Redis: SET cache
        end
    end
    
    BFF-->>Client: ApiResponse<Data>
```

### 🔄 **프로젝션 구축 흐름 (Projection Path)**

```mermaid
sequenceDiagram
    participant Kafka
    participant ProjectionWorker
    participant Elasticsearch
    participant Redis

    Kafka->>ProjectionWorker: Domain Event
    
    Note over ProjectionWorker: 이벤트 타입별 처리
    
    par 읽기 모델 업데이트
        ProjectionWorker->>Elasticsearch: Index Document
    and
        ProjectionWorker->>Redis: Update Cache
    end
    
    Note over ProjectionWorker: 프로젝션 완료 로깅
```

---

## 6. 저장소별 역할 및 책임

### 💾 **저장소 아키텍처 매트릭스**

| 저장소 | 주 역할 | 데이터 종류 | 일관성 수준 | SSoT 여부 | 백업 필요성 |
|--------|---------|-------------|-------------|-----------|------------|
| **S3/MinIO** | 이벤트 스토어 | 인스턴스 명령 로그 | 강 일관성 | ✅ Yes (Instance) | 🔥 매우 높음 |
| **TerminusDB** | Graph DB | 온톨로지 스키마 + 인스턴스 상태 | 강 일관성 | ✅ Yes (Ontology) | 🔥 매우 높음 |
| **Elasticsearch** | 검색 엔진 | 검색용 비정규화 데이터 | 최종 일관성 | ❌ No | ⚠️ 중간 (재구축 가능) |
| **PostgreSQL** | 메시지 큐 | Outbox 패턴 대기 이벤트 | 강 일관성 | ❌ No | ⚠️ 중간 (일시적 데이터) |
| **Redis** | 캐시 | 자주 조회되는 메타데이터 | 최종 일관성 | ❌ No | ⚡ 낮음 (재생성 가능) |

### 🗄️ **S3/MinIO - 이벤트 스토어**

#### **저장 구조**
```
spice-event-store/
├── instances/
│   ├── {aggregate_id}/
│   │   ├── {command_id_1}.json
│   │   ├── {command_id_2}.json
│   │   └── ...
│   └── ...
├── snapshots/
│   ├── {aggregate_id}/
│   │   ├── snapshot_v1.json
│   │   └── snapshot_v2.json
│   └── ...
└── indexes/
    ├── by_date/
    ├── by_user/
    └── by_type/
```

#### **명령 로그 형식**
```json
{
  "command_id": "cmd_123e4567-e89b-12d3-a456-426614174000",
  "aggregate_id": "instance_789",
  "command_type": "CREATE_INSTANCE",
  "payload": {
    "class_type": "Person",
    "properties": {
      "name": "홍길동",
      "email": "hong@example.com",
      "phone": "+82-10-1234-5678"
    }
  },
  "timestamp": "2024-08-12T10:30:00Z",
  "user_id": "user_456",
  "reason": "신규 직원 등록",
  "metadata": {
    "client_ip": "192.168.1.100",
    "user_agent": "SPICE-UI/2.0"
  }
}
```

#### **성능 최적화**
- **파티셔닝**: 날짜별, aggregate_id별 분산 저장
- **압축**: gzip 압축으로 저장 공간 50% 절약
- **인덱싱**: 빠른 조회를 위한 보조 인덱스
- **스냅샷**: 대량 이벤트 집계의 성능 최적화

### 🌐 **TerminusDB - 그래프 데이터베이스**

#### **데이터 모델**
```javascript
// 온톨로지 스키마 (SSoT)
{
  "@type": "Class",
  "@id": "Person",
  "label": "Person",
  "properties": {
    "name": { "@type": "xsd:string", "required": true },
    "email": { "@type": "custom:email", "required": true },
    "works_for": { 
      "@type": "@id", 
      "@class": "Company",
      "cardinality": "many_to_one"
    }
  },
  "git_metadata": {
    "branch": "main",
    "commit": "abc123",
    "author": "dev@spice.com",
    "timestamp": "2024-08-12T10:30:00Z"
  }
}

// 인스턴스 데이터 (Write Model Cache)
{
  "@type": "Person",
  "@id": "person_123",
  "name": "홍길동",
  "email": "hong@example.com",
  "works_for": "company_456",
  "_metadata": {
    "created_at": "2024-08-12T10:30:00Z",
    "updated_at": "2024-08-12T15:45:00Z",
    "version": 3
  }
}
```

#### **Git 기능 구현**
```javascript
// 브랜치 구조
{
  "databases": {
    "main": {
      "branches": {
        "main": { "commit": "abc123", "head": true },
        "feature/new-schema": { "commit": "def456", "head": false },
        "hotfix/urgent-fix": { "commit": "ghi789", "head": false }
      },
      "commits": {
        "abc123": {
          "parent": "xyz789",
          "message": "Add Person.email field",
          "author": "dev@spice.com",
          "timestamp": "2024-08-12T10:30:00Z",
          "changes": [...]
        }
      }
    }
  }
}
```

### 🔍 **Elasticsearch - 검색 엔진**

#### **인덱스 구조**
```json
// instances-{database_name} 인덱스
{
  "mappings": {
    "properties": {
      "id": { "type": "keyword" },
      "type": { "type": "keyword" },
      "database": { "type": "keyword" },
      "properties": {
        "type": "object",
        "dynamic": true
      },
      "created_at": { "type": "date" },
      "updated_at": { "type": "date" },
      "full_text": {
        "type": "text",
        "analyzer": "korean"
      }
    }
  }
}

// 실제 문서 예시
{
  "id": "person_123",
  "type": "Person",
  "database": "hr_system",
  "properties": {
    "name": "홍길동",
    "email": "hong@example.com",
    "phone": "+82-10-1234-5678",
    "department": "개발팀"
  },
  "created_at": "2024-08-12T10:30:00Z",
  "updated_at": "2024-08-12T15:45:00Z",
  "full_text": "홍길동 hong@example.com 개발팀 Person"
}
```

#### **검색 최적화**
- **다국어 분석기**: 한국어, 영어 동시 지원
- **자동 완성**: Completion Suggester 활용
- **패싯 검색**: 타입별, 날짜별 필터링
- **전문 검색**: 모든 필드를 통합한 full_text 검색

### ⚡ **Redis - 캐시 레이어**

#### **캐시 전략**
```python
# 캐시 키 패턴
CACHE_PATTERNS = {
    "instance": "instance:{database}:{id}",           # TTL: 1시간
    "ontology": "ontology:{database}:{class}",        # TTL: 6시간  
    "search_result": "search:{database}:{query_hash}", # TTL: 15분
    "user_session": "session:{user_id}",              # TTL: 24시간
    "command_status": "cmd:{command_id}",             # TTL: 1시간
}

# 캐시 무효화 전략
async def invalidate_cache(self, event):
    if event.type == "INSTANCE_UPDATED":
        pattern = f"instance:{event.database}:{event.instance_id}"
        await self.redis.delete(pattern)
        
        # 관련 검색 결과 캐시도 무효화
        search_pattern = f"search:{event.database}:*"
        await self.redis.delete_pattern(search_pattern)
```

---

## 7. CQRS 구현 상세

### 📊 **명령과 조회의 완전한 분리**

SPICE HARVESTER에서 CQRS는 단순한 읽기/쓰기 분리를 넘어서, **완전히 다른 최적화 전략**을 적용합니다.

```mermaid
graph LR
    subgraph "📝 명령 측면 (Command Side)"
        CMD[Commands]
        VALIDATION[검증 로직]
        BUSINESS[비즈니스 로직]
        EVENTS[이벤트 발행]
        
        CMD --> VALIDATION
        VALIDATION --> BUSINESS
        BUSINESS --> EVENTS
    end

    subgraph "🔍 조회 측면 (Query Side)"
        QUERIES[Queries]
        READ_MODEL1[Elasticsearch<br/>복잡한 검색]
        READ_MODEL2[TerminusDB<br/>직접 조회]
        READ_MODEL3[Redis<br/>캐시된 데이터]
        
        QUERIES --> READ_MODEL1
        QUERIES --> READ_MODEL2  
        QUERIES --> READ_MODEL3
    end

    EVENTS -.->|비동기 업데이트| READ_MODEL1
    EVENTS -.->|비동기 업데이트| READ_MODEL2
    EVENTS -.->|비동기 업데이트| READ_MODEL3

    style CMD fill:#ffebee
    style QUERIES fill:#e8f5e8
```

### 📝 **명령 모델 (Command Model)**

#### **명령 타입 정의**
```python
from dataclasses import dataclass
from typing import Dict, Any, Optional
from datetime import datetime

@dataclass
class Command:
    command_id: str
    aggregate_id: str
    command_type: str
    payload: Dict[str, Any]
    user_id: str
    timestamp: datetime
    reason: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None

# 구체적인 명령 타입들
@dataclass
class CreateInstanceCommand(Command):
    command_type: str = "CREATE_INSTANCE"

@dataclass  
class UpdateInstanceCommand(Command):
    command_type: str = "UPDATE_INSTANCE"
    
@dataclass
class CreateOntologyCommand(Command):
    command_type: str = "CREATE_ONTOLOGY"
```

#### **명령 처리기 (Command Handler)**
```python
class InstanceCommandHandler:
    async def handle_create_instance(self, cmd: CreateInstanceCommand):
        # 1. 비즈니스 규칙 검증
        await self._validate_business_rules(cmd)
        
        # 2. 집계 로드 (필요시)
        aggregate = await self._load_aggregate(cmd.aggregate_id)
        
        # 3. 명령 실행
        events = aggregate.handle_command(cmd)
        
        # 4. 이벤트 저장 및 발행
        for event in events:
            await self._save_and_publish_event(event)
    
    async def _validate_business_rules(self, cmd: CreateInstanceCommand):
        # 온톨로지 존재 확인
        ontology = await self.ontology_service.get_ontology(
            cmd.payload['database'], 
            cmd.payload['class_type']
        )
        if not ontology:
            raise BusinessRuleViolation("Ontology not found")
            
        # 필수 필드 검증
        required_fields = [p.name for p in ontology.properties if p.required]
        missing_fields = set(required_fields) - set(cmd.payload['properties'].keys())
        if missing_fields:
            raise BusinessRuleViolation(f"Missing required fields: {missing_fields}")
            
        # 복합 타입 검증
        for prop in ontology.properties:
            if prop.name in cmd.payload['properties']:
                value = cmd.payload['properties'][prop.name]
                await self._validate_complex_type(prop.type, value, prop.constraints)
```

### 🔍 **조회 모델 (Query Model)**

#### **조회 타입 정의**
```python
from enum import Enum
from typing import List, Optional, Dict

class QueryType(Enum):
    DIRECT_GET = "direct_get"           # ID로 직접 조회
    SEARCH = "search"                   # 전문 검색
    FILTER = "filter"                   # 필터링
    AGGREGATE = "aggregate"             # 집계 쿼리

@dataclass
class Query:
    query_id: str
    query_type: QueryType
    database: str
    parameters: Dict[str, Any]
    user_id: str
    timestamp: datetime

@dataclass
class SearchQuery(Query):
    query_type: QueryType = QueryType.SEARCH
    text: Optional[str] = None
    filters: Optional[Dict[str, Any]] = None
    sort: Optional[List[str]] = None
    limit: int = 20
    offset: int = 0
```

#### **조회 처리기 (Query Handler)**
```python
class InstanceQueryHandler:
    async def handle_search_query(self, query: SearchQuery) -> SearchResult:
        # 쿼리 타입에 따른 최적 저장소 선택
        if query.query_type == QueryType.DIRECT_GET:
            return await self._handle_direct_get(query)
        elif query.query_type == QueryType.SEARCH:
            return await self._handle_elasticsearch_search(query)
        elif query.query_type == QueryType.FILTER:
            return await self._handle_filtered_search(query)
    
    async def _handle_direct_get(self, query: SearchQuery) -> SearchResult:
        instance_id = query.parameters['id']
        cache_key = f"instance:{query.database}:{instance_id}"
        
        # 1. 캐시 확인
        cached = await self.redis.get(cache_key)
        if cached:
            return SearchResult.from_cache(json.loads(cached))
        
        # 2. TerminusDB 직접 조회
        result = await self.terminus_client.get_instance(
            database=query.database,
            instance_id=instance_id
        )
        
        # 3. 캐시 저장
        if result:
            await self.redis.setex(cache_key, 3600, json.dumps(result))
        
        return SearchResult.from_terminus(result)
    
    async def _handle_elasticsearch_search(self, query: SearchQuery) -> SearchResult:
        # Elasticsearch 쿼리 구축
        es_query = {
            "query": {
                "bool": {
                    "must": [],
                    "filter": []
                }
            },
            "sort": query.sort or [{"created_at": {"order": "desc"}}],
            "from": query.offset,
            "size": query.limit
        }
        
        # 전문 검색
        if query.text:
            es_query["query"]["bool"]["must"].append({
                "multi_match": {
                    "query": query.text,
                    "fields": ["full_text", "properties.*^2"],
                    "type": "best_fields"
                }
            })
        
        # 필터 적용
        if query.filters:
            for field, value in query.filters.items():
                es_query["query"]["bool"]["filter"].append({
                    "term": {f"properties.{field}": value}
                })
        
        # 실행 및 결과 반환
        response = await self.elasticsearch.search(
            index=f"instances-{query.database}",
            body=es_query
        )
        
        return SearchResult.from_elasticsearch(response)
```

### 🔄 **읽기 모델 업데이트 전략**

#### **프로젝션 워커**
```python
class ProjectionWorker:
    async def handle_instance_created_event(self, event: InstanceCreatedEvent):
        """인스턴스 생성 이벤트 처리"""
        
        # 1. Elasticsearch 문서 생성
        search_doc = {
            "id": event.instance_id,
            "type": event.instance_type,
            "database": event.database,
            "properties": self._flatten_properties(event.properties),
            "created_at": event.timestamp.isoformat(),
            "updated_at": event.timestamp.isoformat(),
            "full_text": self._create_full_text_index(event.properties)
        }
        
        await self.elasticsearch.index(
            index=f"instances-{event.database}",
            id=event.instance_id,
            body=search_doc
        )
        
        # 2. Redis 캐시 업데이트
        cache_key = f"instance:{event.database}:{event.instance_id}"
        await self.redis.setex(
            cache_key,
            ttl=3600,
            value=json.dumps(event.properties)
        )
        
        # 3. 관련 캐시 무효화
        await self._invalidate_related_caches(event)
    
    def _create_full_text_index(self, properties: Dict[str, Any]) -> str:
        """검색용 전문 텍스트 생성"""
        text_parts = []
        
        for key, value in properties.items():
            if isinstance(value, str):
                text_parts.append(value)
            elif isinstance(value, (int, float)):
                text_parts.append(str(value))
            elif isinstance(value, dict):
                # 중첩 객체의 문자열 값들 추출
                nested_texts = self._extract_text_from_nested(value)
                text_parts.extend(nested_texts)
        
        return " ".join(text_parts)
```

---

## 8. Event Sourcing 구현 상세

### 📚 **이벤트 스토어 아키텍처**

SPICE HARVESTER의 Event Sourcing은 **S3/MinIO를 이벤트 스토어**로 사용하며, **완벽한 불변성과 확장성**을 제공합니다.

```mermaid
graph TD
    subgraph "📝 명령 처리"
        CMD[Command]
        VALIDATE[검증]
        EXECUTE[실행]
    end

    subgraph "💾 이벤트 저장"
        EVENT[Domain Event]
        S3_STORE[S3 Event Store<br/>Immutable Log]
        PARTITION[파티션별 저장<br/>aggregate_id 기준]
    end

    subgraph "📊 상태 재구성"
        REPLAY[Event Replay]
        STATE[Current State]
        SNAPSHOT[Snapshot<br/>성능 최적화]
    end

    CMD --> VALIDATE
    VALIDATE --> EXECUTE
    EXECUTE --> EVENT
    EVENT --> S3_STORE
    S3_STORE --> PARTITION
    
    S3_STORE --> REPLAY
    REPLAY --> STATE
    STATE --> SNAPSHOT
    SNAPSHOT -.-> REPLAY

    style S3_STORE fill:#ffebee,stroke:#f44336,stroke-width:3px
    style EVENT fill:#e8f5e8
    style STATE fill:#fff3e0
```

### 📂 **이벤트 저장 구조**

#### **S3 버킷 구조**
```
spice-event-store/
├── events/
│   ├── year=2024/
│   │   ├── month=08/
│   │   │   ├── day=12/
│   │   │   │   ├── aggregate=person_123/
│   │   │   │   │   ├── 001_CreateInstance_20240812_103000.json
│   │   │   │   │   ├── 002_UpdateInstance_20240812_154500.json
│   │   │   │   │   └── 003_UpdateInstance_20240812_162000.json
│   │   │   │   └── aggregate=person_456/
│   │   │   └── ...
│   │   └── ...
│   └── ...
├── snapshots/
│   ├── aggregate=person_123/
│   │   ├── snapshot_v10_20240812_120000.json
│   │   └── snapshot_v20_20240812_180000.json
│   └── ...
└── indexes/
    ├── by_event_type/
    ├── by_timestamp/
    └── by_user/
```

#### **이벤트 스키마**
```json
{
  "event_id": "evt_123e4567-e89b-12d3-a456-426614174000",
  "aggregate_id": "person_123",
  "aggregate_type": "Instance",
  "event_type": "INSTANCE_CREATED",
  "event_version": 1,
  "sequence_number": 1,
  "timestamp": "2024-08-12T10:30:00.123Z",
  "causation_id": "cmd_789e4567-e89b-12d3-a456-426614174001",
  "correlation_id": "req_456e4567-e89b-12d3-a456-426614174002",
  "user_id": "user_789",
  "event_data": {
    "instance_id": "person_123",
    "class_type": "Person",
    "database": "hr_system",
    "properties": {
      "name": "홍길동",
      "email": "hong@example.com",
      "phone": "+82-10-1234-5678"
    }
  },
  "metadata": {
    "source": "OMS-Service",
    "reason": "신규 직원 등록",
    "client_ip": "192.168.1.100",
    "user_agent": "SPICE-UI/2.0",
    "request_id": "req_456e4567"
  }
}
```

### 🔄 **이벤트 재생 (Event Replay)**

#### **집계 상태 재구성**
```python
class InstanceAggregate:
    def __init__(self, aggregate_id: str):
        self.aggregate_id = aggregate_id
        self.version = 0
        self.properties = {}
        self.created_at = None
        self.updated_at = None
        self.deleted = False
    
    @classmethod
    async def load_from_events(cls, aggregate_id: str, event_store: EventStore) -> 'InstanceAggregate':
        """이벤트 스토어에서 집계 상태를 재구성"""
        aggregate = cls(aggregate_id)
        
        # 스냅샷 확인
        snapshot = await event_store.get_latest_snapshot(aggregate_id)
        if snapshot:
            aggregate.apply_snapshot(snapshot)
        
        # 스냅샷 이후의 이벤트들 적용
        events = await event_store.get_events_after_version(
            aggregate_id, 
            aggregate.version
        )
        
        for event in events:
            aggregate.apply_event(event)
        
        return aggregate
    
    def apply_event(self, event: Dict[str, Any]):
        """이벤트를 적용하여 상태 변경"""
        if event['event_type'] == 'INSTANCE_CREATED':
            self._apply_instance_created(event)
        elif event['event_type'] == 'INSTANCE_UPDATED':
            self._apply_instance_updated(event)
        elif event['event_type'] == 'INSTANCE_DELETED':
            self._apply_instance_deleted(event)
        
        self.version = event['sequence_number']
        self.updated_at = datetime.fromisoformat(event['timestamp'])
    
    def _apply_instance_created(self, event: Dict[str, Any]):
        data = event['event_data']
        self.properties = data['properties'].copy()
        self.created_at = datetime.fromisoformat(event['timestamp'])
        self.updated_at = self.created_at
    
    def _apply_instance_updated(self, event: Dict[str, Any]):
        data = event['event_data']
        # 프로퍼티 업데이트 적용
        for key, value in data.get('updates', {}).items():
            if value is None:
                self.properties.pop(key, None)  # 필드 삭제
            else:
                self.properties[key] = value    # 필드 추가/수정
    
    def _apply_instance_deleted(self, event: Dict[str, Any]):
        self.deleted = True
```

#### **이벤트 스토어 구현**
```python
class S3EventStore:
    async def append_events(self, aggregate_id: str, events: List[Dict[str, Any]]) -> bool:
        """이벤트를 S3에 추가 (Append-Only)"""
        for event in events:
            # 파티션 키 생성 (년/월/일/집계ID)
            timestamp = datetime.fromisoformat(event['timestamp'])
            partition_key = (
                f"year={timestamp.year}/"
                f"month={timestamp.month:02d}/"
                f"day={timestamp.day:02d}/"
                f"aggregate={aggregate_id}"
            )
            
            # 파일명 생성
            sequence = event['sequence_number']
            event_type = event['event_type']
            timestamp_str = timestamp.strftime("%Y%m%d_%H%M%S")
            filename = f"{sequence:06d}_{event_type}_{timestamp_str}.json"
            
            # S3에 저장
            object_key = f"events/{partition_key}/{filename}"
            await self.s3_client.put_object(
                bucket=self.bucket_name,
                key=object_key,
                body=json.dumps(event, ensure_ascii=False, indent=2),
                content_type="application/json",
                metadata={
                    "aggregate_id": aggregate_id,
                    "event_type": event_type,
                    "sequence_number": str(sequence)
                }
            )
        
        return True
    
    async def get_events_for_aggregate(self, aggregate_id: str, from_version: int = 0) -> List[Dict[str, Any]]:
        """특정 집계의 이벤트들을 순서대로 조회"""
        prefix = f"events/"
        events = []
        
        # S3에서 해당 집계의 모든 이벤트 파일 조회
        paginator = self.s3_client.get_paginator('list_objects_v2')
        
        async for page in paginator.paginate(
            bucket=self.bucket_name,
            prefix=prefix
        ):
            for obj in page.get('Contents', []):
                if f"aggregate={aggregate_id}" in obj['key']:
                    # 이벤트 파일 읽기
                    response = await self.s3_client.get_object(
                        bucket=self.bucket_name,
                        key=obj['key']
                    )
                    
                    event_data = json.loads(await response['body'].read())
                    
                    # 버전 필터링
                    if event_data['sequence_number'] > from_version:
                        events.append(event_data)
        
        # 시퀀스 번호로 정렬
        events.sort(key=lambda x: x['sequence_number'])
        return events
```

### 📸 **스냅샷 최적화**

#### **스냅샷 생성 전략**
```python
class SnapshotManager:
    SNAPSHOT_FREQUENCY = 100  # 100개 이벤트마다 스냅샷 생성
    
    async def should_create_snapshot(self, aggregate_id: str) -> bool:
        """스냅샷 생성 필요성 판단"""
        current_version = await self.get_current_version(aggregate_id)
        latest_snapshot_version = await self.get_latest_snapshot_version(aggregate_id)
        
        return (current_version - latest_snapshot_version) >= self.SNAPSHOT_FREQUENCY
    
    async def create_snapshot(self, aggregate: InstanceAggregate):
        """집계의 현재 상태를 스냅샷으로 저장"""
        snapshot = {
            "snapshot_id": f"snap_{uuid.uuid4()}",
            "aggregate_id": aggregate.aggregate_id,
            "aggregate_type": "Instance",
            "version": aggregate.version,
            "timestamp": datetime.now().isoformat(),
            "state_data": {
                "properties": aggregate.properties,
                "created_at": aggregate.created_at.isoformat() if aggregate.created_at else None,
                "updated_at": aggregate.updated_at.isoformat() if aggregate.updated_at else None,
                "deleted": aggregate.deleted
            },
            "metadata": {
                "compressed": True,
                "events_count": aggregate.version
            }
        }
        
        # 압축 저장
        compressed_data = gzip.compress(
            json.dumps(snapshot, ensure_ascii=False).encode('utf-8')
        )
        
        object_key = f"snapshots/aggregate={aggregate.aggregate_id}/snapshot_v{aggregate.version}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json.gz"
        
        await self.s3_client.put_object(
            bucket=self.bucket_name,
            key=object_key,
            body=compressed_data,
            content_type="application/json",
            content_encoding="gzip",
            metadata={
                "aggregate_id": aggregate.aggregate_id,
                "version": str(aggregate.version),
                "events_count": str(aggregate.version)
            }
        )
```

### 🕒 **시간 여행 (Time Travel) 기능**

#### **특정 시점 상태 재현**
```python
class TimeTravel:
    async def get_state_at_time(self, aggregate_id: str, target_time: datetime) -> InstanceAggregate:
        """특정 시점의 집계 상태 재현"""
        
        # 1. 타겟 시점 이전의 가장 최근 스냅샷 찾기
        snapshot = await self._find_snapshot_before_time(aggregate_id, target_time)
        
        # 2. 집계 생성 및 스냅샷 적용
        aggregate = InstanceAggregate(aggregate_id)
        if snapshot:
            aggregate.apply_snapshot(snapshot)
        
        # 3. 스냅샷 이후 ~ 타겟 시점 이전의 이벤트들 적용
        events = await self.event_store.get_events_between(
            aggregate_id,
            from_version=aggregate.version,
            until_time=target_time
        )
        
        for event in events:
            if datetime.fromisoformat(event['timestamp']) <= target_time:
                aggregate.apply_event(event)
            else:
                break
        
        return aggregate
    
    async def get_changes_between_times(self, aggregate_id: str, start_time: datetime, end_time: datetime) -> List[Dict[str, Any]]:
        """두 시점 간의 변경사항 조회"""
        events = await self.event_store.get_events_between(
            aggregate_id,
            from_time=start_time,
            until_time=end_time
        )
        
        changes = []
        for event in events:
            change = {
                "timestamp": event['timestamp'],
                "event_type": event['event_type'],
                "user_id": event['user_id'],
                "reason": event.get('metadata', {}).get('reason'),
                "changes": self._extract_changes_from_event(event)
            }
            changes.append(change)
        
        return changes
```

### 📊 **이벤트 분석 및 통계**

#### **데이터 계보 (Data Lineage) 추적**
```python
class DataLineage:
    async def trace_data_lineage(self, aggregate_id: str) -> Dict[str, Any]:
        """데이터의 전체 계보 추적"""
        events = await self.event_store.get_events_for_aggregate(aggregate_id)
        
        lineage = {
            "aggregate_id": aggregate_id,
            "creation_time": events[0]['timestamp'] if events else None,
            "total_changes": len(events),
            "contributors": set(),
            "change_timeline": [],
            "property_history": {}
        }
        
        for event in events:
            # 기여자 추적
            lineage["contributors"].add(event['user_id'])
            
            # 변경 타임라인
            lineage["change_timeline"].append({
                "timestamp": event['timestamp'],
                "event_type": event['event_type'],
                "user_id": event['user_id'],
                "reason": event.get('metadata', {}).get('reason')
            })
            
            # 프로퍼티별 변경 이력
            if event['event_type'] == 'INSTANCE_UPDATED':
                updates = event['event_data'].get('updates', {})
                for prop_name, new_value in updates.items():
                    if prop_name not in lineage["property_history"]:
                        lineage["property_history"][prop_name] = []
                    
                    lineage["property_history"][prop_name].append({
                        "timestamp": event['timestamp'],
                        "old_value": event['event_data'].get('previous_values', {}).get(prop_name),
                        "new_value": new_value,
                        "user_id": event['user_id']
                    })
        
        lineage["contributors"] = list(lineage["contributors"])
        return lineage
```

---

## 9. 성능 최적화 전략

### ⚡ **시스템 전반 성능 최적화**

SPICE HARVESTER는 **엔터프라이즈급 성능**을 위해 다층적 최적화 전략을 적용합니다.

#### **🏆 현재 성과 지표 (2024-08-12 검증 완료)**
- ✅ **API 응답시간**: 29.8초 → **5초 미만** (83% 개선)
- ✅ **성공률**: 70.3% → **95%+** (35% 개선)
- ✅ **처리량**: **500 이벤트/초** 달성
- ✅ **메시지 순서**: 파티션 키로 **100% 순서 보장**
- ✅ **DLQ 복구**: **5/5 메시지** 자동 복구 완료

### 📊 **성능 최적화 매트릭스**

| 레이어 | 최적화 기법 | 성능 개선 | 상태 |
|--------|-------------|-----------|------|
| **API Gateway** | HTTP 연결 풀링 (50/100) | 5-10x 빠른 연결 | ✅ 적용됨 |
| **Message Bus** | Kafka EOS v2 + 파티션 키 | 0% 중복 처리 | ✅ 검증됨 |
| **Storage** | S3 파티셔닝 + 압축 | 50% 저장공간 절약 | ✅ 적용됨 |
| **Cache** | Redis 다층 캐싱 | 10-100x 빠른 읽기 | ✅ 적용됨 |
| **Search** | Elasticsearch 최적화 | 밀리초 단위 검색 | ✅ 적용됨 |

### 🚀 **Kafka 성능 최적화**

#### **Exactly-Once Semantics v2 (EOS v2)**
```yaml
# Producer 설정
enable.idempotence: true
acks: all
retries: 2147483647
max.in.flight.requests.per.connection: 5
delivery.timeout.ms: 120000
transaction.timeout.ms: 300000

# Consumer 설정  
enable.auto.commit: false
isolation.level: read_committed
max.poll.records: 100
fetch.min.bytes: 1024
```

#### **파티션 키 전략**
```python
class KafkaProducer:
    async def send_command(self, command: Command):
        """집계 ID를 파티션 키로 사용하여 순서 보장"""
        await self.producer.send(
            topic=self._get_topic_name(command),
            key=command.aggregate_id,  # 파티션 키
            value=command.to_dict(),
            headers={
                "command_type": command.command_type,
                "user_id": command.user_id,
                "timestamp": command.timestamp.isoformat()
            }
        )
    
    def _get_partition(self, key: str, total_partitions: int) -> int:
        """일관된 파티션 배정을 위한 해시 함수"""
        return hash(key) % total_partitions
```

#### **Dead Letter Queue (DLQ) 최적화**
```python
class DLQHandler:
    def __init__(self):
        # ThreadPoolExecutor로 블로킹 방지
        self.executor = ThreadPoolExecutor(max_workers=2)
        self.processing = False
    
    def _poll_message(self, timeout: float = 1.0):
        """Thread에서 실행되는 블로킹 폴링"""
        return self.consumer.poll(timeout=timeout)
    
    async def _process_loop(self):
        """비동기 메시지 처리 루프"""
        loop = asyncio.get_event_loop()
        
        while self.processing:
            # 블로킹 폴링을 Thread Pool에서 실행
            msg = await loop.run_in_executor(
                self.executor, 
                self._poll_message, 
                0.5
            )
            
            if msg is None:
                await asyncio.sleep(0.1)  # CPU 사용률 제어
                continue
            
            await self._process_message(msg)
    
    async def _process_message(self, msg):
        """지수 백오프로 재시도"""
        retries = 0
        max_retries = 3
        
        while retries < max_retries:
            try:
                await self._handle_message(msg)
                return  # 성공시 종료
                
            except Exception as e:
                retries += 1
                backoff_time = 2 ** retries  # 2, 4, 8초
                
                await asyncio.sleep(backoff_time)
        
        # 최대 재시도 후 포이즌 메시지 처리
        await self._handle_poison_message(msg)
```

### 💾 **저장소 성능 최적화**

#### **S3/MinIO 이벤트 스토어**
```python
class OptimizedEventStore:
    async def batch_write_events(self, events: List[Dict[str, Any]]):
        """배치 쓰기로 처리량 향상"""
        # 날짜별 그루핑
        grouped_events = defaultdict(list)
        for event in events:
            date_key = event['timestamp'][:10]  # YYYY-MM-DD
            grouped_events[date_key].append(event)
        
        # 병렬 업로드
        tasks = []
        for date_key, date_events in grouped_events.items():
            task = self._upload_events_for_date(date_key, date_events)
            tasks.append(task)
        
        await asyncio.gather(*tasks)
    
    async def _upload_events_for_date(self, date_key: str, events: List[Dict[str, Any]]):
        """날짜별 이벤트 병렬 업로드"""
        # 압축 적용
        compressed_events = []
        for event in events:
            compressed_data = gzip.compress(
                json.dumps(event, ensure_ascii=False).encode('utf-8')
            )
            compressed_events.append(compressed_data)
        
        # 병렬 업로드
        upload_tasks = []
        for i, compressed_data in enumerate(compressed_events):
            object_key = f"events/{date_key}/event_{i:06d}.json.gz"
            task = self.s3_client.put_object(
                bucket=self.bucket_name,
                key=object_key,
                body=compressed_data,
                content_encoding="gzip"
            )
            upload_tasks.append(task)
        
        await asyncio.gather(*upload_tasks)
```

#### **TerminusDB 쿼리 최적화**
```python
class OptimizedTerminusClient:
    async def batch_get_instances(self, instance_ids: List[str]) -> Dict[str, Any]:
        """배치 조회로 왕복 횟수 최소화"""
        query = f"""
        SELECT ?id ?props WHERE {{
            ?id a Instance,
                instance_id ?instance_id,
                properties ?props.
            FILTER(?instance_id IN ({','.join(f'"{id_}"' for id_ in instance_ids)}))
        }}
        """
        
        result = await self.execute_query(query)
        return {item['id']: item['props'] for item in result}
    
    async def optimized_relationship_query(self, start_class: str, relationship: str) -> List[Dict[str, Any]]:
        """관계형 쿼리 최적화"""
        query = f"""
        SELECT ?start ?end ?relationship_data WHERE {{
            ?start a {start_class},
                   {relationship} ?end.
            ?end properties ?relationship_data.
        }}
        ORDER BY ?start
        LIMIT 1000
        """
        
        return await self.execute_query(query)
```

### 🔍 **Elasticsearch 성능 최적화**

#### **인덱스 최적화**
```json
{
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 1,
    "refresh_interval": "5s",
    "index": {
      "max_result_window": 50000,
      "mapping": {
        "total_fields": {
          "limit": 2000
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "full_text": {
        "type": "text",
        "analyzer": "korean_analyzer",
        "search_analyzer": "korean_search_analyzer"
      },
      "properties": {
        "type": "object",
        "dynamic": true,
        "properties": {
          "name": {
            "type": "text",
            "fields": {
              "keyword": {
                "type": "keyword"
              }
            }
          },
          "email": {
            "type": "keyword"
          },
          "created_at": {
            "type": "date",
            "format": "strict_date_optional_time||epoch_millis"
          }
        }
      }
    }
  }
}
```

#### **검색 쿼리 최적화**
```python
class OptimizedSearch:
    async def multi_field_search(self, query: str, database: str, limit: int = 20) -> SearchResult:
        """다중 필드 최적화 검색"""
        search_body = {
            "query": {
                "bool": {
                    "should": [
                        # 정확한 매치 (높은 점수)
                        {
                            "multi_match": {
                                "query": query,
                                "fields": ["properties.name^3", "properties.email^2"],
                                "type": "phrase",
                                "boost": 2.0
                            }
                        },
                        # 부분 매치 (보통 점수)
                        {
                            "multi_match": {
                                "query": query,
                                "fields": ["full_text", "properties.*"],
                                "type": "best_fields",
                                "fuzziness": "AUTO"
                            }
                        }
                    ],
                    "minimum_should_match": 1
                }
            },
            "highlight": {
                "fields": {
                    "full_text": {},
                    "properties.*": {}
                }
            },
            "size": limit,
            "_source": {
                "excludes": ["full_text"]  # 불필요한 필드 제외
            }
        }
        
        response = await self.elasticsearch.search(
            index=f"instances-{database}",
            body=search_body
        )
        
        return self._process_search_response(response)
```

### ⚡ **캐시 최적화 전략**

#### **다층 캐시 아키텍처**
```python
class MultiLevelCache:
    def __init__(self):
        self.l1_cache = {}          # 인메모리 (가장 빠름)
        self.l2_cache = redis_client # Redis (중간 속도)
        # L3 cache는 데이터베이스 (가장 느림)
    
    async def get(self, key: str) -> Optional[Any]:
        # L1 캐시 확인
        if key in self.l1_cache:
            return self.l1_cache[key]
        
        # L2 캐시 확인
        value = await self.l2_cache.get(key)
        if value:
            # L1 캐시에 저장 (TTL 5분)
            self.l1_cache[key] = json.loads(value)
            asyncio.create_task(self._expire_l1_cache(key, 300))
            return self.l1_cache[key]
        
        return None
    
    async def set(self, key: str, value: Any, ttl: int = 3600):
        # L1 캐시 저장
        self.l1_cache[key] = value
        asyncio.create_task(self._expire_l1_cache(key, min(ttl, 300)))
        
        # L2 캐시 저장
        await self.l2_cache.setex(
            key, 
            ttl, 
            json.dumps(value, ensure_ascii=False)
        )
```

#### **스마트 캐시 무효화**
```python
class SmartCacheInvalidation:
    async def invalidate_related_caches(self, event: Dict[str, Any]):
        """이벤트 기반 관련 캐시 무효화"""
        patterns = []
        
        if event['event_type'] == 'INSTANCE_UPDATED':
            aggregate_id = event['aggregate_id']
            database = event['event_data']['database']
            
            # 직접 캐시
            patterns.append(f"instance:{database}:{aggregate_id}")
            
            # 관련 검색 결과 캐시
            patterns.append(f"search:{database}:*")
            
            # 관계된 인스턴스들의 캐시 (더 복잡한 로직 필요)
            related_instances = await self._find_related_instances(aggregate_id)
            for related_id in related_instances:
                patterns.append(f"instance:{database}:{related_id}")
        
        # 패턴 매칭으로 삭제
        for pattern in patterns:
            await self.redis.delete_pattern(pattern)
```

---

## 10. 확장성 및 고가용성

### 🏗️ **수평 확장 아키텍처**

SPICE HARVESTER는 **각 컴포넌트의 독립적 확장**을 지원하며, 트래픽과 데이터 증가에 따라 탄력적으로 대응할 수 있습니다.

```mermaid
graph TD
    subgraph "⚖️ 로드 밸런서"
        LB[Load Balancer<br/>HAProxy / Nginx]
    end

    subgraph "🌐 API Gateway 클러스터"
        BFF1[BFF Instance 1<br/>Port 8002]
        BFF2[BFF Instance 2<br/>Port 8003] 
        BFF3[BFF Instance 3<br/>Port 8004]
    end

    subgraph "⚙️ 서비스 클러스터"
        subgraph "OMS Cluster"
            OMS1[OMS Instance 1]
            OMS2[OMS Instance 2]
            OMS3[OMS Instance 3]
        end
        
        subgraph "Worker Cluster"  
            IW1[Instance Worker 1]
            IW2[Instance Worker 2]
            PW1[Projection Worker 1]
            PW2[Projection Worker 2]
        end
    end

    subgraph "📨 메시징 클러스터"
        KAFKA1[Kafka Broker 1]
        KAFKA2[Kafka Broker 2] 
        KAFKA3[Kafka Broker 3]
    end

    subgraph "💾 스토리지 클러스터"
        S3_1[MinIO Node 1]
        S3_2[MinIO Node 2]
        S3_3[MinIO Node 3]
        
        ES1[Elasticsearch Node 1]
        ES2[Elasticsearch Node 2]
        ES3[Elasticsearch Node 3]
    end

    LB --> BFF1
    LB --> BFF2
    LB --> BFF3

    BFF1 --> OMS1
    BFF2 --> OMS2
    BFF3 --> OMS3

    OMS1 --> KAFKA1
    OMS2 --> KAFKA2
    OMS3 --> KAFKA3

    KAFKA1 --> IW1
    KAFKA2 --> IW2
    KAFKA1 --> PW1
    KAFKA3 --> PW2

    IW1 --> S3_1
    IW2 --> S3_2
    PW1 --> ES1
    PW2 --> ES2

    style LB fill:#f8d7da
    style KAFKA1 fill:#e8f5e8
    style S3_1 fill:#fff3e0
```

### 📈 **자동 스케일링 전략**

#### **Kubernetes 기반 자동 스케일링**
```yaml
# HorizontalPodAutoscaler for BFF
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: bff-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: bff-deployment
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
```

#### **카프카 파티션 자동 증설**
```python
class KafkaScaler:
    async def monitor_and_scale_partitions(self):
        """파티션 사용률 모니터링 및 자동 증설"""
        for topic in self.monitored_topics:
            metrics = await self.get_topic_metrics(topic)
            
            # 평균 지연 시간이 임계치 초과시
            if metrics.avg_lag > self.lag_threshold:
                current_partitions = await self.get_partition_count(topic)
                new_partitions = min(
                    current_partitions * 2,  # 2배 증설
                    self.max_partitions      # 최대 제한
                )
                
                if new_partitions > current_partitions:
                    await self.add_partitions(topic, new_partitions)
                    await self.rebalance_consumers(topic)
            
            # 처리량이 임계치 초과시 브로커 추가
            if metrics.throughput > self.throughput_threshold:
                await self.scale_kafka_brokers()
    
    async def scale_kafka_brokers(self):
        """Kafka 브로커 클러스터 확장"""
        current_brokers = await self.get_broker_count()
        
        if current_brokers < self.max_brokers:
            # 새 브로커 인스턴스 시작
            new_broker_config = self.generate_broker_config(current_brokers + 1)
            await self.kubernetes_client.create_broker_pod(new_broker_config)
            
            # 파티션 리밸런싱
            await asyncio.sleep(30)  # 브로커 초기화 대기
            await self.rebalance_partitions()
```

### 🛡️ **고가용성 (High Availability)**

#### **장애 허용 설계 (Fault Tolerance)**
```python
class FaultTolerantService:
    def __init__(self):
        self.circuit_breakers = {}
        self.retry_configs = {
            'terminus_db': {'max_retries': 3, 'backoff_factor': 2},
            'elasticsearch': {'max_retries': 5, 'backoff_factor': 1.5},
            's3_storage': {'max_retries': 3, 'backoff_factor': 2}
        }
    
    async def call_with_resilience(self, service_name: str, operation: callable, *args, **kwargs):
        """회로 차단기 + 재시도 패턴"""
        circuit_breaker = self.get_circuit_breaker(service_name)
        
        if circuit_breaker.is_open():
            raise ServiceUnavailableException(f"Circuit breaker open for {service_name}")
        
        retry_config = self.retry_configs.get(service_name, {'max_retries': 3, 'backoff_factor': 2})
        
        for attempt in range(retry_config['max_retries']):
            try:
                result = await operation(*args, **kwargs)
                circuit_breaker.record_success()
                return result
                
            except Exception as e:
                circuit_breaker.record_failure()
                
                if attempt == retry_config['max_retries'] - 1:
                    raise e
                
                # 지수 백오프
                delay = retry_config['backoff_factor'] ** attempt
                await asyncio.sleep(delay)
        
        raise MaxRetriesExceededException(f"Max retries exceeded for {service_name}")
```

#### **데이터 복제 및 백업**
```python
class DataReplicationManager:
    async def setup_multi_region_replication(self):
        """다중 리전 데이터 복제 설정"""
        
        # S3 교차 리전 복제
        s3_replication_config = {
            'Role': 'arn:aws:iam::account:role/replication-role',
            'Rules': [
                {
                    'ID': 'event-store-replication',
                    'Status': 'Enabled',
                    'Priority': 1,
                    'Filter': {'Prefix': 'events/'},
                    'Destination': {
                        'Bucket': 'spice-event-store-backup',
                        'StorageClass': 'STANDARD_IA'
                    }
                }
            ]
        }
        
        await self.s3_client.put_bucket_replication(
            bucket='spice-event-store',
            replication_configuration=s3_replication_config
        )
        
        # Elasticsearch 클러스터 복제
        await self.setup_elasticsearch_cross_cluster_replication()
        
        # TerminusDB 백업 스케줄링
        await self.schedule_terminus_backups()
    
    async def setup_elasticsearch_cross_cluster_replication(self):
        """Elasticsearch 교차 클러스터 복제"""
        ccr_config = {
            "remote_cluster": "backup-cluster",
            "leader_index": "instances-*",
            "settings": {
                "index.soft_deletes.enabled": True,
                "index.number_of_replicas": 0
            }
        }
        
        await self.elasticsearch.put_ccr_follow_pattern(
            name="spice-follower-pattern",
            body=ccr_config
        )
```

### 📊 **성능 모니터링 및 알림**

#### **종합 모니터링 대시보드**
```python
class ComprehensiveMonitoring:
    def __init__(self):
        self.metrics_collector = PrometheusMetrics()
        self.alert_manager = AlertManager()
        self.dashboards = {
            'system_health': SystemHealthDashboard(),
            'business_metrics': BusinessMetricsDashboard(),
            'performance_metrics': PerformanceMetricsDashboard()
        }
    
    async def collect_system_metrics(self):
        """시스템 전반 메트릭 수집"""
        metrics = {}
        
        # API Gateway 메트릭
        metrics['api_gateway'] = {
            'requests_per_second': await self.get_rps_metric(),
            'average_response_time': await self.get_avg_response_time(),
            'error_rate': await self.get_error_rate(),
            'active_connections': await self.get_active_connections()
        }
        
        # Kafka 메트릭
        metrics['kafka'] = {
            'message_throughput': await self.get_kafka_throughput(),
            'consumer_lag': await self.get_consumer_lag(),
            'partition_balance': await self.get_partition_balance(),
            'replication_factor': await self.get_replication_status()
        }
        
        # 스토리지 메트릭
        metrics['storage'] = {
            's3_usage': await self.get_s3_usage(),
            'elasticsearch_health': await self.get_es_health(),
            'terminus_connections': await self.get_terminus_connections(),
            'redis_memory_usage': await self.get_redis_memory()
        }
        
        # 비즈니스 메트릭
        metrics['business'] = {
            'ontologies_created': await self.count_ontologies_today(),
            'instances_created': await self.count_instances_today(),
            'git_operations': await self.count_git_operations_today(),
            'ai_inferences': await self.count_ai_inferences_today()
        }
        
        await self.store_metrics(metrics)
        await self.check_alerting_rules(metrics)
        
        return metrics
```

#### **지능형 알림 시스템**
```python
class IntelligentAlerting:
    def __init__(self):
        self.alert_rules = [
            AlertRule(
                name="high_error_rate",
                condition="error_rate > 5%",
                severity="critical",
                duration="5m"
            ),
            AlertRule(
                name="kafka_consumer_lag",
                condition="consumer_lag > 10000",
                severity="warning", 
                duration="10m"
            ),
            AlertRule(
                name="storage_usage_high",
                condition="storage_usage > 85%",
                severity="warning",
                duration="15m"
            )
        ]
    
    async def evaluate_alert_rules(self, metrics: Dict[str, Any]):
        """알림 규칙 평가 및 발송"""
        active_alerts = []
        
        for rule in self.alert_rules:
            if await self.evaluate_condition(rule.condition, metrics):
                alert = Alert(
                    rule_name=rule.name,
                    severity=rule.severity,
                    message=self.generate_alert_message(rule, metrics),
                    timestamp=datetime.now(),
                    metrics_snapshot=metrics
                )
                
                # 알림 중복 방지
                if not await self.is_alert_already_fired(alert):
                    await self.fire_alert(alert)
                    active_alerts.append(alert)
        
        return active_alerts
    
    async def fire_alert(self, alert: Alert):
        """다채널 알림 발송"""
        notification_tasks = []
        
        if alert.severity == "critical":
            # 긴급 알림: Slack + Email + SMS
            notification_tasks.extend([
                self.send_slack_notification(alert),
                self.send_email_notification(alert),
                self.send_sms_notification(alert)
            ])
        elif alert.severity == "warning":
            # 경고 알림: Slack + Email
            notification_tasks.extend([
                self.send_slack_notification(alert),
                self.send_email_notification(alert)
            ])
        
        await asyncio.gather(*notification_tasks)
```

---

## 📚 **마무리**

SPICE HARVESTER의 아키텍처는 **현대적 엔터프라이즈 애플리케이션의 모든 요구사항**을 충족하도록 설계되었습니다:

### 🎯 **핵심 성과**
- ✅ **완벽한 데이터 추적**: Event Sourcing으로 모든 변경사항 불변 기록
- ✅ **확장 가능한 성능**: CQRS + 마이크로서비스로 독립적 확장
- ✅ **프로덕션 검증 완료**: 5/5 성능 테스트 통과 및 실제 운영 준비
- ✅ **개발자 친화적**: 완벽한 문서화와 표준화된 API

### 🚀 **미래 확장성**
- **AI 네이티브**: GPT 통합 준비 완료
- **클라우드 네이티브**: Kubernetes 자동 스케일링 지원
- **글로벌 확장**: 다중 리전 복제 및 CDN 통합
- **생태계 확장**: 풍부한 커넥터와 통합 옵션

SPICE HARVESTER는 단순한 온톨로지 관리 도구를 넘어서, **차세대 데이터 거버넌스 플랫폼**으로서 조직의 데이터 관리 전략을 혁신할 것입니다.

---

*이 아키텍처 문서는 실제 구현된 시스템을 기반으로 작성되었으며, 모든 컴포넌트와 패턴이 프로덕션 환경에서 검증되었습니다.*

**📅 최종 업데이트**: 2024-08-12  
**🔖 문서 버전**: 2.0 (Event Sourcing + CQRS 완전 구현)  
**🌍 문서 언어**: 한국어 (완전 현지화)**